[{"path":"/articles/baba.html","id":"concept","dir":"Articles","previous_headings":"","what":"Concept","title":"Buffered Area Based Approach","text":"area-based approach partitions study area cells computes derived metrics points lie within cell. method offers straightforward means map value interest across territory. However, one drawback mapping resolution typically coarse, cells typically measuring 20 x 20 meters, corresponding 400 square meters inventory plots used build predictive model. Achieving finer resolution possible. lasR, introduced concept Buffered Area Based Approach (BABA) Moving Windows Area Based Approach (MWABA). BABA, metrics computed using points within cell size s (typically 20 meters), akin classical ABA. However, resolution raster effectively r due moving window progresses steps size r. instance, can compute average Z elevation 400 square meter area resolution 5 meters, instead typical 20 meters.","code":""},{"path":"/articles/baba.html","id":"exemple-1","dir":"Articles","previous_headings":"","what":"Exemple 1","title":"Buffered Area Based Approach","text":"’s important emphasize BABA, although resolution set 5 meters, values pixel computed based 20-meter cell. metric remains valid concerning reference plot inventory, typically 400 square meters. Consequently, becomes feasible predict map values interest fine-grained resolution using regular plot inventory data.","code":"f <- system.file(\"extdata\", \"Megaplot.las\", package=\"lasR\") aba  = rasterize(20, \"zmean\")      # ABA baba = rasterize(c(5,20), \"zmean\") # BABA pipeline = aba + baba ans = exec(pipeline, on = f)  terra::plot(ans[[1]], col = col, main = \"ABA\") terra::plot(ans[[2]], col = col, main = \"BABA\")"},{"path":"/articles/baba.html","id":"exemple-2","dir":"Articles","previous_headings":"","what":"Exemple 2","title":"Buffered Area Based Approach","text":"approach also enables mapping point density finer resolution, among possibilities.","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") c1 <- rasterize(1, \"count\") c2  <- rasterize(c(1,4), \"count\") pipeline = c1 + c2 res <- exec(pipeline, on = f) terra::plot(res[[1]]/4, col = gray.colors(15,0,1), main = \"Regular\")   # divide by 4 to get the density terra::plot(res[[2]]/25, col = gray.colors(15,0,1), main = \"Moving windows\")  # divide by 25 to get the density"},{"path":"/articles/baba.html","id":"naming-convention","dir":"Articles","previous_headings":"","what":"Naming convention","title":"Buffered Area Based Approach","text":"Buffered Area Based Approach (BABA), Moving Windows Area Based Approach (MWABA), Multi-Resolution Area Based Approach (MRABA) – feel free refer however prefer.","code":""},{"path":[]},{"path":"/articles/benchmarks.html","id":"code","dir":"Articles","previous_headings":"Canopy Height Model","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) chm = rasterize_canopy(ctg, 1, p2r())   # lasR set_parallel_strategy(...) pipeline = rasterize(1, \"max\") exec(pipeline, on = ctg)"},{"path":[]},{"path":[]},{"path":"/articles/benchmarks.html","id":"code-1","dir":"Articles","previous_headings":"Digital Terrain Model","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) dtm = rasterize_terrain(ctg, 1, tin())  # lasR set_parallel_strategy(...) tri = triangulate() pipeline = reader_las(filter = keep_ground()) + tri + rasterize(1, tri) exec(pipeline, on = ctg)"},{"path":[]},{"path":"/articles/benchmarks.html","id":"multiple-raster","dir":"Articles","previous_headings":"","what":"Multiple raster","title":"Benchmarks of lasR vs. lidR","text":"gain terms computation time much significant running multiple stages single pipeline files read lasR multiple times lidR. , operations executed single pass C++ level, resulting efficient memory management.","code":""},{"path":"/articles/benchmarks.html","id":"code-2","dir":"Articles","previous_headings":"Multiple raster","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) custom_function = function(z,i) { list(avgz = mean(z), avgi = mean(i)) } ctg = readLAScatalog(f) chm = rasterize_canopy(ctg, 1, p2r()) met = pixel_metrics(ctg, ~custom_function(Z, Intensity), 20) den = rasterize_density(ctg, 5)  # lasR set_parallel_strategy(...) custom_function = function(z,i) { list(avgz = mean(z), avgi = mean(i)) } chm = rasterize(1, \"max\") met = rasterize(20, custom_function(Z, Intensity)) den = rasterize(5, \"count\") pipeline = chm + met + den exec(pipeline, on = folder)"},{"path":[]},{"path":[]},{"path":"/articles/benchmarks.html","id":"code-3","dir":"Articles","previous_headings":"Normalization","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) opt_output_files(ctg) <- paste0(tempdir(), \"/*_norm\") norm = normalize_height(ctg, tin())  # lasR set_parallel_strategy(...) pipeline = reader(f) + normalize() + write_las() processor(pipeline)"},{"path":[]},{"path":[]},{"path":"/articles/benchmarks.html","id":"code-4","dir":"Articles","previous_headings":"Local maximum","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) tree = locate_trees(ctg, lmf(5))  # lasR set_parallel_strategy(...) pipeline = reader(f) + local_maximum(5) processor(pipeline)"},{"path":[]},{"path":"/articles/benchmarks.html","id":"complex-pipeline","dir":"Articles","previous_headings":"","what":"Complex Pipeline","title":"Benchmarks of lasR vs. lidR","text":"complex pipeline, point cloud normalized written new files. Digital Terrain Model (DTM) produced, Canopy Height Model (CHM) built, individual trees detected. detected trees used seeds region-growing algorithm segments trees. lasR pipeline can handle hundreds laser tiles, lidR may struggle apply pipeline, especially tree segmentation.","code":""},{"path":"/articles/benchmarks.html","id":"code-5","dir":"Articles","previous_headings":"Complex Pipeline","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"del = triangulate(filter = keep_ground()) norm = transform_with(del) dtm = rasterize(1, del) chm = rasterize(1, \"max\") seed = local_maximum(3) tree = region_growing(chm, seed) write = write_las() pipeline = read + del + norm + write + dtm + chm +  seed + tree ans = exec(pipeline, on = ctg, progress = TRUE)"},{"path":[]},{"path":"/articles/multithreading.html","id":"sequential-strategy","dir":"Articles","previous_headings":"","what":"Sequential strategy","title":"Parallel processing","text":"sequential strategy default strategy. However, easier start option explain specificities lasR. sequential processing, name indicates, LAS/LAZ files processed sequentially, nothing parallelized. point cloud one file passes pipeline files waiting processed. represented figure .","code":"set_parallel_strategy(sequential()) # or exec(pipeline, on = f, ncores = sequential())"},{"path":"/articles/multithreading.html","id":"concurrent-points-strategy","dir":"Articles","previous_headings":"","what":"Concurrent points strategy","title":"Parallel processing","text":"Concurrent points half_cores() default strategy. LAS/LAZ files processed sequentially. point cloud one file passes pipeline files waiting. Inside pipeline, stages parallelized processing points different threads. core processes subset point cloud. stages parallelized consequently faster, practice, lot stages can easily parallelized way.","code":"set_parallel_strategy(concurrent_points(4)) # or exec(pipeline, on = f, ncores = concurrent_points(4))"},{"path":"/articles/multithreading.html","id":"concurrent-files-strategy","dir":"Articles","previous_headings":"","what":"Concurrent files strategy","title":"Parallel processing","text":"LAS/LAZ files processed parallel. point cloud several files passes several cloned pipelines files waiting. Inside pipeline, stages parallelized. puts lot pressure disk many LAS/LAZ files read simultaneously, also stage can write raster/vector/LAS files simultaneously. Additionally, uses lot memory since many LAS files loaded memory simultaneously. modern fast SSD disks significant amount RAM, fastest option. course, users use cores; otherwise, may run memory. See also benchmarks vignette.","code":"set_parallel_strategy(concurrent_files(4)) # or exec(pipeline, on = f, ncores = concurrent_files(4)) # or exec(pipeline, on = f, ncores = 4) # more convenient"},{"path":"/articles/multithreading.html","id":"nested-strategy","dir":"Articles","previous_headings":"","what":"Nested strategy","title":"Parallel processing","text":"LAS/LAZ files processed parallel. point cloud several files passes several cloned pipelines files waiting. Inside pipeline, stages also parallelized processing points different threads. Nested reserved experts .","code":"set_parallel_strategy(nested(4, 2)) # or exec(pipeline, on = f, ncores = nested(4, 2))"},{"path":"/articles/multithreading.html","id":"special-cases","dir":"Articles","previous_headings":"","what":"Special cases","title":"Parallel processing","text":"lasR, everything written pure C++ except two stages inject user-defined R code use R C API (see R stages) R multi-threaded, thus calling stages parallel thread-safe crash R session best case deeply corrupt R memory worst case. Consequently, stages protected pipelines involving stages ran parallel concurrent-files strategy.","code":"rasterize(20, user_function(Z)) callback(user_function(data))"},{"path":"/articles/multithreading.html","id":"real-timeline","dir":"Articles","previous_headings":"","what":"Real timeline","title":"Parallel processing","text":"figures , pipelines represented idealized simplified manner. example, stages depicted taking amount time, cores shown running parallel without overhead. simplification aids understanding, capture full complexity actual process. actual timeline real pipeline processing 9 files shown figure .","code":""},{"path":[]},{"path":"/articles/pipeline.html","id":"normalize","dir":"Articles","previous_headings":"Pipeline factories","what":"Normalize","title":"Pipelines","text":"pipeline already installed package. can used way","code":"normalize = function(extrabytes = FALSE) {   tri <- triangulate(filter = keep_ground())   pipeline <- tri      if (extrabytes)   {     extra = add_extrabytes(\"int\", \"HAG\", \"Height Above Ground\")     trans = transform_with(tri, store_in_attribute = \"HAG\")     pipeline = pipeline + extra + trans   }   else   {     trans = transform_with(tri)     pipeline = pipeline + trans   }      return(pipeline) } pipeline = reader(f) + normalize() + write_las(o)"},{"path":[]},{"path":"/articles/pipeline.html","id":"with-csf","dir":"Articles","previous_headings":"Pipeline factories > Classify ground","what":"With CSF","title":"Pipelines","text":"","code":"ground_csf = function(smooth = FALSE, threshold = 0.5, resolution = 0.5, rigidness = 1L, iterations = 500L, step = 0.65) {   csf = function(data, smooth, threshold, resolution, rigidness, iterations, step)   {     id = RCSF::CSF(data, smooth, threshold, resolution, rigidness, iterations, step)     class = integer(nrow(data))     class[id] = 2L     data$Classification <- class     return(data)   }      classify = callback(csf, expose = \"xyz\", smooth = smooth, threshold = threshold, resolution = resolution, rigidness = rigidness, iterations = iterations, step = step)   return(classify) } pipeline = reader(f) + ground_csf() + write_las(o)"},{"path":"/articles/pipeline.html","id":"with-mcc","dir":"Articles","previous_headings":"Pipeline factories > Classify ground","what":"With MCC","title":"Pipelines","text":"pipelines use callback() exposes point cloud data.frame. One reasons lasR memory-efficient faster lidR expose point cloud data.frame. Thus, pipelines different classify_ground() function lidR. advantage using lasR ability pipe different stages.","code":"ground_mcc = function(s = 1.5, t = 0.3) {   csf = function(data, s, t)   {     id = RMCC::MCC(data, s, t)     class = integer(nrow(data))     class[id] = 2L     data$Classification <- class     return(data)   }      classify = callback(csf, expose = \"xyz\", s = s, t = t)   return(classify) } pipeline = reader(f) + ground_mcc() + write_las(o)"},{"path":"/articles/pipeline.html","id":"canopy-heigh-model","dir":"Articles","previous_headings":"Pipeline factories","what":"Canopy Heigh Model","title":"Pipelines","text":"two pipelines natively installed package name chm().","code":"chm_p2r = function(res, filter = \"\", ofile = tempfile(fileext = \".tif\")) {   return(rasterize(res, \"max\", filter = filter, ofile = ofile)) } chm_tin = function(res, ofile = tempfile(fileext = \".tif\")) {   tin = triangulate(filter = keep_first())   chm = rasterize(res, tin, ofile = ofile)   return(tin+chm) }"},{"path":"/articles/pipeline.html","id":"digital-terrain-model","dir":"Articles","previous_headings":"Pipeline factories","what":"Digital Terrain Model","title":"Pipelines","text":"one also natively installed package. add_class can used add class used ground 9 water.","code":"dtm = function(res, ofile = tempfile(fileext = \".tif\"), add_class = NULL) {   filter = keep_ground()   if (!is.null(add_class)) filter = filter + keep_class(add_class)   tin = triangulate(filter = filter)   chm = rasterize(res, tin, ofile = ofile)   return(tin+chm) }"},{"path":[]},{"path":"/articles/pipeline.html","id":"read-las","dir":"Articles","previous_headings":"Useful functions","what":"Read LAS","title":"Pipelines","text":"","code":"read_las = function(files, select = \"xyzi\", filter = \"\") {   load = function(data) { return(data) }   read = reader_las(filter = filter)   call = callback(load, expose = select, no_las_update = TRUE)   return(exec(read+call, on = f)) }"},{"path":"/articles/pipeline.html","id":"buffer-tiles","dir":"Articles","previous_headings":"Useful functions","what":"Buffer tiles","title":"Pipelines","text":"","code":"buffer_tiles = function(files, buffer, ofiles = paste0(tempdir(), \"/*_buffered.las\")) {   read = reader_las()   write = write_las(ofiles, keep_buffer = TRUE)   return(exec(read+write, on = files, buffer = buffer)) }"},{"path":"/articles/pipeline.html","id":"clip-circle","dir":"Articles","previous_headings":"Useful functions","what":"Clip circle","title":"Pipelines","text":"Writes LAS files returns data.frames. Supports sf objects input.","code":"clip_circle = function(files, geometry, radius, ofiles = paste0(tempdir(), \"/*_clipped.las\")) {   if (sf::st_geometry_type(geometry, FALSE) != \"POINT\")      stop(\"Expected POINT geometry type\")    coordinates <- sf::st_coordinates(geometry)   xcenter <- coordinates[,1]   ycenter <- coordinates[,2]      read = reader_las(xc = xcenter, yc = ycenter, r = radius)      if (length(ofiles) == 1L && ofiles == \"\")     stage = callback(function(data) { return(data) }, expose = \"*\", no_las_update = T)   else     stage = write_las(ofiles)      ans = exec(read+stage, on = files)   return(ans) }"},{"path":"/articles/pipeline.html","id":"crs","dir":"Articles","previous_headings":"Useful functions","what":"CRS","title":"Pipelines","text":"CRS sf object. cost applying hulls() virtually null.","code":"crs = function(files) {   pipeline = reader_las() + hulls()   ans = exec(pipeline, on = files)   return(sf::st_crs(ans)) }"},{"path":"/articles/pipeline.html","id":"inventory-metrics","dir":"Articles","previous_headings":"Useful functions","what":"Inventory metrics","title":"Pipelines","text":"Using sf object provide plot centers offering option normalize --fly. returns sf object extra attributes.","code":"inventory_metrics = function(files, geometry, radius, fun, normalize = FALSE) {   if (sf::st_geometry_type(geometry, FALSE) != \"POINT\")      stop(\"Expected POINT geometry type\")    coordinates <- sf::st_coordinates(geometry)   xcenter <- coordinates[,1]   ycenter <- coordinates[,2]      pipeline <- reader_las(xc = xcenter, yc = ycenter, r = radius)      if (normalize)   {     tri <- triangulate(filter = keep_ground())     trans <- transform_with(tri)     pipeline <- pipeline + tri + trans   }    pipeline <- pipeline + callback(fun, expose = \"*\")   ans <- exec(pipeline, on = files)   ans <- lapply(ans, as.data.frame)   ans <- do.call(rbind, ans)   return(cbind(geometry, ans)) }"},{"path":"/articles/pipeline.html","id":"virtual-point-cloud","dir":"Articles","previous_headings":"Useful functions","what":"Virtual point cloud","title":"Pipelines","text":"","code":"build_vpc = function(files, ofile) {   read = reader_las()   write = write_vpc(ofile)   exec(read+write, on = files) }"},{"path":"/articles/r-stages.html","id":"rasterize","dir":"Articles","previous_headings":"","what":"Rasterize","title":"R stages","text":"tutorial, mentioned rasterize() supports injection user-defined R expression. equivalent pixel_metrics() package lidR. user-defined function can mapped, making extremely versatile slower. Let’s compute map median intensity injecting user-defined expression. Like lidR, attributes point cloud named: X, Y, Z, Intensity, gpstime, ReturnNumber, NumberOfreturns, Classification, UserData, PointSourceID, R, G, B, NIR. users familiar lidR package, note ScanAngleRank/ScanAngle; instead scanner angle always named ScanAngle numeric. Also flags named Withheld, Synthetic Keypoint.  Notice , specific case, using rasterize(10, \"i_median\") efficient.","code":"pipeline = rasterize(10, median(Intensity)) ans = exec(pipeline, on = f)  terra::plot(ans, mar = c(1, 1, 1, 3), col = heat.colors(15))"},{"path":"/articles/r-stages.html","id":"callback","dir":"Articles","previous_headings":"","what":"Callback","title":"R stages","text":"callback stage holds significant importance second last entry point inject R code pipeline, following rasterize(). familiar lidR package, initial step often involves reading data lidR::readLAS() expose point cloud data.frame object R. contrast, lasR loads point cloud optimally C++ without exposing directly R. However, callback, becomes possible expose point cloud data.frame executing specific R functions. Similar lidR, attributes point cloud lasR named: X, Y, Z, Intensity, gpstime, ReturnNumber, NumberOfreturns, Classification, UserData, PointSourceID, R, G, B, NIR. Notably, users accustomed lidR package, scanner angle consistently named ScanAngle numeric, opposed ScanAngleRank/ScanAngle. Additionally, flags named Withheld, Synthetic, Keypoint. Let’s delve simple example. LAS file, callback loads point cloud data.frame invokes meanz() function data.frame. output list two elements processed two files (f displayed document). average Z elevation respectively 809.08 13.27 file. mindful , given LAS/LAZ file, point cloud may contain points original file file loaded buffer. clarification matter provided later. callback function versatile can also employed edit point cloud. user-defined function returns data.frame number rows original one, function edits underlying C++ dataset. enables users perform tasks assigning class specific point. physically removing points possible, users can flag points Withheld. cases, points processed subsequent stages, discarded. observed, , time callback explicitly return anything; however, edited point cloud internally. generate output, users must use another stage write_las(). ’s important note write_las() write point number 12 flagged withheld. Neither subsequent stage process . point still memory discarded. memory efficiency reasons, possible physically remove point underlying memory lasR. Instead, points flagged withheld never processed. One consequence , points flagged withheld LAS/LAZ file processed lasR. aligns intended purpose flag according LAS specification may differ default behavior many software market including lidR. Now, let’s explore capabilities callback . First, let’s create lidR-like read_las() function expose point cloud R. following example, user-defined function employed return data.frame . user’s function returns data.frame number points original dataset, updates points C++ level. , use no_las_update = TRUE explicitly return result. Ground points can also classified using R function, one provided RCSF package: callback() exposes point cloud data.frame. way expose point clouds users manageable way. One reasons lasR memory-efficient faster lidR expose point cloud data.frame. Thus, pipelines using callback() significantly different lidR. advantage using lasR ability pipe different stages.","code":"meanz = function(data){ return(mean(data$Z)) } call = callback(meanz, expose = \"xyz\") ans = exec(call, on = f) print(ans) #>  - 809.0835  #>  - 13.27202 edit_points = function(data) {   data$Classification[5:7] = c(2L,2L,2L)   data$Withheld = FALSE   data$Withheld[12] = TRUE   return(data) }  call = callback(edit_points, expose = \"xyzc\") ans = exec(call, on = f) ans #> NULL read_las = function(f, select = \"xyzi\", filter = \"\") {   load = function(data) { return(data) }   read = reader_las(filter = filter)   call = callback(load, expose = select, no_las_update = TRUE)   return (exec(read+call, on = f)) }  f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") las = read_las(f) head(las) #>          X       Y        Z Intensity #> 1 273357.1 5274360 806.5340      1340 #> 2 273357.2 5274359 806.5635       728 #> 3 273357.2 5274358 806.0248      1369 #> 4 273357.2 5274510 809.6303       589 #> 5 273357.2 5274509 809.3880      1302 #> 6 273357.2 5274508 809.4847       123 csf = function(data) {   id = RCSF::CSF(data)   class = integer(nrow(data))   class[id] = 2L   data$Classification <- class   return(data) }  read = reader_las() classify = callback(csf, expose = \"xyz\") write = write_las() pipeline = read + classify + write exec(pipeline, on = f)"},{"path":"/articles/r-stages.html","id":"buffer","dir":"Articles","previous_headings":"","what":"Buffer","title":"R stages","text":"Point clouds typically stored multiple contiguous files. avoid edge artifacts, file must loaded extra points coming neighboring files. Everything handled automatically, except callback() stage. callback(), point cloud exposed data.frame buffer, providing user-defined function spatial context. callback used edit points, everything handled internally. However, R object returned, responsibility user handle buffer. example, following pipeline, processing two files, callback() used count number points. presence triangulate() implies file loaded buffer make valid triangulation. Consequently, counting points callback() returns points summarise() summarise() internal function knows deal buffer. can compare pipeline without triangulate(). case, reason use buffer, files buffered. counts equal. handle buffer, user can read attribute bbox data.frame. contains bounding box point cloud without buffer use column Buffer contains TRUE FALSE point. TRUE, point buffer. buffer exposed user includes letter 'b'. conclusion, hypothesis user-defined function returns something complex, two ways handle buffer: either using bounding box using Buffer flag. third option use drop_buffer. case users ensure receive data.frame include points buffer.","code":"count = function(data) { length(data$X) } del = triangulate(filter = keep_ground()) npts = callback(count, expose = \"x\") sum = summarise() ans = exec(del + npts + sum, on = f) print(ans$callback) #>  - 682031  #>  - 931581 ans$callback[[1]]+ ans$callback[[2]] #> [1] 1613612 ans$summary$npoints #> [1] 1355607 ans = exec(npts + sum, on = f) ans$callback[[1]]+ ans$callback[[2]] #> [1] 1355607 ans$summary$npoints #> [1] 1355607 count_buffer_aware = function(data) {   bbox = attr(data, \"bbox\")   npoints = sum(!data$Buffer)   return(list(bbox = bbox, npoints = npoints)) }  del = triangulate(filter = keep_ground()) npts = callback(count_buffer_aware, expose = \"b\") # b for buffer sum = summarise() ans = exec(del + npts + sum, on = f) print(ans$callback) #>  - List: #>    - bbox : 885022.4 629157.2 885210.2 629400  #>    - npoints : 531662  #>  - List: #>    - bbox : 885024.1 629400 885217.1 629700  #>    - npoints : 823945 ans$callback[[1]]$npoints+ ans$callback[[2]]$npoints #> [1] 1355607 ans$summary$npoints #> [1] 1355607"},{"path":"/articles/r-stages.html","id":"parallelisation","dir":"Articles","previous_headings":"","what":"Parallelisation","title":"R stages","text":"Read multithreading page entering section. R multi-threaded, thus calling stages parallel thread-safe crash R session best case deeply corrupt R memory worst case. Consequently, stages protected run concurrently concurrent-file strategy. stages meant build complex convenient pipelines intend production tools. lasR::rasterize(10, mymetrics(Z, Intensity)) produces output lidR::pixel_metrics(las, mymetrics(Z, Intensity), 10), lidR version faster can parallelized multiple R sessions. lasR, hand, parallelizes computation single R session. approach pros cons won’t discussed tutorial. One con pipelines using injected R code parallelizable default.","code":""},{"path":"/articles/tutorial.html","id":"overall-functionality","dir":"Articles","previous_headings":"","what":"Overall functionality","title":"Tutorial","text":"lasR, R functions provided user designed process data directly; instead, used create pipeline. pipeline consists stages applied point cloud order. stage can either transform point cloud within pipeline without generating output process point cloud produce output. figure , 4 LAS/LAZ files pipeline (1) reads file, (2) builds writes DTM disk, (3) transforms point cloud normalizing elevation, (4) builds canopy height model using transformed point cloud, (5) transforms point cloud removing points 5 m. resulting version point cloud (points 5m) discarded lost additional stage pipeline. However, stages can added, application predictive model points 5 m stage writes point cloud disk. first file completes entire pipeline, second file used, pipeline applied fill missing parts geospatial rasters vectors produced pipeline. file loaded buffer neighboring files needed. pipeline created R interface nothing initially. building pipeline, users must call exec() function initiate computation.","code":""},{"path":"/articles/tutorial.html","id":"reader","dir":"Articles","previous_headings":"","what":"Reader","title":"Tutorial","text":"reader_las() stage MUST first stage pipeline (blue figure ). stage reads point cloud necessary. creating pipeline stage, header files read, computation actually applied. points thus even read stage pipeline require read points. result returned. practice using read_las() without argument can omitted, function exec adds --fly.","code":"pipeline = reader_las() exec(pipeline, on = f) #> NULL"},{"path":"/articles/tutorial.html","id":"triangulate","dir":"Articles","previous_headings":"","what":"Triangulate","title":"Tutorial","text":"first stage can try triangulate(). algorithm performs Delaunay triangulation points interest. Triangulating points useful task employed numerous processing tasks. Triangulating points interesting, usually want use filter argument triangulate specific points interest. following example, triangulate points classified 2 (.e., ground). produces meshed Digital Terrain Model. example, files read sequentially, points loaded one one stored build Delaunay triangulation. lasR, one file stored memory time. program stores point cloud Delaunay triangulation current processing file. data discarded load new file. users provide path output file store result, result lost. following pipeline, building triangulation ground points, get output everything lost. following pipeline triangulation stored geopackage file providing argument ofile:  can also triangulate first returns. produce meshed Digital Surface Model. can also perform triangulations pipeline. idea lasR execute tasks one pass using pipeline: Using triangulate() without stage pipeline usually useful. Typically, triangulate() employed without ofile argument intermediate step. instance, can used rasterize().","code":"pipeline = reader_las() + triangulate(filter = keep_ground()) ans = exec(pipeline, on = f) ans #> NULL pipeline = reader_las() + triangulate(filter = keep_ground(), ofile = tempgpkg()) ans = exec(pipeline, on = f) ans #> Simple feature collection with 1 feature and 0 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XYZ #> Bounding box:  xmin: 273357.2 ymin: 5274357 xmax: 273642.9 ymax: 5274643 #> z_range:       zmin: 788.9932 zmax: 814.8322 #> Projected CRS: NAD83(CSRS) / MTM zone 7 #> # A tibble: 1 × 1 #>                                                                             geom #>                                                               <MULTIPOLYGON [m]> #> 1 Z (((273500.4 5274501 808.4787, 273501.2 5274502 808.1748, 273500.4 5274502 8… par(mar = c(2, 2, 1, 1)) plot(ans, axes = T, lwd = 0.5) read = reader_las() del = triangulate(filter = keep_first(), ofile = tempgpkg()) ans = exec(read+del, on = f) read = reader_las() del1 = triangulate(filter = keep_ground(), ofile = tempfile(fileext = \".gpkg\")) del2 = triangulate(filter = keep_first(), ofile = tempfile(fileext = \".gpkg\")) pipeline = read + del1 + del2 ans = exec(pipeline, on = f)"},{"path":"/articles/tutorial.html","id":"rasterize","dir":"Articles","previous_headings":"","what":"Rasterize","title":"Tutorial","text":"rasterize() exactly users may expect even . three variations: Rasterize Delaunay triangulation. Rasterize predefined operators. operators optimized internally, making operations fast possible. Rasterize injecting user-defined R expression. equivalent pixel_metrics() package lidR. user-defined function can mapped, making extremely versatile slower. variations, users can build CHM, DTM, predictive model, anything else.","code":""},{"path":"/articles/tutorial.html","id":"rasterize---triangulation","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - triangulation","title":"Tutorial","text":"Let’s build DTM using triangulation ground points rasterize() stage. following pipeline, LAS files read, points loaded LAS file buffer, Delaunay triangulation ground points built, triangulation interpolated rasterized. default, rasterize() writes raster temporary file, result discarded. , exec() returns one SpatRaster triangulate() returns nothing (NULL). Therefore, pipeline contains two stages, one returns something.  Notice , contrary lidR package, usually high-level function names like rasterize_terrain(). Instead, lasR made low-level functions versatile also challenging use.","code":"# omitting reader_las() for the example del = triangulate(filter = keep_ground()) dtm = rasterize(1, del) pipeline = del + dtm ans = exec(pipeline, on = f) ans #> class       : SpatRaster  #> dimensions  : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file22885c93909b.tif  #> name        : file22885c93909b terra::plot(ans, col = gray.colors(25,0,1), mar = c(1, 1, 1, 3))"},{"path":"/articles/tutorial.html","id":"rasterize---internal-metrics","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - internal metrics","title":"Tutorial","text":"Internal metrics strings format attribute_function. attribute attribute point cloud z, classification, intensity. function available metrics function mean, max, sd. following exemples valid metric strings: z_max, i_mean, intensity_mean, classification_mode, z_sd. Readers can refer official documentation discover possible combinations. Let’s build two CHMs: one based highest point per pixel resolution 2 meters, second based triangulation first returns resolution 50 cm. following pipeline, using two variations rasterize(): one capable rasterizing triangulation capable rasterizing point cloud predefined operator (max interpreted z_max absence explicit attribute). output named list two SpatRaster.  simplicity package pre-installed pipelines named chm() dtm() explained .","code":"del <- triangulate(filter = keep_first()) chm1 <- rasterize(2, \"max\") chm2 <- rasterize(0.5, del) pipeline <- del + chm1 + chm2 ans <- exec(pipeline, on = f)  terra::plot(ans[[1]], mar = c(1, 1, 1, 3), col = col) terra::plot(ans[[2]], mar = c(1, 1, 1, 3), col = col)"},{"path":"/articles/tutorial.html","id":"rasterize---r-expression","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - R expression","title":"Tutorial","text":"special case covered special tutorial R-based stages","code":""},{"path":"/articles/tutorial.html","id":"rasterize---buffered","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - buffered","title":"Tutorial","text":"lasR package introduced concept buffered area-based approach enhance resolution prediction maps. However, concept covered detail tutorial. information, readers can refer dedicated article","code":""},{"path":"/articles/tutorial.html","id":"transform-with","dir":"Articles","previous_headings":"","what":"Transform with","title":"Tutorial","text":"Another way use Delaunay triangulation transform point cloud. Users can add subtract triangulation point cloud, effectively normalizing . Unlike lidR package, high-level function names like normalize_points(). Instead, lasR composed low-level functions offer versatility. Let’s normalize point cloud using triangulation ground points (meshed DTM). following example, triangulation used transform_with() modifies point cloud pipeline. triangulate() transform_with() return nothing. output NULL. convenience pipeline pre-recorded package name normalize(). transform_with() can also transform raster. presented tutorial. obtain meaningful output, necessary chain another stage. point cloud modified , discarded nothing . instance, can compute Canopy Height Model (CHM) normalized point cloud. following pipeline, first rasterization (chm1) applied normalization, second rasterization occurs transform_with(), thus applied transformed point cloud.  performing normalization, users may want write normalized point cloud disk later use. case, can append write_las() stage pipeline.","code":"del = triangulate(filter = keep_ground()) norm = transform_with(del, \"-\") pipeline = del + norm ans = exec(pipeline, on = f) ans #> NULL del = triangulate(filter = keep_ground()) norm = transform_with(del, \"-\") chm1 = rasterize(2, \"max\") chm2 = rasterize(2, \"max\") pipeline = chm1 + del + norm + chm2 ans = exec(pipeline, on = f)  col = grDevices::colorRampPalette(c(\"blue\", \"cyan2\", \"yellow\", \"red\"))(15) terra::plot(c(ans[[1]], ans[[2]]), col = col)"},{"path":"/articles/tutorial.html","id":"write-las","dir":"Articles","previous_headings":"","what":"Write LAS","title":"Tutorial","text":"write_las() can called point pipeline. writes one file per input file, using name input files added prefixes suffixes. following pipeline, read files, write ground points files named original files suffix _ground, perform triangulation entire point cloud, followed normalization. Finally, write normalized point cloud suffix _normalized. crucial include wildcard * file path; otherwise, single large file created. behavior may intentional. Let’s consider creating file merge pipeline. following example, wildcard * used names LAS/LAZ files. input files read, points sequentially written single file dataset_merged.laz, naturally forming merge pipeline.","code":"write1 = write_las(paste0(tempdir(), \"/*_ground.laz\"), filter = keep_ground()) write2 = write_las(paste0(tempdir(), \"/*_normalized.laz\"), ) del = triangulate(filter = keep_ground()) norm = transform_with(del, \"-\") pipeline =  write1 + del + norm + write2 ans = exec(pipeline, on = f) ans #>  - write_las : /tmp/RtmpRCEgXq/bcts_1_ground.laz /tmp/RtmpRCEgXq/bcts_2_ground.laz  #>  - write_las.1 : /tmp/RtmpRCEgXq/bcts_1_normalized.laz /tmp/RtmpRCEgXq/bcts_2_normalized.laz ofile = paste0(tempdir(), \"/dataset_merged.laz\") merge = reader_las() + write_las(ofile) ans = exec(merge, on = f) ans #> [1] \"/tmp/RtmpRCEgXq/dataset_merged.laz\""},{"path":"/articles/tutorial.html","id":"local-maximum","dir":"Articles","previous_headings":"","what":"Local maximum","title":"Tutorial","text":"stage works either point cloud raster. following pipeline first stage builds CHM, second stage finds local maxima point cloud second stages finds local maxima chm. lm1 lm2 expected produce relatively close results strictly identical.","code":"chm = rasterize(1, \"max\") lm1 = local_maximum(3) lm2 = local_maximum_raster(chm, 3) pipeline = chm + lm1 + lm2"},{"path":"/articles/tutorial.html","id":"tree-segmentation","dir":"Articles","previous_headings":"","what":"Tree Segmentation","title":"Tutorial","text":"section presents complex pipeline tree segmentation using local_maximum_raster() identify tree tops CHM. uses region_growing() segment trees using seeds produced local_maximum_raster(). Canopy Height Model (CHM) triangulation-based using triangulation() rasterize() first returns. CHM post-processed pit_fill(), algorithm designed enhance CHM filling pits NAs. reader may noticed seeds produced raster one used region_growing(). checked internally ensure seeds matching raster used segmenting trees. tutorial, pipeline tested one file render page faster. However, pipeline can applied number files produce continuous output, managing buffer files. Every intermediate output can exported, tutorial, export everything display outputs.","code":"del = triangulate(filter = keep_first()) chm = rasterize(0.5, del) chm2 = pit_fill(chm) seed = local_maximum_raster(chm2, 3) tree = region_growing(chm2, seed) pipeline = del + chm + chm2 +  seed + tree ans = exec(pipeline, on = f) col = grDevices::colorRampPalette(c(\"blue\", \"cyan2\", \"yellow\", \"red\"))(25) col2 = grDevices::colorRampPalette(c(\"purple\", \"blue\", \"cyan2\", \"yellow\", \"red\", \"green\"))(50) terra::plot(ans$rasterize, col = col, mar = c(1, 1, 1, 3)) terra::plot(ans$pit_fill, col = col, mar = c(1, 1, 1, 3)) terra::plot(ans$region_growing, col = col2[sample.int(50, 277, TRUE)], mar = c(1, 1, 1, 3)) plot(ans$local_maximum$geom, add = T, pch = 19, cex = 0.5)"},{"path":"/articles/tutorial.html","id":"buffer","dir":"Articles","previous_headings":"","what":"Buffer","title":"Tutorial","text":"Point clouds typically stored multiple contiguous files. avoid edge artifacts, file must loaded extra points coming neighboring files. Everything handled automatically.","code":""},{"path":"/articles/tutorial.html","id":"hulls","dir":"Articles","previous_headings":"","what":"Hulls","title":"Tutorial","text":"Delaunay triangulation defines convex polygon, represents convex hull points. However, dense point clouds, removing triangles large edges due absence points results complex structure.  hulls() algorithm computes contour mesh, producing concave hull holes:  However hulls() likely used without triangulation. case returns bounding box LAS/LAZ file read header. used triangulate(0) returns convex hull inefficient way get convex hull.","code":"del = triangulate(15, filter = keep_ground(), ofile = tempgpkg()) ans = exec(del, on = f)  par(mar = c(2, 2, 1, 1)) plot(ans, axes = T, lwd = 0.5) del = triangulate(15, filter = keep_ground()) bound = hulls(del) ans = exec(del+bound, on = f)  par(mar = c(2, 2, 1, 1)) plot(ans, axes = T, lwd = 0.5, col = \"gray\")"},{"path":"/articles/tutorial.html","id":"readers","dir":"Articles","previous_headings":"","what":"Readers","title":"Tutorial","text":"reader_las() MUST first stage pipeline even can conveniently omitted simplest form. However several readers hidden behind reader_las(): reader_las_coverage(): read files process entire point cloud. default behavior reader_las(). reader_las_rectangles(): read rectangular regions interest coverage process sequentially. reader_las_circles(): read circular regions interest coverage process sequentially. following pipeline triangulates ground points, normalizes point cloud, computes metric interest file entire coverage. file loaded buffer triangulation performed without edge artifacts. Notice use drop_buffer = TRUE expose data.frame without buffer used perform triangulation normalization. following pipeline, contrary, works exactly operates circular plots. readers allow building ground inventory pipeline, plot extraction examples","code":"my_metric_fun = function(data) { mean(data$Z) } tri <- triangulate(filter = keep_ground()) trans <- transform_with(tri) norm <- tri + trans metric <- callback(my_metric_fun, expose = \"z\", drop_buffer = TRUE) pipeline = norm + metric pipeline = reader_las_circles(xcenter, ycenter, 11.28) + pipeline"},{"path":"/articles/tutorial.html","id":"summarise","dir":"Articles","previous_headings":"","what":"Summarise","title":"Tutorial","text":"summarise() stage computes metrics interest entire point cloud, .e., points read. following example, processing four files. stage reports number points, number first returns, histograms, metrics. Like stages, output produced summarise() depends positioning pipeline. Let’s insert sampling stage (described tutorial). can see summarizes point cloud current state pipeline. summarise() can also compute metrics. case, metrics computed entire point cloud (.e., points read) chunk read (.e., file query). feature, example, allows computing metrics plot inventory.","code":"read = reader_las() summary = summarise() pipeline = read + summary ans = exec(pipeline, on = f) head(ans) #>  - npoints : 2834350  #>  - nsingle : 1233936  #>  - nwithheld : 0  #>  - nsynthetic : 0  #>  - npoints_per_return : 1981696 746460 101739 4455  #>  - npoints_per_class : 2684009 150341 pipeline = summarise() + sampling_voxel(4) + summarise() ans = exec(pipeline, on = f) print(head(ans[[1]])) #>  - npoints : 73403  #>  - nsingle : 31294  #>  - nwithheld : 0  #>  - nsynthetic : 0  #>  - npoints_per_return : 53538 15828 3569 451 16 1  #>  - npoints_per_class : 61347 8159 3897 print(head(ans[[2]])) #>  - npoints : 12745  #>  - nsingle : 5042  #>  - nwithheld : 0  #>  - nsynthetic : 0  #>  - npoints_per_return : 9415 2589 655 79 6 1  #>  - npoints_per_class : 10862 1510 373"},{"path":"/articles/tutorial.html","id":"plot-inventory","dir":"Articles","previous_headings":"","what":"Plot inventory","title":"Tutorial","text":"pipeline extracts plot inventory using shapefile non-normalized point cloud, normalizes plot transform_with(), computes metrics plot using summarise(). also writes normalized non-normalized plot separate files. means , single pass, performs extraction, normalization, saving, computation. circular plot loaded buffer perform correct triangulation, stages natively know handle buffer. means summarise() computes metrics without including buffer points write_las() write buffer points.","code":"ofiles_plot <- paste0(tempdir(), \"/plot_*.las\") ofiles_plot_norm <- paste0(tempdir(), \"/plot_*_norm.las\")  library(sf) inventory <- st_read(\"shapefile.shp\") coordinates <- st_coordinates(inventory) xcenter <- coordinates[,1] ycenter <- coordinates[,2]  read <- reader_las(xc = xcenter, yc = ycenter, r = 11.28)  tri <- triangulate(filter = keep_ground()) trans <- transform_with(tri) norm <- tri + trans metrics <- summarise(metrics = c(\"z_mean\", \"z_p95\", \"i_median\", \"count\")) write1 <- write_las(ofiles_plot) write2 <- write_las(ofiles_plot_norm)  pipeline = read + write1 + norm + write2"},{"path":"/articles/tutorial.html","id":"wildcard-usage","dir":"Articles","previous_headings":"","what":"Wildcard Usage","title":"Tutorial","text":"Usually, write_las() used wildcard ofile argument (see ) write one file per processed file. Otherwise, everything written single massive LAS file (might desired behavior). contrary, rasterize() used without wildcard write everything single raster file, also accepts wildcard write results multiple files, useful reader_las_circles() avoid one massive raster mostly empty. Compare pipeline without wildcard. Without wildcard, output single raster covers entire point cloud two patches populated pixels.  wildcard, output contains two rasters cover regions interest.","code":"ofile = paste0(tempdir(), \"/chm.tif\")   # no wildcard  x = c(885100, 885100) y = c(629200, 629600)  pipeline = reader_las(xc = x, yc = y, r = 20) + rasterize(2, \"max\", ofile = ofile) r0 = exec(pipeline, on = f)  terra::plot(r0, col = col) # covers the entire collection of files ofile = paste0(tempdir(), \"/chm_*.tif\") # wildcard  x = c(885100, 885100) y = c(629200, 629600)  pipeline = reader_las(xc = x, yc = y, r = 20) + rasterize(2, \"max\", ofile = ofile) ans = exec(pipeline, on = f)  r1 = terra::rast(ans[1]) r2 = terra::rast(ans[2]) terra::plot(r1, col = col) terra::plot(r2, col = col)"},{"path":"/articles/tutorial.html","id":"compatibility-with-lidr","dir":"Articles","previous_headings":"","what":"Compatibility with lidR","title":"Tutorial","text":"lasR depends lidR compatibility . Instead providing paths files folder possible pass LAScatalog LAS object readers. case LAScatalog, exec() respects processing options LAScatalog including chunk size, chunk buffer, progress bar display partial processing. general case, options can supplied arguments exec() functions.","code":"library(lasR) library(lidR)  pipeline = normalize() + write_las()  ctg = readLAScatalog(folder) ans = exec(pipeline, on = ctg)  las = readLAS(file) ans = exec(pipeline, on = las)"},{"path":"/articles/tutorial.html","id":"stop-pipeline-if","dir":"Articles","previous_headings":"","what":"Stop pipeline if","title":"Tutorial","text":"pipeline can long succession stages, may happen want apply entire pipeline every file. case, stop_if stage allows us conditionally stop pipeline anywhere. Let’s assume dataset 100 files pipeline reads, computes hulls, computes DTM. possible compute hulls 100 files DTM reduced region interest defined user stop_if_outside(). stop_if (currently) stage can put reader_las(). case, reading stage skipped, effectively applying pipeline subset files encompass bounding boxes defined user. Notice pipeline produces output pipeline takes longer compute files processed read anyway. thus preferable put stop_if() reader_las() specific case. Currently, one stop_if stage conditionally stops pipeline based bounding box condition, easy add options later demand.","code":"read = reader_las() hll = hulls() tri = triangulate(filter = keep_ground()) dtm = rasterize(1, tri) pipeline = read + hll + tri + dtm stopif <- stop_if_outside(880000, 620000, 885000, 630000) pipeline <- read + hll + stopif + tri + dtm pipeline <- stopif + read + hll + tri + dtm pipeline <- read + stopif + hll + tri + dtm"},{"path":"/articles/tutorial.html","id":"parallel-processing","dir":"Articles","previous_headings":"","what":"Parallel processing","title":"Tutorial","text":"topic covered dedicated article","code":""},{"path":"/articles/tutorial.html","id":"other-stages","dir":"Articles","previous_headings":"","what":"Other stages","title":"Tutorial","text":"lasR several stages mentioned tutorial. Among others: add_extrabytes() add_rgb() callback() classify_with_ivf() classify_with_csf() delete_points() geometry_features() load_raster() pit_fill() write_vpc()","code":""},{"path":"/articles/why.html","id":"rationnale-for-lasr-vs--lidr","dir":"Articles","previous_headings":"","what":"Rationnale for lasR vs. lidR","title":"Why lasR?","text":"need new package? short answer lies following graph. x-axis represents time perform three different rasterizations (CHM, DTM, density map), y-axis represents amount RAM memory used lidR lasR (details benchmark vignette). lasR intended much efficient lidR terms memory usage computation times.  second issue absence powerful pipeline engine lidR. Performing task simple extracting deriving metrics multiple inventory plots non-normalized collection files easy lidR. straightforward point cloud normalized, , users must write complex custom script. introduction real pipelines, lasR enables users complex tasks easier way (see tutorial vignette well pipeline vignette). Last least, almost decade additional experience R, C++, point cloud processing, lot feedback compared started creation lidR. simply technically capable writing lasR ten years ago!","code":""},{"path":[]},{"path":"/articles/why.html","id":"pipeline","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Pipeline","title":"Why lasR?","text":"lasR introduces versatile pipeline engine, enabling creation complex processing pipelines. Users can simultaneously create ABA compute DTM one read pass, leading significant speed-.","code":""},{"path":"/articles/why.html","id":"data-loading","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Data loading","title":"Why lasR?","text":"Unlike lidR, lasR load lidar data data.frame. designed efficient data processing, memory management C++ level. Consequently, read_las() function. Everything internally efficiently stored C++ structure keeps data compact memory. However, entry points available inject user-defined R code C++ pipeline.","code":""},{"path":"/articles/why.html","id":"dependencies","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Dependencies","title":"Why lasR?","text":"lasR 0 dependency. doesn’t even depend Rcpp. lasR use terra sf R level reading writing spatial data; instead, links GDAL. terra sf installed, output files read packages. Due absence dependency R package non-loading data R objects, also dependency rgl, resulting interactive 3D viewer like lidR.","code":""},{"path":"/articles/why.html","id":"code","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Code","title":"Why lasR?","text":"lasR written 100% C++ contains R code. utilizes source code lidR significant improvements. major improvements observed benchmark much source code rather organization code, .e., longer using data.frame, memory management C++ rather R, processing R level, pipelines, .","code":""},{"path":"/articles/why.html","id":"should-i-use-lidr-or-lasr","dir":"Articles","previous_headings":"","what":"Should I use lidR or lasR?","title":"Why lasR?","text":"question actually pretty simple answer. want explore, manipulate, test, try, retry, implement new ideas mind, use lidR. know want, want relatively common (raster metrics, DTM, CHM, tree location), especially want large coverage, use lasR.","code":""},{"path":"/articles/why.html","id":"example-1","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 1","title":"Why lasR?","text":"received 500 km² data, want CHM DTM. → Use lasR compute fast possible.","code":""},{"path":"/articles/why.html","id":"example-2","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 2","title":"Why lasR?","text":"want segment trees, explore different methods, test different parameters small plots. Maybe integrate custom step, ’s exploratory process. → Use lidR.","code":""},{"path":"/articles/why.html","id":"example-3","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 3","title":"Why lasR?","text":"want extract circular ground inventories compute metrics plot. → dataset already normalized, can use either lasR lidR; pretty much equivalent. lidR easier use; lasR little bit efficient difficult use (yet pipeline vignette contains copy-pastable code ). dataset normalized, lasR much simpler case, thanks pipeline processor allows adding normalization stage computing metrics.","code":""},{"path":"/articles/why.html","id":"example-4","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 4","title":"Why lasR?","text":"want create complex pipeline computes local shape points classify roofs wires point cloud. using shapefile, want classify water point cloud. finish, want write new classified LAS files. → Use lidR. lasR many tools. lasR lidR; much efficient less versatile fewer tools.","code":""},{"path":"/articles/why.html","id":"example-5","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 5","title":"Why lasR?","text":"want find segment trees common algorithm. Nothing fancy. want 100 km² . → Use lasR. lidR probably fail .","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jean-Romain Roussel. Author, maintainer, copyright holder. Martin Isenburg. Copyright holder.            author included LASlib LASzip libraries Benoît St-Onge. Copyright holder.            author included 'chm_prep' function Niels Lohmann. Copyright holder.            author included json parser Volodymyr Bilonenko. Copyright holder.            author included delaunator triangulation State Key Laboratory Remote Sensing Science, Institute Remote Sensing Science Engineering, Beijing Normal University. Copyright holder.            copyright holder included CSF","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Roussel J (2024). lasR: Fast Pipeable Airborne LiDAR Data Tools. R package version 0.7.2, https://github.com/r-lidar/lasR.","code":"@Manual{,   title = {lasR: Fast and Pipeable Airborne LiDAR Data Tools},   author = {Jean-Romain Roussel},   year = {2024},   note = {R package version 0.7.2},   url = {https://github.com/r-lidar/lasR}, }"},{"path":"/index.html","id":"lasr","dir":"","previous_headings":"","what":"Fast and Pipeable Airborne LiDAR Data Tools","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"R Package Fast Airborne LiDAR Data Processing lasR package (pronounce laser) intent supersede lidR package, designed much efficient lidR common tasks like production CHM, DTM, tree detection segmentation large coverages. lidR intends tool box make data exploration innovation easy. lasR another hand focuses production, optimized memory speed makes trade aspects development. 📖 Read tutorial start lasR","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"currently plan releasing lasR CRAN. lasR hosted r-universe: Users can’t rely CRAN versioning system RStudio update button get latest version lasR. loading lasR library(lasR), internal routine checks latest version prints message new version available. Updates frequent way.","code":"install.packages('lasR', repos = 'https://r-lidar.r-universe.dev') library(lasR) #> lasR 0.1.3 is now available. You are using 0.1.1 #> install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')"},{"path":"/index.html","id":"benchmark","dir":"","previous_headings":"","what":"Benchmark","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"following benchmark compares much time RAM memory takes lasR lidR produce DTM, CHM, raster two metrics derived Z intensity. test performed 120 million points stored 4 LAZ files. details benchmark vignette.","code":""},{"path":"/index.html","id":"main-differences-with-lidr","dir":"","previous_headings":"","what":"Main differences with lidR","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"Introduces concept pipelines, missing lidR, chain multiple operations point cloud optimally. written exclusively C/C++ without single line R. R code API standalone C++ software. load point cloud data.frame. point cloud stored C++ structure exposed users. 1 strong dependencies gdal. sf terra installed experience better. details corresponding vignette","code":""},{"path":"/index.html","id":"about","dir":"","previous_headings":"","what":"About","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"lasR developed Laval University.","code":""},{"path":"/index.html","id":"copyright-information","dir":"","previous_headings":"","what":"Copyright Information","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"© 2023-2024 Jean-Romain Roussel Provided GPL-3 license. © 2007-2021 Martin Isenburg - http://rapidlasso.com Provided LGPL license modified R-compliant Jean-Romain Roussel. © 2008-2023 Benoît St-Onge - Geophoton-inc/chm_prep Provided GPL-3 license. Lohmann, N. (2023). JSON Modern C++ (Version 3.11.3) [Computer software]. https://github.com/nlohmann Provided MIT license © 2018 Volodymyr Bilonenko. delfrrr/delaunator-cpp Provided MIT license © 2008-2024 Conrad Sanderson (https://conradsanderson.id.au) © 2008-2016 National ICT Australia (NICTA) © 2017-2024 Data61 / CSIRO Provided Apache license © 2017 State Key Laboratory Remote Sensing Science, Institute Remote Sensing Science Engineering, Beijing Normal University Provided Apache License W. Zhang, J. Qi, P. Wan, H. Wang, D. Xie, X. Wang, G. Yan, “Easy--Use Airborne LiDAR Data Filtering Method Based Cloth Simulation,” Remote Sens., vol. 8, . 6, p. 501, 2016.","code":""},{"path":"/reference/add_extrabytes.html","id":null,"dir":"Reference","previous_headings":"","what":"Add attributes to a LAS file — add_extrabytes","title":"Add attributes to a LAS file — add_extrabytes","text":"According LAS specifications, LAS file contains core defined attributes, XYZ coordinates, intensity, return number, , point. possible add supplementary attributes. stages adds extra bytes attribute points. Values zeroed: underlying point cloud edited support new extrabyte attribute. new attribute can populated later another stage","code":""},{"path":"/reference/add_extrabytes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add attributes to a LAS file — add_extrabytes","text":"","code":"add_extrabytes(data_type, name, description, scale = 1, offset = 0)"},{"path":"/reference/add_extrabytes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add attributes to a LAS file — add_extrabytes","text":"data_type character. data type extra bytes attribute. Can \"uchar\", \"char\", \"ushort\", \"short\", \"uint\", \"int\", \"uint64\", \"int64\", \"float\", \"double\". name character. name extra bytes attribute add file. description character. short description extra bytes attribute add file (32 characters). scale, offset numeric. scale offset data. See LAS specification.","code":""},{"path":"/reference/add_extrabytes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add attributes to a LAS file — add_extrabytes","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"/reference/add_extrabytes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add attributes to a LAS file — add_extrabytes","text":"","code":"f <- system.file(\"extdata\", \"Example.las\", package = \"lasR\") fun <- function(data) { data$RAND <- runif(nrow(data), 0, 100); return(data) } pipeline <- reader_las() +   add_extrabytes(\"float\", \"RAND\", \"Random numbers\") +   callback(fun, expose = \"xyz\") exec(pipeline, on = f) #> NULL"},{"path":"/reference/add_rgb.html","id":null,"dir":"Reference","previous_headings":"","what":"Add RGB attributes to a LAS file — add_rgb","title":"Add RGB attributes to a LAS file — add_rgb","text":"Modifies LAS format convert format RGB attributes. Values zeroed: underlying point cloud edited transformed format supports RGB. RGB can populated later another stage. point cloud already RGB, nothing happens, RGB values preserved.","code":""},{"path":"/reference/add_rgb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add RGB attributes to a LAS file — add_rgb","text":"","code":"add_rgb()"},{"path":"/reference/add_rgb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add RGB attributes to a LAS file — add_rgb","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"/reference/add_rgb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add RGB attributes to a LAS file — add_rgb","text":"","code":"f <- system.file(\"extdata\", \"Example.las\", package=\"lasR\")  pipeline <- add_rgb() + write_las() exec(pipeline, on = f) #> [1] \"/tmp/Rtmp3xX9cx/Example.las\""},{"path":"/reference/callback.html","id":null,"dir":"Reference","previous_headings":"","what":"Call a user-defined function on the point cloud — callback","title":"Call a user-defined function on the point cloud — callback","text":"Call user-defined function point cloud. function receives data.frame point cloud. first input must point cloud. function returns anything data.frame number points, output stored returned end. However, output data.frame number points, updates point cloud. function can, therefore, used modify point cloud using user-defined function. function versatile complex. comprehensive set examples can found online tutorial.","code":""},{"path":"/reference/callback.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call a user-defined function on the point cloud — callback","text":"","code":"callback(fun, expose = \"xyz\", ..., drop_buffer = FALSE, no_las_update = FALSE)"},{"path":"/reference/callback.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call a user-defined function on the point cloud — callback","text":"fun function. user-defined function takes first argument data.frame exposed point cloud attributes (see examples). expose character. Expose attributes interest save memory (see details). ... parameters function fun drop_buffer bool. false, expose point buffer. no_las_update bool. user-defined function returns data.frame, supposed update point cloud. Can disabled.","code":""},{"path":"/reference/callback.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Call a user-defined function on the point cloud — callback","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"/reference/callback.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Call a user-defined function on the point cloud — callback","text":"lasR, point cloud exposed R data.frame like lidR. stored internally C++ structure seen modified directly users using R code. callback function stage allows direct interaction point cloud copying temporarily data.frame apply user-defined function.expose: 'expose' argument specifies data actually exposed R. example, 'xyzia' means x, y, z coordinates, intensity, scan angle exposed. supported entries t - gpstime, - scan angle, - intensity, n - number returns, r - return number, c - classification, s - synthetic flag, k - keypoint flag, w - withheld flag, o - overlap flag (format 6+), u - user data, p - point source ID, e - edge flight line flag, d - direction scan flag, R - red channel RGB color, G - green channel RGB color, B - blue channel RGB color, N - near-infrared channel, C - scanner channel (format 6+) Also numbers 1 9 extra bytes data numbers 1 9. 'E' enables extra bytes loaded.  '*' wildcard enables everything exposed LAS file.","code":""},{"path":[]},{"path":"/reference/callback.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Call a user-defined function on the point cloud — callback","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package = \"lasR\")  # There is no function in lasR to read the data in R. Let's create one read_las <- function(f) {   load <- function(data) { return(data) }   read <- reader_las()   call <- callback(load, expose = \"xyzi\", no_las_update = TRUE)   return (exec(read + call, on = f)) } las <- read_las(f) head(las) #>          X       Y        Z Intensity #> 1 273357.1 5274360 806.5340      1340 #> 2 273357.2 5274359 806.5635       728 #> 3 273357.2 5274358 806.0248      1369 #> 4 273357.2 5274510 809.6303       589 #> 5 273357.2 5274509 809.3880      1302 #> 6 273357.2 5274508 809.4847       123  convert_intensity_in_range <- function(data, min, max) {   i <- data$Intensity   i <- ((i - min(i)) / (max(i) - min(i))) * (max - min) + min   i[i < min] <- min   i[i > max] <- max   data$Intensity <- as.integer(i)   return(data) }  read <- reader_las() call <- callback(convert_intensity_in_range, expose = \"i\", min = 0, max = 255) write <- write_las() pipeline <- read + call + write ans <- exec(pipeline, on = f)  las <- read_las(ans) head(las) #>          X       Y        Z Intensity #> 1 273357.1 5274360 806.5340       137 #> 2 273357.2 5274359 806.5635        72 #> 3 273357.2 5274358 806.0248       140 #> 4 273357.2 5274510 809.6303        57 #> 5 273357.2 5274509 809.3880       133 #> 6 273357.2 5274508 809.4847         7"},{"path":"/reference/chm.html","id":null,"dir":"Reference","previous_headings":"","what":"Canopy Height Model — chm","title":"Canopy Height Model — chm","text":"Create Canopy Height Model using triangulate rasterize.","code":""},{"path":"/reference/chm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Canopy Height Model — chm","text":"","code":"chm(res = 1, tin = FALSE, ofile = tempfile(fileext = \".tif\"))"},{"path":"/reference/chm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Canopy Height Model — chm","text":"res numeric. resolution raster. tin bool. default CHM point--raster based methods .e. pixel assigned elevation highest point. tin = TRUE CHM triangulation-based model. first returns triangulated interpolated. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":[]},{"path":"/reference/chm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Canopy Height Model — chm","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline <- reader_las() + chm() exec(pipeline, on = f) #> class       : SpatRaster  #> dimensions  : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file1e9c65149d5f.tif  #> name        : max"},{"path":"/reference/classify_with_csf.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify ground points — classify_with_csf","title":"Classify ground points — classify_with_csf","text":"Classify points using Cloth Simulation Filter Zhang et al. (2016) (see references) relies authors' original source code. point cloud already ground points, classification original ground point set zero. stage modifies point cloud pipeline produce output.","code":""},{"path":"/reference/classify_with_csf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify ground points — classify_with_csf","text":"","code":"classify_with_csf(   slope_smooth = FALSE,   class_threshold = 0.5,   cloth_resolution = 0.5,   rigidness = 1L,   iterations = 500L,   time_step = 0.65,   class = 2L )"},{"path":"/reference/classify_with_csf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify ground points — classify_with_csf","text":"slope_smooth logical. steep slopes exist, set parameter TRUE reduce errors post-processing. class_threshold scalar. distance simulated cloth classify point cloud ground non-ground. default 0.5. cloth_resolution scalar. distance particles cloth. usually set average distance points point cloud. default value 0.5. rigidness integer. rigidness cloth. 1 stands soft (fit rugged terrain), 2 stands medium, 3 stands hard cloth (flat terrain). default 1. iterations integer. Maximum iterations simulating cloth. default value 500. Usually, need change value. time_step scalar. Time step simulating cloth gravity. default value 0.65. Usually, need change value. suitable cases. class integer. classification attribute points. Usually 2 ground points.","code":""},{"path":"/reference/classify_with_csf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classify ground points — classify_with_csf","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"/reference/classify_with_csf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Classify ground points — classify_with_csf","text":"W. Zhang, J. Qi*, P. Wan, H. Wang, D. Xie, X. Wang, G. Yan, “Easy--Use Airborne LiDAR Data Filtering Method Based Cloth Simulation,” Remote Sens., vol. 8, . 6, p. 501, 2016. (http://www.mdpi.com/2072-4292/8/6/501/htm)","code":""},{"path":"/reference/classify_with_csf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classify ground points — classify_with_csf","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline = classify_with_csf(TRUE, 1 ,1, time_step = 1) + write_las() ans = exec(pipeline, on = f, progress = TRUE) #> Read files headers: [==========] 100% (1 threads)                     Overall: [          ] 0% (1 threads) | : no progress                      Overall: [          ] 0% (1 threads) | read_las: [          ] 0% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 1% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 2% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 3% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 4% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 5% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 6% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 7% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 8% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 9% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 10% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 11% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 12% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 13% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 14% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 15% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 16% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 17% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 18% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 19% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 20% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 21% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 22% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 23% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 24% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 25% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 26% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 27% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 28% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 29% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 30% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 31% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 32% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 33% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 34% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 35% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 36% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 37% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 38% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 39% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 40% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 41% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 42% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 43% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 44% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 45% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 46% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 47% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 48% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 49% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 50% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 51% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 52% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 53% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 54% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 55% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 56% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 57% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 58% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 59% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 60% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 61% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 62% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 63% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 64% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 65% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 66% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 67% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 68% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 69% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 70% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 71% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 72% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 73% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 74% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 75% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 76% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 77% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 78% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 79% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 80% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 81% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 82% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 83% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 84% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 85% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 86% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 87% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 88% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 89% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 90% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 91% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 92% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 93% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 94% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 95% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 96% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 97% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 98% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 99% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==========] 100% (1 threads)                     Overall: [          ] 0% (1 threads) | CSF: no progress                      Overall: [          ] 0% (1 threads) | Write LAS: [          ] 0% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 1% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 2% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 3% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 4% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 5% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 6% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 7% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 8% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 9% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 10% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 11% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 12% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 13% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 14% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 15% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 16% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 17% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 18% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 19% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 20% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 21% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 22% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 23% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 24% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 25% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 26% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 27% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 28% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 29% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 30% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 31% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 32% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 33% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 34% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 35% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 36% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 37% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 38% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 39% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 40% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 41% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 42% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 43% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 44% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 45% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 46% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 47% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 48% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 49% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 50% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 51% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 52% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 53% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 54% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 55% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 56% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 57% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 58% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 59% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 60% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 61% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 62% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 63% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 64% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 65% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 66% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 67% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 68% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 69% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 70% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 71% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 72% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 73% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 74% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 75% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 76% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 77% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 78% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 79% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 80% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 81% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 82% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 83% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 84% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 85% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 86% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 87% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 88% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 89% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 90% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 91% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 92% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 93% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 94% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 95% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 96% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 97% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 98% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 99% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==========] 100% (1 threads)                     Overall: [==========] 100% (1 threads) |                      Overall: [==========] 100% (1 threads)"},{"path":"/reference/classify_with_ivf.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify noise points — classify_with_ivf","title":"Classify noise points — classify_with_ivf","text":"Classify points using Isolated Voxel Filter. stage identifies points points surrounding 3 x 3 x 3 = 27 voxels edits points assign target classification. Used class 18, classifies points noise. stage modifies point cloud pipeline produce output.","code":""},{"path":"/reference/classify_with_ivf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify noise points — classify_with_ivf","text":"","code":"classify_with_ivf(res = 5, n = 6L, class = 18L)"},{"path":"/reference/classify_with_ivf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify noise points — classify_with_ivf","text":"res numeric. Resolution voxels. n integer. maximal number 'points' 27 voxels. class integer. class assign points match condition.","code":""},{"path":"/reference/classify_with_ivf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classify noise points — classify_with_ivf","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"/reference/delete_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter and delete points — delete_points","title":"Filter and delete points — delete_points","text":"Remove points point cloud. stage modifies point cloud pipeline produce output.","code":""},{"path":"/reference/delete_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter and delete points — delete_points","text":"","code":"delete_points(filter = \"\")"},{"path":"/reference/delete_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter and delete points — delete_points","text":"filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given stage filter applied, points meet criteria processed. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters.","code":""},{"path":"/reference/delete_points.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter and delete points — delete_points","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"/reference/delete_points.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter and delete points — delete_points","text":"","code":"f <- system.file(\"extdata\", \"Megaplot.las\", package=\"lasR\") read <- reader_las() filter <- delete_points(keep_z_above(4))  pipeline <- read + summarise() + filter + summarise() exec(pipeline, on = f) #> $summary #> $summary$npoints #> [1] 81590 #>  #> $summary$nsingle #> [1] 34337 #>  #> $summary$nwithheld #> [1] 0 #>  #> $summary$nsynthetic #> [1] 0 #>  #> $summary$npoints_per_return #>     1     2     3     4  #> 55756 21493  3999   342  #>  #> $summary$npoints_per_class #>     1     2  #> 74201  7389  #>  #> $summary$z_histogram #>     0     2     4     6     8    10    12    14    16    18    20    22    24  #> 11031  1256  2476  3994  4295  4898  5943  7115  8557  9934 10353  7520  3156  #>    26    28    30  #>   955   103     4  #>  #> $summary$i_histogram #>     0    50   100   150   200   250   300   350   400   450   500   550   600  #> 43359 37956   204    42    16     6     2     0     1     1     2     0     1  #>  #> $summary$crs #> [1] \"PROJCRS[\\\"NAD83 / UTM zone 17N\\\",BASEGEOGCRS[\\\"NAD83\\\",DATUM[\\\"North American Datum 1983\\\",ELLIPSOID[\\\"GRS 1980\\\",6378137,298.257222101,LENGTHUNIT[\\\"metre\\\",1]]],PRIMEM[\\\"Greenwich\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],ID[\\\"EPSG\\\",4269]],CONVERSION[\\\"UTM zone 17N\\\",METHOD[\\\"Transverse Mercator\\\",ID[\\\"EPSG\\\",9807]],PARAMETER[\\\"Latitude of natural origin\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8801]],PARAMETER[\\\"Longitude of natural origin\\\",-81,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8802]],PARAMETER[\\\"Scale factor at natural origin\\\",0.9996,SCALEUNIT[\\\"unity\\\",1],ID[\\\"EPSG\\\",8805]],PARAMETER[\\\"False easting\\\",500000,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8806]],PARAMETER[\\\"False northing\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8807]]],CS[Cartesian,2],AXIS[\\\"(E)\\\",east,ORDER[1],LENGTHUNIT[\\\"metre\\\",1]],AXIS[\\\"(N)\\\",north,ORDER[2],LENGTHUNIT[\\\"metre\\\",1]],USAGE[SCOPE[\\\"Engineering survey, topographic mapping.\\\"],AREA[\\\"North America - between 84°W and 78°W - onshore and offshore. Canada - Nunavut; Ontario; Quebec. United States (USA) - Florida; Georgia; Kentucky; Maryland; Michigan; New York; North Carolina; Ohio; Pennsylvania; South Carolina; Tennessee; Virginia; West Virginia.\\\"],BBOX[23.81,-84,84,-78]],ID[\\\"EPSG\\\",26917]]\" #>  #> $summary$epsg #> [1] 26917 #>  #>  #> $summary.1 #> $summary.1$npoints #> [1] 68328 #>  #> $summary.1$nsingle #> [1] 26693 #>  #> $summary.1$nwithheld #> [1] 0 #>  #> $summary.1$nsynthetic #> [1] 0 #>  #> $summary.1$npoints_per_return #>     1     2     3     4  #> 47919 18297  2058    54  #>  #> $summary.1$npoints_per_class #>     1  #> 68328  #>  #> $summary.1$z_histogram #>     4     6     8    10    12    14    16    18    20    22    24    26    28  #>  1501  3994  4295  4898  5943  7115  8557  9934 10353  7520  3156   955   103  #>    30  #>     4  #>  #> $summary.1$i_histogram #>     0    50  #> 34738 33590  #>  #> $summary.1$crs #> [1] \"PROJCRS[\\\"NAD83 / UTM zone 17N\\\",BASEGEOGCRS[\\\"NAD83\\\",DATUM[\\\"North American Datum 1983\\\",ELLIPSOID[\\\"GRS 1980\\\",6378137,298.257222101,LENGTHUNIT[\\\"metre\\\",1]]],PRIMEM[\\\"Greenwich\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],ID[\\\"EPSG\\\",4269]],CONVERSION[\\\"UTM zone 17N\\\",METHOD[\\\"Transverse Mercator\\\",ID[\\\"EPSG\\\",9807]],PARAMETER[\\\"Latitude of natural origin\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8801]],PARAMETER[\\\"Longitude of natural origin\\\",-81,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8802]],PARAMETER[\\\"Scale factor at natural origin\\\",0.9996,SCALEUNIT[\\\"unity\\\",1],ID[\\\"EPSG\\\",8805]],PARAMETER[\\\"False easting\\\",500000,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8806]],PARAMETER[\\\"False northing\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8807]]],CS[Cartesian,2],AXIS[\\\"(E)\\\",east,ORDER[1],LENGTHUNIT[\\\"metre\\\",1]],AXIS[\\\"(N)\\\",north,ORDER[2],LENGTHUNIT[\\\"metre\\\",1]],USAGE[SCOPE[\\\"Engineering survey, topographic mapping.\\\"],AREA[\\\"North America - between 84°W and 78°W - onshore and offshore. Canada - Nunavut; Ontario; Quebec. United States (USA) - Florida; Georgia; Kentucky; Maryland; Michigan; New York; North Carolina; Ohio; Pennsylvania; South Carolina; Tennessee; Virginia; West Virginia.\\\"],BBOX[23.81,-84,84,-78]],ID[\\\"EPSG\\\",26917]]\" #>  #> $summary.1$epsg #> [1] 26917 #>  #>"},{"path":"/reference/dtm.html","id":null,"dir":"Reference","previous_headings":"","what":"Digital Terrain Model — dtm","title":"Digital Terrain Model — dtm","text":"Create Digital Terrain Model using triangulate rasterize.","code":""},{"path":"/reference/dtm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Digital Terrain Model — dtm","text":"","code":"dtm(res = 1, add_class = NULL, ofile = temptif())"},{"path":"/reference/dtm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Digital Terrain Model — dtm","text":"res numeric. resolution raster. add_class integer. default triangulates using ground points (class 2). possible provide additional classes 9 water. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":[]},{"path":"/reference/dtm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Digital Terrain Model — dtm","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline <- reader_las() + dtm() exec(pipeline, on = f) #> class       : SpatRaster  #> dimensions  : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file1e9c704eef01.tif  #> name        : file1e9c704eef01"},{"path":"/reference/exec.html","id":null,"dir":"Reference","previous_headings":"","what":"Process the pipeline — exec","title":"Process the pipeline — exec","text":"Process pipeline. Every functions package nothing. function must called pipeline order actually process point-cloud. process parallel using multiple cores, refer multithreading page.","code":""},{"path":"/reference/exec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process the pipeline — exec","text":"","code":"exec(pipeline, on, with = NULL, ...)"},{"path":"/reference/exec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process the pipeline — exec","text":"pipeline pipeline. serie stages called order Can paths files use, path folder files stored, path virtual point cloud file data.frame containing point cloud. supports also LAScatalog LAS objects lidR. list. list options control pipeline executed. includes options control parallel processing, progress bar display, tile buffering . See set_exec_options details available options. ... processing options can explicitly named passed outside argument. See set_exec_options","code":""},{"path":[]},{"path":"/reference/exec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process the pipeline — exec","text":"","code":"if (FALSE) { f <- paste0(system.file(package=\"lasR\"), \"/extdata/bcts/\") f <- list.files(f, pattern = \"(?i)\\\\.la(s|z)$\", full.names = TRUE)  read <- reader_las() tri <- triangulate(15) dtm <- rasterize(5, tri) lmf <- local_maximum(5) met <- rasterize(2, \"imean\") pipeline <- read + tri + dtm + lmf + met ans <- exec(pipeline, on = f, with = list(progress = TRUE)) }"},{"path":"/reference/filters.html","id":null,"dir":"Reference","previous_headings":"","what":"Point filters — filters","title":"Point filters — filters","text":"lasR uses LASlib/LASzip, library developed Martin Isenburg read write LAS/LAZ files. Thus, flags available LAStools also available lasR. Filters strings put filter arguments lasR algorithms. list available strings accessible filter_usage. convenience, useful filters associated function returns corresponding string.","code":""},{"path":"/reference/filters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Point filters — filters","text":"","code":"keep_class(x)  drop_class(x)  keep_first()  drop_first()  keep_ground()  drop_ground()  keep_noise()  drop_noise()  keep_z_above(x)  drop_z_above(x)  keep_z_below(x)  drop_z_below(x)  drop_duplicates()  filter_usage()  # S3 method for laslibfilter print(x, ...)  # S3 method for laslibfilter +(e1, e2)"},{"path":"/reference/filters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Point filters — filters","text":"x numeric integer function filter used. ... Unused. e1, e2 lasR objects.","code":""},{"path":"/reference/filters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Point filters — filters","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") filter_usage() #> Filter points based on their coordinates. #>   -keep_tile 631000 4834000 1000 (ll_x ll_y size) #>   -keep_circle 630250.00 4834750.00 100 (x y radius) #>   -keep_xy 630000 4834000 631000 4836000 (min_x min_y max_x max_y) #>   -drop_xy 630000 4834000 631000 4836000 (min_x min_y max_x max_y) #>   -keep_x 631500.50 631501.00 (min_x max_x) #>   -drop_x 631500.50 631501.00 (min_x max_x) #>   -drop_x_below 630000.50 (min_x) #>   -drop_x_above 630500.50 (max_x) #>   -keep_y 4834500.25 4834550.25 (min_y max_y) #>   -drop_y 4834500.25 4834550.25 (min_y max_y) #>   -drop_y_below 4834500.25 (min_y) #>   -drop_y_above 4836000.75 (max_y) #>   -keep_z 11.125 130.725 (min_z max_z) #>   -drop_z 11.125 130.725 (min_z max_z) #>   -drop_z_below 11.125 (min_z) #>   -drop_z_above 130.725 (max_z) #>   -keep_xyz 620000 4830000 100 621000 4831000 200 (min_x min_y min_z max_x max_y max_z) #>   -drop_xyz 620000 4830000 100 621000 4831000 200 (min_x min_y min_z max_x max_y max_z) #>   -drop_duplicates #> Filter points based on their return numbering. #>   -keep_first -first_only -drop_first #>   -keep_last -last_only -drop_last #>   -keep_second_last -drop_second_last #>   -keep_first_of_many -keep_last_of_many #>   -drop_first_of_many -drop_last_of_many #>   -keep_middle -drop_middle #>   -keep_return 1 2 3 #>   -drop_return 3 4 #>   -keep_single -drop_single #>   -keep_double -drop_double #>   -keep_triple -drop_triple #>   -keep_quadruple -drop_quadruple #>   -keep_number_of_returns 5 #>   -drop_number_of_returns 0 #> Filter points based on the scanline flags. #>   -drop_scan_direction 0 #>   -keep_scan_direction_change #>   -keep_edge_of_flight_line #> Filter points based on their intensity. #>   -keep_intensity 20 380 #>   -drop_intensity_below 20 #>   -drop_intensity_above 380 #>   -drop_intensity_between 4000 5000 #> Filter points based on classifications or flags. #>   -keep_class 1 3 7 #>   -drop_class 4 2 #>   -keep_extended_class 43 #>   -drop_extended_class 129 135 #>   -drop_synthetic -keep_synthetic #>   -drop_keypoint -keep_keypoint #>   -drop_withheld -keep_withheld #>   -drop_overlap -keep_overlap #> Filter points based on their user data. #>   -keep_user_data 1 #>   -drop_user_data 255 #>   -keep_user_data_below 50 #>   -keep_user_data_above 150 #>   -keep_user_data_between 10 20 #>   -drop_user_data_below 1 #>   -drop_user_data_above 100 #>   -drop_user_data_between 10 40 #> Filter points based on their point source ID. #>   -keep_point_source 3 #>   -keep_point_source_between 2 6 #>   -drop_point_source 27 #>   -drop_point_source_below 6 #>   -drop_point_source_above 15 #>   -drop_point_source_between 17 21 #> Filter points based on their scan angle. #>   -keep_scan_angle -15 15 #>   -drop_abs_scan_angle_above 15 #>   -drop_abs_scan_angle_below 1 #>   -drop_scan_angle_below -15 #>   -drop_scan_angle_above 15 #>   -drop_scan_angle_between -25 -23 #> Filter points based on their gps time. #>   -keep_gps_time 11.125 130.725 #>   -drop_gps_time_below 11.125 #>   -drop_gps_time_above 130.725 #>   -drop_gps_time_between 22.0 48.0 #> Filter points based on their RGB/CIR/NIR channels. #>   -keep_RGB_red 1 1 #>   -drop_RGB_red 5000 20000 #>   -keep_RGB_green 30 100 #>   -drop_RGB_green 2000 10000 #>   -keep_RGB_blue 0 0 #>   -keep_RGB_nir 64 127 #>   -keep_RGB_greenness 200 65535 #>   -keep_NDVI 0.2 0.7 -keep_NDVI_from_CIR -0.1 0.5 #>   -keep_NDVI_intensity_is_NIR 0.4 0.8 -keep_NDVI_green_is_NIR -0.2 0.2 #> Filter points based on their wavepacket. #>   -keep_wavepacket 0 #>   -drop_wavepacket 3 #> Filter points based on extra attributes. #>   -keep_attribute_above 0 5.0 #>   -drop_attribute_below 1 1.5 #> Filter points with simple thinning. #>   -keep_every_nth 2 -drop_every_nth 3 #>   -keep_random_fraction 0.1 #>   -keep_random_fraction 0.1 4711 #>   -thin_with_grid 1.0 #>   -thin_pulses_with_time 0.0001 #>   -thin_points_with_time 0.000001 #> Boolean combination of filters. #>   -filter_and gnd = keep_class(c(2,9)) reader_las(gnd) #>  ----------- #> reader_las (uid:5541) #>   filter : -keep_class 2 9  #>   output :   #> ----------- triangulate(filter = keep_ground()) #>  ----------- #> triangulate (uid:38ec) #>   max_edge : 0  #>   filter : -keep_class 2  #>   output :   #>   use_attribute : Z  #> ----------- rasterize(1, \"max\", filter = \"-drop_z_below 5\") #>  ----------- #> rasterize (uid:6b06) #>   res : 1  #>   window : 1  #>   method : max  #>   filter : -drop_z_below 5  #>   output : /tmp/Rtmp3xX9cx/file1e9c36ada537.tif  #> -----------"},{"path":"/reference/geometry_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute pointwise geometry features — geometry_features","title":"Compute pointwise geometry features — geometry_features","text":"Compute pointwise geometry features based local neighborhood. feature added extrabyte attribute. names extrabytes attributes (recorded) coeff00, coeff01, coeff02 , lambda1, lambda2, lambda3, anisotropy, planarity, sphericity, linearity, omnivariance, curvature, eigensum, angle, normalX, normalY, normalZ (recorded order). total 23 attributes can added. strongly discouraged use . features recorded single precision floating points yet computing triple size point cloud. stage modifies point cloud pipeline produce output.","code":""},{"path":"/reference/geometry_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute pointwise geometry features — geometry_features","text":"","code":"geometry_features(k, r, features = \"\")"},{"path":"/reference/geometry_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute pointwise geometry features — geometry_features","text":"k, r integer numeric respectively k-nearest neighbours radius neighborhood sphere. k given r missing, computes knn, r given k missing computes sphere neighborhood, k r given computes knn limit search distance. features String. Geometric feature export. feature added extrabyte attribute. Use 'C' 9 principal component coefficients, 'E' 3 eigenvalues covariance matrix, '' anisotropy, 'p' planarity, 's' sphericity, 'l' linearity, 'o' omnivariance, 'c' curvature, 'e' sum eigenvalues, '' angle (inclination degrees relative azimuth), 'n' 3 components normal vector. Notice uppercase labeled components allow computing lowercase labeled components. Default \"\". case, singular value decomposition computed serves purpose. order flags matter features recorded order mentioned .","code":""},{"path":"/reference/geometry_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute pointwise geometry features — geometry_features","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"/reference/geometry_features.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute pointwise geometry features — geometry_features","text":"Hackel, T., Wegner, J. D., & Schindler, K. (2016). Contour detection unstructured 3D point clouds. Proceedings IEEE conference computer vision pattern recognition (pp. 1610-1618).","code":""},{"path":"/reference/geometry_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute pointwise geometry features — geometry_features","text":"","code":"f <- system.file(\"extdata\", \"Example.las\", package = \"lasR\") pipeline <- geometry_features(8, features = \"pi\") + write_las() ans <- exec(pipeline, on = f)"},{"path":"/reference/hulls.html","id":null,"dir":"Reference","previous_headings":"","what":"Contour of a point cloud — hulls","title":"Contour of a point cloud — hulls","text":"stage uses Delaunay triangulation computes contour. contour strict Delaunay triangulation convex hull, lasR, triangulation max_edge argument. Thus, contour might convex hull holes. Used without triangulation returns bouding box points.","code":""},{"path":"/reference/hulls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Contour of a point cloud — hulls","text":"","code":"hulls(mesh = NULL, ofile = tempgpkg())"},{"path":"/reference/hulls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Contour of a point cloud — hulls","text":"mesh NULL LASRalgorithm. triangulate stage. NULL take bounding box header file. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":"/reference/hulls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Contour of a point cloud — hulls","text":"stage produces vector. path provided `ofile` expected `.gpkg` format supported GDAL. Vector stages may produce geometries Z coordinates. Thus, discouraged store formats 3D support, shapefiles.","code":""},{"path":[]},{"path":"/reference/hulls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Contour of a point cloud — hulls","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package = \"lasR\") read <- reader_las() tri <- triangulate(20, filter = keep_ground()) contour <- hulls(tri) pipeline <- read + tri + contour ans <- exec(pipeline, on = f) plot(ans)"},{"path":"/reference/lasR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"lasR: airborne LiDAR for forestry applications — lasR-package","title":"lasR: airborne LiDAR for forestry applications — lasR-package","text":"lasR provides set tools process efficiently airborne LiDAR data forestry contexts. package works .las .laz files. toolbox includes algorithms DSM, CHM, DTM, ABA, normalisation, tree detection, tree segmentation, tree delineation, colourization, validation tools, well processing engine process broad LiDAR coverage split many files efficiently.","code":""},{"path":[]},{"path":"/reference/lasR-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"lasR: airborne LiDAR for forestry applications — lasR-package","text":"Maintainer: Jean-Romain Roussel jean-romain.roussel.1@ulaval.ca [copyright holder] contributors: Martin Isenburg (author included LASlib LASzip libraries) [copyright holder] Benoît St-Onge (author included 'chm_prep' function) [copyright holder] Niels Lohmann (author included json parser) [copyright holder] Volodymyr Bilonenko (author included delaunator triangulation) [copyright holder] State Key Laboratory Remote Sensing Science, Institute Remote Sensing Science Engineering, Beijing Normal University (copyright holder included CSF) [copyright holder]","code":""},{"path":"/reference/load_raster.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a raster for later use — load_raster","title":"Load a raster for later use — load_raster","text":"Load raster disk file later use. example, load DTM feed transform_with stage load CHM feed pit_fill stage. raster never loaded entirely. Internally, chunks corresponding currently processed point cloud loaded. careful: internally, raster read float matter original datatype.","code":""},{"path":"/reference/load_raster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a raster for later use — load_raster","text":"","code":"load_raster(file, band = 1L)"},{"path":"/reference/load_raster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a raster for later use — load_raster","text":"file character. Path raster file. band integer. band load. reads loads single band.","code":""},{"path":"/reference/load_raster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a raster for later use — load_raster","text":"","code":"r <- system.file(\"extdata/bcts\", \"bcts_dsm_5m.tif\", package = \"lasR\") f <- paste0(system.file(package = \"lasR\"), \"/extdata/bcts/\") f <- list.files(f, pattern = \"(?i)\\\\.la(s|z)$\", full.names = TRUE)  # In the following pipeline, neither load_raster nor pit_fill process any points. # The internal engine is capable of knowing that, and the LAS files won't actually be # read. Yet the raster r will be processed by chunk following the LAS file pattern. rr <- load_raster(r) pipeline <- rr + pit_fill(rr) ans <- exec(pipeline, on = f, verbose = FALSE)"},{"path":"/reference/local_maximum.html","id":null,"dir":"Reference","previous_headings":"","what":"Local Maximum — local_maximum","title":"Local Maximum — local_maximum","text":"Local Maximum stage identifies points locally maximum. window size fixed circular. stage modify point cloud. produces derived product vector format. function local_maximum_raster applies raster instead point cloud","code":""},{"path":"/reference/local_maximum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local Maximum — local_maximum","text":"","code":"local_maximum(   ws,   min_height = 2,   filter = \"\",   ofile = tempgpkg(),   use_attribute = \"Z\",   record_attributes = FALSE )  local_maximum_raster(   raster,   ws,   min_height = 2,   filter = \"\",   ofile = tempgpkg() )"},{"path":"/reference/local_maximum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local Maximum — local_maximum","text":"ws numeric. Diameter moving window used detect local maxima units input data (usually meters). min_height numeric. Minimum height local maximum. Threshold point local maximum. Default 2. filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given stage filter applied, points meet criteria processed. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage. use_attribute character. default local maximum performed coordinate Z. Can also name extra bytes attribute 'HAG' exists. Can also 'Intensity' probably use case one. record_attributes coordinates XYZ points corresponding local maxima recorded. also possible record attributes theses points intensity, return number, scan angle . raster LASRalgorithm. stage produces raster.","code":""},{"path":"/reference/local_maximum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local Maximum — local_maximum","text":"stage produces vector. path provided `ofile` expected `.gpkg` format supported GDAL. Vector stages may produce geometries Z coordinates. Thus, discouraged store formats 3D support, shapefiles.","code":""},{"path":"/reference/local_maximum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local Maximum — local_maximum","text":"","code":"f <- system.file(\"extdata\", \"MixedConifer.las\", package = \"lasR\") read <- reader_las() lmf <- local_maximum(5) ans <- exec(read + lmf, on = f) ans #> Simple feature collection with 177 features and 0 fields #> Geometry type: POINT #> Dimension:     XYZ #> Bounding box:  xmin: 481260 ymin: 3812921 xmax: 481349.8 ymax: 3813011 #> z_range:       zmin: 2.42 zmax: 32.07 #> Projected CRS: NAD83 / UTM zone 12N #> # A tibble: 177 × 1 #>                          geom #>                   <POINT [m]> #>  1 Z (481309.9 3812944 22.55) #>  2    Z (481294.7 3813011 16) #>  3 Z (481307.2 3813000 27.09) #>  4 Z (481281.9 3813003 26.95) #>  5 Z (481278.4 3813002 23.58) #>  6 Z (481265.3 3812996 19.75) #>  7 Z (481302.9 3812929 25.65) #>  8 Z (481261.8 3812999 18.89) #>  9 Z (481302.9 3812969 22.97) #> 10   Z (481302 3812947 18.58) #> # ℹ 167 more rows  chm <- rasterize(1, \"max\") lmf <- local_maximum_raster(chm, 5) ans <- exec(read + chm + lmf, on = f) # terra::plot(ans$rasterize) # plot(ans$local_maximum, add = T, pch = 19)"},{"path":"/reference/metric_engine.html","id":null,"dir":"Reference","previous_headings":"","what":"Metric engine — metric_engine","title":"Metric engine — metric_engine","text":"metric engine internal tool allow derive metric set points parsing string. used rasterize, summarise well functions. string composed two parts separated underscore. first part attribute metric must computed (e.g., z, intensity, classification). second part name metric (e.g., mean, sd, cv). string thus typically looks like \"z_max\", \"intensity_min\", \"z_mean\", \"classification_mode\". details see sections 'Attribute' 'Metrics' respectively.","code":""},{"path":"/reference/metric_engine.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Metric engine — metric_engine","text":"careful: engine supports combination attribute_metric strings. computable, meaningful. example, c_mode makes sense z_mode. Also, metrics computed 32-bit floating point accuracy, x_mean y_sum might slightly inaccurate, anyway, metrics supposed useful.","code":""},{"path":"/reference/metric_engine.html","id":"attribute","dir":"Reference","previous_headings":"","what":"Attribute","title":"Metric engine — metric_engine","text":"available attributes accessible via single letter via lowercase name: t - gpstime, - angle, - intensity, n - numberofreturns, r - returnnumber, c - classification, s - synthetic, k - keypoint, w - withheld, o - overlap (format 6+), u - userdata, p - pointsourceid, e - edgeofflightline, d - scandirectionflag, R - red, G - green, B - blue, N - nir.careful typos: attributes non failing features. attribute exist NaN returned. Thus intesity_mean return NaN rather failing.","code":""},{"path":"/reference/metric_engine.html","id":"metrics","dir":"Reference","previous_headings":"","what":"Metrics","title":"Metric engine — metric_engine","text":"available metric names : count, max, min, mean, median, sum, sd, cv, pX (percentile), aboveX, mode. metrics attribute + name + parameter X, pX X can substituted number. , z_pX represents Xth percentile; instance, z_p95 signifies 95th percentile z. z_aboveX corresponds percentage points X (sometimes called canopy cover). possible call metric without name attribute. case, z default. e.g. mean equals z_mean","code":""},{"path":"/reference/metric_engine.html","id":"extrabytes-attribute","dir":"Reference","previous_headings":"","what":"Extrabytes attribute","title":"Metric engine — metric_engine","text":"core attributes x, y, z, classification, intensity, . point clouds extra attributes called extrabytes attributes. case, metrics can derived way using names extra attributes. careful typos. attributes checked internally extrabytes attributes. example, user requests: ntensity_mean, typo name extra attribute. extrabytes never failing, ntensity_mean return NaN rather error.","code":""},{"path":"/reference/metric_engine.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Metric engine — metric_engine","text":"","code":"metrics = c(\"z_max\", \"i_min\", \"r_mean\", \"n_median\", \"z_sd\", \"c_sd\", \"t_cv\", \"u_sum\", \"z_p95\") f <- system.file(\"extdata\", \"Example.las\", package=\"lasR\") p <- summarise(metrics = metrics) r <- rasterize(5, operators = metrics) ans <- exec(p+r, on = f) ans$summary$metrics #>        c_sd i_min n_median   r_mean         t_cv u_sum   z_max    z_p95 #> 1 0.3051286    27        1 1.133333 4.466148e-07   960 978.345 978.2653 #>       z_sd #> 1 1.459199 ans$rasterize #> class       : SpatRaster  #> dimensions  : 1, 4, 9  (nrow, ncol, nlyr) #> resolution  : 5, 5  (x, y) #> extent      : 339000, 339020, 5248000, 5248005  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83 / UTM zone 17N (EPSG:26917)  #> source      : file1e9c66bc1001.tif  #> names       : z_max, i_min, r_mean, n_median, z_sd, c_sd, ..."},{"path":"/reference/multithreading.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel processing tools — multithreading","title":"Parallel processing tools — multithreading","text":"lasR uses OpenMP paralellize internal C++ code. set_parallel_strategy() globally changes strategy used process point clouds. sequential(), concurrent_files(), concurrent_points(), nested() functions assign parallelization strategy (see Details). has_omp_support() tells lasR package compiled support OpenMP unlikely case MacOS.","code":""},{"path":"/reference/multithreading.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel processing tools — multithreading","text":"","code":"set_parallel_strategy(strategy)  unset_parallel_strategy()  get_parallel_strategy()  ncores()  half_cores()  sequential()  concurrent_files(ncores = half_cores())  concurrent_points(ncores = half_cores())  nested(ncores = ncores()/4L, ncores2 = 2L)  has_omp_support()"},{"path":"/reference/multithreading.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel processing tools — multithreading","text":"strategy object returned one sequential(), concurrent_points(), concurrent_files() nested(). ncores integer. Number cores. ncores2 integer.  Number cores. nested strategy ncores number concurrent files ncores2 number concurrent points.","code":""},{"path":"/reference/multithreading.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parallel processing tools — multithreading","text":"4 strategies parallel processing: sequential parallelization : sequential() concurrent-points Point cloud files processed sequentially one one. Inside pipeline, stages parallelized able process multiple points simultaneously. stages natively parallelized. E.g. concurrent_points(4) concurrent-files Files processed parallel. Several files loaded memory processed simultaneously. entire pipeline parallelized, inside stage, points processed sequentially. E.g. concurrent_files(4) nested Files processed parallel. Several files loaded memory processed simultaneously, inside stages, points processed parallel. E.g. nested(4,2) concurrent-files likely desirable fastest option. However, uses memory loads multiple files. default concurrent_points(half_cores()) can changed globally using e.g. set_parallel_strategy(concurrent_files(4))","code":""},{"path":"/reference/multithreading.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel processing tools — multithreading","text":"","code":"if (FALSE) { f <- paste0(system.file(package=\"lasR\"), \"/extdata/bcts/\") f <- list.files(f, pattern = \"(?i)\\\\.la(s|z)$\", full.names = TRUE)  pipeline <- reader_las() + rasterize(2, \"imean\")  ans <- exec(pipeline, on = f, progress = TRUE, ncores = concurrent_files(4))  set_parallel_strategy(concurrent_files(4)) ans <- exec(pipeline, on = f, progress = TRUE) }"},{"path":"/reference/normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize the point cloud — normalize","title":"Normalize the point cloud — normalize","text":"Normalize point cloud using triangulate transform_with. triangulates ground points applies transform_with linearly interpolate elevation point within triangle.","code":""},{"path":"/reference/normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize the point cloud — normalize","text":"","code":"normalize(extrabytes = FALSE)"},{"path":"/reference/normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize the point cloud — normalize","text":"extrabytes bool. FALSE coordinate Z point cloud modified becomes height ground (HAG). TRUE coordinate Z modified new extrabytes attribute named 'HAG' added point cloud.","code":""},{"path":[]},{"path":"/reference/normalize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize the point cloud — normalize","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline <- reader_las() + normalize() + write_las() exec(pipeline, on = f) #> [1] \"/tmp/Rtmp3xX9cx/Topography.las\""},{"path":"/reference/pit_fill.html","id":null,"dir":"Reference","previous_headings":"","what":"Pits and spikes filling — pit_fill","title":"Pits and spikes filling — pit_fill","text":"Pits spikes filling raster. Typically used post-processing CHM. algorithm St-Onge 2008 (see reference).","code":""},{"path":"/reference/pit_fill.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pits and spikes filling — pit_fill","text":"","code":"pit_fill(   raster,   lap_size = 3L,   thr_lap = 0.1,   thr_spk = -0.1,   med_size = 3L,   dil_radius = 0L,   ofile = temptif() )"},{"path":"/reference/pit_fill.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pits and spikes filling — pit_fill","text":"raster LASRalgorithm. stage produces raster. lap_size integer. Size Laplacian filter kernel (integer value, pixels). thr_lap numeric. Threshold Laplacian value detecting cavity (values value considered cavity). positive value. thr_spk numeric. Threshold Laplacian value detecting spike (values value considered spike). negative value. med_size integer. Size median filter kernel (integer value, pixels). dil_radius integer. Dilation radius (integer value, pixels). ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":"/reference/pit_fill.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pits and spikes filling — pit_fill","text":"stage produces raster. path provided `ofile` expected `.tif` format supported GDAL.","code":""},{"path":"/reference/pit_fill.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pits and spikes filling — pit_fill","text":"St-Onge, B., 2008. Methods improving quality true orthomosaic Vexcel UltraCam images created using alidar digital surface model, Proceedings Silvilaser 2008, Edinburgh, 555-562. https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=81365288221f3ac34b51a82e2cfed8d58defb10e","code":""},{"path":"/reference/pit_fill.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pits and spikes filling — pit_fill","text":"","code":"f <- system.file(\"extdata\", \"MixedConifer.las\", package=\"lasR\")  reader <- reader_las(filter = keep_first()) tri <- triangulate() chm <- rasterize(0.25, tri) pit <- pit_fill(chm) u <- exec(reader + tri + chm + pit, on = f)  chm <- u[[1]] sto <- u[[2]]  #terra::plot(c(chm, sto), col = lidR::height.colors(25))"},{"path":"/reference/rasterize.html","id":null,"dir":"Reference","previous_headings":"","what":"Rasterize a point cloud — rasterize","title":"Rasterize a point cloud — rasterize","text":"Rasterize point cloud using different approaches. stage modify point cloud. produces derived product raster format.","code":""},{"path":"/reference/rasterize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rasterize a point cloud — rasterize","text":"","code":"rasterize(res, operators = \"max\", filter = \"\", ofile = temptif(), ...)"},{"path":"/reference/rasterize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rasterize a point cloud — rasterize","text":"res numeric. resolution raster. Can vector two resolutions. case correspond x y resolution buffered rasterization. (see section 'Buffered' examples) operators Can character vector. \"min\", \"max\" \"count\" accepted well many others (see section 'Operators'). Can also rasterize triangulation input LASRalgorithm triangulation (see examples). Can also user-defined expression (see example section 'Operators'). filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given stage filter applied, points meet criteria processed. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage. ... default_value numeric. rasterizing operator filter (e.g. -keep_z_above 2) pixels covered points may longer contain point pass filter criteria assigned NA. differentiate NAs non covered pixels NAs covered pixels without point pass filter, later case can assigned another value 0.","code":""},{"path":"/reference/rasterize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rasterize a point cloud — rasterize","text":"stage produces raster. path provided `ofile` expected `.tif` format supported GDAL.","code":""},{"path":"/reference/rasterize.html","id":"operators","dir":"Reference","previous_headings":"","what":"Operators","title":"Rasterize a point cloud — rasterize","text":"operators string vector strings: read metric_engine see possible strings examples valid calls:   operators R user-defined expression, function return either vector numbers list containing atomic numbers. assign band name raster, vector list must named accordingly. following valid operators:","code":"rasterize(10, c(\"max\", \"count\", \"i_mean\", \"z_p95\")) rasterize(10, c(\"z_max\", \"c_count\", \"intensity_mean\", \"p95\")) f = function(x) { return(mean(x)) } g = function(x,y) { return(c(avg = mean(x), med = median(y))) } h = function(x) { return(list(a = mean(x), b = median(x))) } rasterize(10, f(Intensity)) rasterize(10, g(Z, Intensity)) rasterize(10, h(Z))"},{"path":"/reference/rasterize.html","id":"buffered","dir":"Reference","previous_headings":"","what":"Buffered","title":"Rasterize a point cloud — rasterize","text":"argument res vector two numbers, first number represents resolution output raster, second number represents size windows used compute metrics. approach called Buffered Area Based Approach (BABA). classical rasterization, metrics computed independently pixel. example, predicting resource typically involves computing metrics 400 square meter pixel, resulting raster resolution 20 meters. possible achieve finer granularity method. However, buffered rasterization, possible compute raster resolution 10 meters (.e., computing metrics every 10 meters) using 20 x 20 windows metric computation. case, windows overlap, essentially creating moving window effect. option apply rasterizing triangulation, second value considered case.","code":""},{"path":"/reference/rasterize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rasterize a point cloud — rasterize","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader_las() tri  <- triangulate(filter = keep_ground()) dtm  <- rasterize(1, tri) # input is a triangulation stage avgi <- rasterize(10, mean(Intensity)) # input is a user expression chm  <- rasterize(2, \"max\") # input is a character vector pipeline <- read + tri + dtm + avgi + chm ans <- exec(pipeline, on = f) ans[[1]] #> class       : SpatRaster  #> dimensions  : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file1e9c1685c9ba.tif  #> name        : file1e9c1685c9ba  ans[[2]] #> class       : SpatRaster  #> dimensions  : 30, 30, 1  (nrow, ncol, nlyr) #> resolution  : 10, 10  (x, y) #> extent      : 273350, 273650, 5274350, 5274650  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file1e9c2b51727e.tif  #> name        : file1e9c2b51727e  ans[[3]] #> class       : SpatRaster  #> dimensions  : 144, 144, 1  (nrow, ncol, nlyr) #> resolution  : 2, 2  (x, y) #> extent      : 273356, 273644, 5274356, 5274644  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file1e9c1a6a72bf.tif  #> name        : max   # Demonstration of buffered rasterization  # A good resolution for computing point density is 5 meters. c0 <- rasterize(5, \"count\")  # Computing point density at too fine a resolution doesn't make sense since there is # either zero or one point per pixel. Therefore, producing a point density raster with # a 2 m resolution is not feasible with classical rasterization. c1 <- rasterize(2, \"count\")  # Using a buffered approach, we can produce a raster with a 2-meter resolution where # the metrics for each pixel are computed using a 5-meter window. c2  <- rasterize(c(2,5), \"count\")  pipeline = read + c0 + c1 + c2 res <- exec(pipeline, on = f) terra::plot(res[[1]]/25)  # divide by 25 to get the density  terra::plot(res[[2]]/4)   # divide by 4 to get the density  terra::plot(res[[3]]/25)  # divide by 25 to get the density"},{"path":"/reference/reader_las.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the pipeline — reader_las","title":"Initialize the pipeline — reader_las","text":"first stage must called pipeline. stage nothing returns nothing associated another processing stage. initializes pipeline. reader_las() main function dispatches functions. reader_las_coverage() processes entire point cloud. reader_las_circles() reader_las_rectangles() read process selected regions interest. chosen reader options .e. using reader_las() can omitted.","code":""},{"path":"/reference/reader_las.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the pipeline — reader_las","text":"","code":"reader_las(filter = \"\", ...)  reader_las_coverage(filter = \"\", ...)  reader_las_circles(xc, yc, r, filter = \"\", ...)  reader_las_rectangles(xmin, ymin, xmax, ymax, filter = \"\", ...)"},{"path":"/reference/reader_las.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the pipeline — reader_las","text":"filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given stage filter applied, points meet criteria processed. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. ... passed readers xc, yc, r numeric. Circle centres radius radii. xmin, ymin, xmax, ymax numeric. Coordinates rectangles","code":""},{"path":"/reference/reader_las.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize the pipeline — reader_las","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package = \"lasR\")  pipeline <- reader_las() + rasterize(10, \"zmax\") ans <- exec(pipeline, on = f) # terra::plot(ans)  pipeline <- reader_las(filter = keep_z_above(1.3)) + rasterize(10, \"zmean\") ans <- exec(pipeline, on = f) # terra::plot(ans)  # read_las() with no option can be omitted ans <- exec(rasterize(10, \"zmax\"), on = f) # terra::plot(ans)  # Perform a query and apply the pipeline on a subset pipeline = reader_las_circles(273500, 5274500, 20) + rasterize(2, \"zmax\") ans <- exec(pipeline, on = f) #> 1 files do not have a spatial index. Spatial indexing speeds up tile buffering and spatial queries drastically. #> Files will be indexed on-the-fly. This will take some extra time now but will speed up everything later. # terra::plot(ans)  # Perform a query and apply the pipeline on a subset with 1 output files per query ofile = paste0(tempdir(), \"/*_chm.tif\") pipeline = reader_las_circles(273500, 5274500, 20) + rasterize(2, \"zmax\", ofile = ofile) ans <- exec(pipeline, on = f) # terra::plot(ans)"},{"path":"/reference/region_growing.html","id":null,"dir":"Reference","previous_headings":"","what":"Region growing — region_growing","title":"Region growing — region_growing","text":"Region growing individual tree segmentation based Dalponte Coomes (2016) algorithm (see reference). Note stage strictly performs segmentation, original method described manuscript also performs pre- post-processing tasks. , tasks expected done user separate functions.","code":""},{"path":"/reference/region_growing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Region growing — region_growing","text":"","code":"region_growing(   raster,   seeds,   th_tree = 2,   th_seed = 0.45,   th_cr = 0.55,   max_cr = 20,   ofile = temptif() )"},{"path":"/reference/region_growing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Region growing — region_growing","text":"raster LASRalgoritm. stage producing raster. seeds LASRalgoritm. stage producing points used seeds. th_tree numeric. Threshold pixel tree. Default 2. th_seed numeric. Growing threshold 1. See reference Dalponte et al. 2016. pixel added region height greater tree height multiplied value. 0 1. Default 0.45. th_cr numeric. Growing threshold 2. See reference Dalponte et al. 2016. pixel added region height greater current mean height region multiplied value. 0 1. Default 0.55. max_cr numeric. Maximum value crown diameter detected tree (data units). Default 20. CAREFUL algorithm exists lidR package parameter pixels lidR. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":"/reference/region_growing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Region growing — region_growing","text":"stage produces raster. path provided `ofile` expected `.tif` format supported GDAL.","code":""},{"path":"/reference/region_growing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Region growing — region_growing","text":"Dalponte, M. Coomes, D. . (2016), Tree-centric mapping forest carbon density airborne laser scanning hyperspectral data. Methods Ecol Evol, 7: 1236–1245. doi:10.1111/2041-210X.12575.","code":""},{"path":"/reference/region_growing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Region growing — region_growing","text":"","code":"f <- system.file(\"extdata\", \"MixedConifer.las\", package=\"lasR\")  reader <- reader_las(filter = keep_first()) chm <- rasterize(1, \"max\") lmx <- local_maximum_raster(chm, 5) tree <- region_growing(chm, lmx, max_cr = 10) u <- exec(reader + chm + lmx + tree, on = f)  # terra::plot(u$rasterize) # plot(u$local_maximum, add = T, pch = 19, cex = 0.5) # terra::plot(u$region_growing, col = rainbow(150)) # plot(u$local_maximum, add = T, pch = 19, cex = 0.5)"},{"path":"/reference/sampling.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the point cloud — sampling_voxel","title":"Sample the point cloud — sampling_voxel","text":"Sample point cloud, keeping one random point per pixel per voxel perform poisson sampling. stages modify point cloud pipeline produce output.","code":""},{"path":"/reference/sampling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the point cloud — sampling_voxel","text":"","code":"sampling_voxel(res = 2, filter = \"\", ...)  sampling_pixel(res = 2, filter = \"\", ...)  sampling_poisson(distance = 2, filter = \"\", ...)"},{"path":"/reference/sampling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the point cloud — sampling_voxel","text":"res numeric. pixel/voxel resolution filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given stage filter applied, points meet criteria processed. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. ... unused distance numeric. Minimum distance points poisson sampling.","code":""},{"path":"/reference/sampling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the point cloud — sampling_voxel","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"/reference/sampling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the point cloud — sampling_voxel","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader_las() vox <- sampling_voxel(5) write <- write_las() pipeline <- read + vox + write exec(pipeline, on = f) #> [1] \"/tmp/Rtmp3xX9cx/Topography.las\""},{"path":"/reference/set_crs.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the CRS of the pipeline — set_crs","title":"Set the CRS of the pipeline — set_crs","text":"Assign CRS pipeline. stage reproject data. assigns CRS. stage affects subsequent stages pipeline thus appear close reader_las assign correct CRS stages.","code":""},{"path":"/reference/set_crs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the CRS of the pipeline — set_crs","text":"","code":"set_crs(x)"},{"path":"/reference/set_crs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the CRS of the pipeline — set_crs","text":"x integer string. EPSG code WKT string understood GDAL","code":""},{"path":"/reference/set_crs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set the CRS of the pipeline — set_crs","text":"","code":"# expected usage hmax = rasterize(10, \"max\") pipeline = reader_las() + set_crs(2949) + hmax  # fancy usages are working as expected. The .tif file is written with a CRS, the .gpkg file with # another CRS and the .las file with yet another CRS. pipeline = set_crs(2044) + hmax + set_crs(2004) + local_maximum(5) + set_crs(2949) + write_las()"},{"path":"/reference/set_exec_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set global processing options — set_exec_options","title":"Set global processing options — set_exec_options","text":"Set global processing options exec function. default, pipelines executed without progress bar, processing one file time sequentially. following options can passed exec() function four ways. See details.","code":""},{"path":"/reference/set_exec_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set global processing options — set_exec_options","text":"","code":"set_exec_options(   ncores = NULL,   progress = NULL,   buffer = NULL,   chunk = NULL,   ... )  unset_exec_option()"},{"path":"/reference/set_exec_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set global processing options — set_exec_options","text":"ncores object returned one sequential(), concurrent_points(), concurrent_files(), nested(). See multithreading. NULL default concurrent_points(half_cores()). simple integer provided corresponds concurrent_files(ncores). progress boolean. Displays progress bar. buffer numeric. file read buffer. default NULL, mean file buffered. means internal routine knows buffer needed pick greatest value internal suggestion value. chunk numeric. default, collection files processed file (chunk = NULL chunk = 0). possible process arbitrary-sized chunks. useful e.g., processing collections large files processing massive copc file. ... internal options exposed users.","code":""},{"path":"/reference/set_exec_options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set global processing options — set_exec_options","text":"4 ways pass processing options, important understand precedence rules: first option explicitly naming option. option deprecated used convenience backward compatibility. second option passing list argument. option explicit preferred. argument takes precedence explicit arguments. third option using LAScatalog lidR package. LAScatalog already carries processing options respected lasR package. options LAScatalog take precedence. last option setting global processing options. global precedence mainly intended provide way users override options access exec() function. may happen developer creates function executes pipeline internally, users provide options.","code":"exec(pipeline, on = f, progress = TRUE, ncores = 8) exec(pipeline, on = f, with = list(progress = TRUE, chunk = 500)) exec(pipeline, on = ctg, ncores = 4) set_exec_options(progress = TRUE, ncores = concurrent_files(2)) exec(pipeline, on = f)"},{"path":[]},{"path":"/reference/stop_if_outside.html","id":null,"dir":"Reference","previous_headings":"","what":"Stop the pipeline if a conditionally — stop_if_outside","title":"Stop the pipeline if a conditionally — stop_if_outside","text":"Stop pipeline conditionally. stages `stop_if` stage skipped condition met. allows process subset dataset skip stages conditionally. stop computation. breaks pipeline current file/chunk currently processed. (see exemple)","code":""},{"path":"/reference/stop_if_outside.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stop the pipeline if a conditionally — stop_if_outside","text":"","code":"stop_if_outside(xmin, ymin, xmax, ymax)"},{"path":"/reference/stop_if_outside.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stop the pipeline if a conditionally — stop_if_outside","text":"xmin, ymin, xmax, ymax numeric. bounding box","code":""},{"path":"/reference/stop_if_outside.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stop the pipeline if a conditionally — stop_if_outside","text":"","code":"# Collection of 4 files f <- system.file(\"extdata\", \"bcts/\", package=\"lasR\")  # This bounding box encompasses only one of the four files stopif = stop_if_outside(884800, 620000, 885400, 629200)  read = reader_las() hll = hulls() tri = triangulate(filter = keep_ground()) dtm = rasterize(1, tri)  # reads the 4 files but 'tri' and 'dtm' are computed only for one file because stopif # allows to escape the pipeline outside the bounding box pipeline = read + hll + stopif + tri + dtm ans1 <- exec(pipeline, on = f) plot(ans1$hulls$geom, axes = TRUE) terra::plot(ans1$rasterize, add = TRUE)   # stopif can be applied before read. Only one file will actually be read and processed pipeline = stopif + read + hll + tri + dtm ans2 <- exec(pipeline, on = f) plot(ans2$hulls$geom, axes = TRUE) terra::plot(ans1$rasterize, add = TRUE, legend = FALSE)"},{"path":"/reference/summarise.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary — summarise","title":"Summary — summarise","text":"Summarize dataset counting number points, first returns metrics entire point cloud. also produces histogram Z Intensity attributes entiere point cloud. can also compute metrics file chunk metric engine rasterize. stage modify point cloud. produces summary list.","code":""},{"path":"/reference/summarise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary — summarise","text":"","code":"summarise(zwbin = 2, iwbin = 50, metrics = NULL, filter = \"\")"},{"path":"/reference/summarise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary — summarise","text":"zwbin, iwbin numeric. Width bins histograms Z Intensity. metrics Character vector. \"min\", \"max\" \"count\" accepted well many others (see metric_engine). NULL nothing computed. something provided metrics computed chunk loaded. chunk might file may also plot (see examples). filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given stage filter applied, points meet criteria processed. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters.","code":""},{"path":"/reference/summarise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary — summarise","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader_las() pipeline <- read + summarise() ans <- exec(pipeline, on = f) ans #> $npoints #> [1] 73403 #>  #> $nsingle #> [1] 31294 #>  #> $nwithheld #> [1] 0 #>  #> $nsynthetic #> [1] 0 #>  #> $npoints_per_return #>     1     2     3     4     5     6  #> 53538 15828  3569   451    16     1  #>  #> $npoints_per_class #>     1     2     9  #> 61347  8159  3897  #>  #> $z_histogram #>   788   790   792   794   796   798   800   802   804   806   808   810   812  #>     1   163   265   470   596   694  1610  4955  5510 13833  9974  9865  8076  #>   814   816   818   820   822   824   826   828   830  #>  6643  4682  2958  1715   830   390   146    26     1  #>  #> $i_histogram #>   50  100  150  200  250  300  350  400  450  500  550  600  650  700  750  800  #>   25  397 1041 1576 2842 2585 2249 2051 2341 2575 2301 2529 2483 2623 2505 2697  #>  850  900  950 1000 1050 1100 1150 1200 1250 1300 1350 1400 1450 1500 1550 1600  #> 2759 2865 2865 3242 3272 3556 3464 3231 2589 2472 3478 3747 1969  532  183  104  #> 1650 1700 1750 1800 1850 1900 1950 2000 2050 2100 2150 2200 2250 2300 2350 2400  #>   97   65   35   18    9   13    7    6    0    1    0    2    1    0    0    0  #> 2450  #>    1  #>  #> $crs #> [1] \"PROJCRS[\\\"NAD83(CSRS) / MTM zone 7\\\",BASEGEOGCRS[\\\"NAD83(CSRS)\\\",DATUM[\\\"NAD83 Canadian Spatial Reference System\\\",ELLIPSOID[\\\"GRS 1980\\\",6378137,298.257222101,LENGTHUNIT[\\\"metre\\\",1]]],PRIMEM[\\\"Greenwich\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],ID[\\\"EPSG\\\",4617]],CONVERSION[\\\"MTM zone 7\\\",METHOD[\\\"Transverse Mercator\\\",ID[\\\"EPSG\\\",9807]],PARAMETER[\\\"Latitude of natural origin\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8801]],PARAMETER[\\\"Longitude of natural origin\\\",-70.5,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8802]],PARAMETER[\\\"Scale factor at natural origin\\\",0.9999,SCALEUNIT[\\\"unity\\\",1],ID[\\\"EPSG\\\",8805]],PARAMETER[\\\"False easting\\\",304800,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8806]],PARAMETER[\\\"False northing\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8807]]],CS[Cartesian,2],AXIS[\\\"easting (E(X))\\\",east,ORDER[1],LENGTHUNIT[\\\"metre\\\",1]],AXIS[\\\"northing (N(Y))\\\",north,ORDER[2],LENGTHUNIT[\\\"metre\\\",1]],USAGE[SCOPE[\\\"Engineering survey, topographic mapping.\\\"],AREA[\\\"Canada - Quebec - between 72°W and 69°W.\\\"],BBOX[45.01,-72,61.8,-69]],ID[\\\"EPSG\\\",2949]]\" #>  #> $epsg #> [1] 2949 #>   # Compute metrics for each plot read = reader_las_circles(c(273400, 273500), c(5274450, 5274550), 11.28) metrics = summarise(metrics = c(\"z_mean\", \"z_p95\", \"i_median\", \"count\")) pipeline = read + metrics ans = exec(pipeline, on = f) ans$metrics #>   count i_median   z_mean    z_p95 #> 1   291     1311 806.0330 807.2401 #> 2   185      731 804.0168 811.2172"},{"path":"/reference/temporary_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporary files — temporary_files","title":"Temporary files — temporary_files","text":"Convenient functions create temporary file given extension.","code":""},{"path":"/reference/temporary_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporary files — temporary_files","text":"","code":"temptif()  tempgpkg()  tempshp()  templas()  templaz()"},{"path":"/reference/temporary_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporary files — temporary_files","text":"string. Path temporary file.","code":""},{"path":"/reference/temporary_files.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporary files — temporary_files","text":"","code":"tempshp() #> [1] \"/tmp/Rtmp3xX9cx/file1e9c6772d010.shp\" templaz() #> [1] \"/tmp/Rtmp3xX9cx/file1e9c7805db5e.laz\""},{"path":"/reference/tools.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools inherited from base R — tools","title":"Tools inherited from base R — tools","text":"Tools inherited base R","code":""},{"path":"/reference/tools.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tools inherited from base R — tools","text":"","code":"# S3 method for LASRalgorithm print(x, ...)  # S3 method for LASRpipeline print(x, ...)  # S3 method for LASRpipeline +(e1, e2)  # S3 method for LASRpipeline c(...)"},{"path":"/reference/tools.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools inherited from base R — tools","text":"x, e1, e2 lasR objects ... lasR objects. equivalent +","code":""},{"path":"/reference/tools.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tools inherited from base R — tools","text":"","code":"algo1 <- rasterize(1, \"max\") algo2 <- rasterize(4, \"min\") print(algo1) #>  ----------- #> rasterize (uid:0c15) #>   res : 1  #>   window : 1  #>   method : max  #>   filter :   #>   output : /tmp/Rtmp3xX9cx/file1e9c2d8d4c92.tif  #> ----------- pipeline <- algo1 + algo2 print(pipeline) #>  ----------- #> rasterize (uid:0c15) #>   res : 1  #>   window : 1  #>   method : max  #>   filter :   #>   output : /tmp/Rtmp3xX9cx/file1e9c2d8d4c92.tif  #> ----------- #> rasterize (uid:5ff1) #>   res : 4  #>   window : 4  #>   method : min  #>   filter :   #>   output : /tmp/Rtmp3xX9cx/file1e9c7b75991e.tif  #> -----------"},{"path":"/reference/transform_with.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform a point cloud using another stage — transform_with","title":"Transform a point cloud using another stage — transform_with","text":"stage uses another stage produced Delaunay triangulation raster performs operation modify point cloud. can typically used build normalization stage stage modifies point cloud pipeline produce output.","code":""},{"path":"/reference/transform_with.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform a point cloud using another stage — transform_with","text":"","code":"transform_with(stage, operator = \"-\", store_in_attribute = \"\")"},{"path":"/reference/transform_with.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform a point cloud using another stage — transform_with","text":"stage LASRpipeline. stage produces triangulation raster. operator string. '-' '+' supported. store_in_attribute string. Use extra bytes attribute store result.","code":""},{"path":"/reference/transform_with.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform a point cloud using another stage — transform_with","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":[]},{"path":"/reference/transform_with.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform a point cloud using another stage — transform_with","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\")  # There is a normalize pipeline in lasR but let's create one almost equivalent mesh  <- triangulate(filter = keep_ground()) trans <- transform_with(mesh) pipeline <- mesh + trans + write_las() ans <- exec(pipeline, on = f)"},{"path":"/reference/triangulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Delaunay triangulation — triangulate","title":"Delaunay triangulation — triangulate","text":"Delaunay triangulation. Can used build DTM, CHM, normalize point cloud, application. stage typically used intermediate process without output file. stage modify point cloud.","code":""},{"path":"/reference/triangulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delaunay triangulation — triangulate","text":"","code":"triangulate(max_edge = 0, filter = \"\", ofile = \"\", use_attribute = \"Z\")"},{"path":"/reference/triangulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delaunay triangulation — triangulate","text":"max_edge numeric. Maximum edge length triangle Delaunay triangulation. triangle edge length greater value, removed. max_edge = 0, trimming done (see examples). filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given stage filter applied, points meet criteria processed. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage. use_attribute character. default triangulation performed coordinate Z. Can also name extra bytes attribute 'HAG' exists. Can also 'Intensity'.","code":""},{"path":"/reference/triangulate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delaunay triangulation — triangulate","text":"stage produces vector. path provided `ofile` expected `.gpkg` format supported GDAL. Vector stages may produce geometries Z coordinates. Thus, discouraged store formats 3D support, shapefiles.","code":""},{"path":"/reference/triangulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delaunay triangulation — triangulate","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader_las() tri1 <- triangulate(25, filter = keep_ground(), ofile = tempgpkg()) filter <- \"-keep_last -keep_random_fraction 0.1\" tri2 <- triangulate(filter = filter, ofile = tempgpkg()) pipeline <- read + tri1 + tri2 ans <- exec(pipeline, on = f) #plot(ans[[1]]) #plot(ans[[2]])"},{"path":"/reference/write_las.html","id":null,"dir":"Reference","previous_headings":"","what":"Write LAS or LAZ files — write_las","title":"Write LAS or LAZ files — write_las","text":"Write LAS LAZ file step pipeline (typically end). Unlike stages, output written single large file multiple tiled files corresponding original collection files.","code":""},{"path":"/reference/write_las.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write LAS or LAZ files — write_las","text":"","code":"write_las(   ofile = paste0(tempdir(), \"/*.las\"),   filter = \"\",   keep_buffer = FALSE )"},{"path":"/reference/write_las.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write LAS or LAZ files — write_las","text":"ofile character. Output file names. string must contain wildcard * wildcard can replaced name original tile preserve tiling pattern. wildcard omitted, everything written single file. may desired behavior circumstances, e.g., merge files. filter 'filter' argument allows filtering point-cloud work points interest. available filters LASlib can found running filter_usage. given stage filter applied, points meet criteria processed. common strings \"-keep_first\", \"-keep_class 2\", \"drop_z_below 2\". details see filters. keep_buffer bool. buffer removed write file can preserved.","code":""},{"path":"/reference/write_las.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write LAS or LAZ files — write_las","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader_las() tri  <- triangulate(filter = keep_ground()) normalize <- tri + transform_with(tri) pipeline <- read + normalize + write_las(paste0(tempdir(), \"/*_norm.las\")) exec(pipeline, on = f) #> [1] \"/tmp/Rtmp3xX9cx/Topography_norm.las\""},{"path":"/reference/write_lax.html","id":null,"dir":"Reference","previous_headings":"","what":"Write spatial indexing .lax files — write_lax","title":"Write spatial indexing .lax files — write_lax","text":"Creates .lax file .las .laz file. .lax file contains spatial indexing information. Spatial indexing drastically speeds tile buffering spatial queries. lasR, mandatory spatially indexed point clouds, either using .lax files .copc.laz files. processed file collection spatially indexed, write_lax() file automatically added beginning pipeline (see Details).","code":""},{"path":"/reference/write_lax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write spatial indexing .lax files — write_lax","text":"","code":"write_lax(embedded = FALSE, overwrite = FALSE)"},{"path":"/reference/write_lax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write spatial indexing .lax files — write_lax","text":"embedded boolean. .lax file auxiliary file accompanies corresponding las laz file. .lax file can also embedded within laz file produce single file. overwrite boolean. stage create new spatial index corresponding point cloud already spatial index. TRUE, forces creation new one. copc.laz files never reindexed lax files.","code":""},{"path":"/reference/write_lax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write spatial indexing .lax files — write_lax","text":"stage added automatically lasR, placed beginning pipeline, las/laz files indexed --fly used. advantage users need anything; works transparently delay processing. drawback , condition, stage run parallel. stage explicitly added users, can placed anywhere pipeline always executed first anything else. files indexed first parallel, actual processing start. avoid overthinking works, best simpler run exec(write_lax(), = files) non indexed point cloud anything point cloud.","code":""},{"path":"/reference/write_lax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write spatial indexing .lax files — write_lax","text":"","code":"if (FALSE) { exec(write_lax(), on = files) }"},{"path":"/reference/write_vpc.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a Virtual Point Cloud — write_vpc","title":"Write a Virtual Point Cloud — write_vpc","text":"Borrowing concept virtual rasters GDAL, VPC file format references point cloud files virtual point cloud (VPC)","code":""},{"path":"/reference/write_vpc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a Virtual Point Cloud — write_vpc","text":"","code":"write_vpc(ofile, absolute_path = FALSE, use_gpstime = FALSE)"},{"path":"/reference/write_vpc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a Virtual Point Cloud — write_vpc","text":"ofile character. file path extension .vpc write virtual point cloud file absolute_path boolean. absolute path files stored tile index file. use_gpstime logical. fill datetime attribute VPC file, uses year day year recorded header. attributes usually relevant. often zeroed official signification attributes corresponds creation LAS file. guarantee date corresponds acquisition date. use_gpstime = TRUE, use gpstime first point recorded file compute day year acquisition. works GPS time recorded Adjusted Standard GPS Time GPS Week Time.","code":""},{"path":"/reference/write_vpc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Write a Virtual Point Cloud — write_vpc","text":"https://www.lutraconsulting.co.uk/blog/2023/06/08/virtual-point-clouds/https://github.com/PDAL/wrench/blob/main/vpc-spec.md","code":""},{"path":"/reference/write_vpc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a Virtual Point Cloud — write_vpc","text":"","code":"if (FALSE) { pipeline = write_vpc(\"folder/dataset.vpc\") exec(pipeline, on = \"folder\") }"},{"path":"/news/index.html","id":"lasr-072","dir":"Changelog","previous_headings":"","what":"lasR 0.7.2","title":"lasR 0.7.2","text":"New argument use_gpstime write_vpc() Fix: division 0 raster stage initialization Fix: datetime parsing write_vpc() Fix: write_vpc() writes valid files readable QGIS","code":""},{"path":"/news/index.html","id":"lasr-071","dir":"Changelog","previous_headings":"","what":"lasR 0.7.1","title":"lasR 0.7.1","text":"Fix: sampling stages robustly support 4 billions voxels Enhance: noise ivf faster. Fix: fix memory corruption point clouds 4.3 GB","code":""},{"path":[]},{"path":"/news/index.html","id":"new-features-0-7-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"lasR 0.7.0","text":"New stage classify_with_csf() classify ground points. metric engine introduced v0.6.0 can now compute metrics extrabytes attributes. e.g. Amplitude_mean New stage sampling_poisson perform Poisson Disk Sampling sampling_pixel sampling_voxel faster.","code":""},{"path":"/news/index.html","id":"fixes-0-7-0","dir":"Changelog","previous_headings":"","what":"FIXES","title":"lasR 0.7.0","text":"sampling_* stages respect filter argument Fix #63 crash chunk skipped either 0 points stop_if stage. Fix #64 metrics RGB actually computed RRR","code":""},{"path":"/news/index.html","id":"breaking-changes-0-7-0","dir":"Changelog","previous_headings":"","what":"BREAKING CHANGES","title":"lasR 0.7.0","text":"classify_isolated_voxels() renamed classify_with_ivf() consistency.","code":""},{"path":"/news/index.html","id":"lasr-062","dir":"Changelog","previous_headings":"","what":"lasR 0.6.2","title":"lasR 0.6.2","text":"Fix: writing copc file copc file crashed. Fix: #62 attributes vector files recorded output file template contains wildcard * Fix: metrics cv sd computed properly.","code":""},{"path":"/news/index.html","id":"lasr-061","dir":"Changelog","previous_headings":"","what":"lasR 0.6.1","title":"lasR 0.6.1","text":"Fix: metrics cv sd return NAs instead Inf edges case undefined. Enhance: progress bar displays better number cores used. Fix: progress bar reader_las() stage. now displays correct percentage. Fix: write_las() without wildcard (merge mode) works files different formats scales/offsets","code":""},{"path":[]},{"path":"/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"lasR 0.6.0","text":"New stage stop_if conditionally escape pipeline. New section stop_if online tutorial. New stage write_lax. stage automatically added engine can now explicitly added users. New internal “metric engine”. metric engine used compute metrics , e.g., rasterize() operators like zmean, imean, . metric engine redesigned allows string format attribute_metric z_sd, i_mean, c_mode, a_mean, intensity_max, classification_mode, angle_mean, combinations. attributes mapped, new functions available sum, mode. Many added easily. Former strings zmean imax longer valid replaced z_mean i_max backward compatible. rasterize gained access new metric engine can compute many metrics natively. summarize() gained access metric engine can compute metrics file chunk. Used conjunction reader_las_circle(), can used, example, compute plot inventory metrics. online tutorial updated. section “plot inventory” longer uses callback() preceded new section “summarize”.","code":""},{"path":"/news/index.html","id":"breaking-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"BREAKING CHANGES","title":"lasR 0.6.0","text":"package longer assigns set_parallel_strategy(concurrent_points(half_core())) loading. Instead, nothing provided, interpreted concurrent_points(half_core()). Thus, users can now write exec(pipeline, = file, ncores = 8). engine now respect ncores = 8 global settings global precedence assigned. multi-threading vignette updated. Pipelines include R-based stages (rasterize R function, callback) longer parallelizable concurrent-file strategy. Parallelizing pipeline involves R C API terribly complex eventually leads pseudo-parallelism lot troubleshooting deal (especially abort pipeline). Consequently, removed parallelism capabilities. numerous new native metrics added metric engine compensate loss. online documentation updated accordingly.","code":""},{"path":"/news/index.html","id":"internal-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"INTERNAL CHANGES","title":"lasR 0.6.0","text":"large number changes separate lasR R. lasR can now compiled standalone software. Makefile added repository. R level, pipeline processing options passed C++ engine via JSON file instead passed via R’s C API, effectively separating lasR R . R side lasR now purely API standalone engine. JSON file produced lasR package can executed standalone software: lasr pipeline.json. However, syntax JSON file documented intended documented. Rather, JSON file produced API lasR package, QGIS plugin, Python package. Obviously, currently thing.","code":""},{"path":"/news/index.html","id":"lasr-056","dir":"Changelog","previous_headings":"","what":"lasR 0.5.6","title":"lasR 0.5.6","text":"Fix: reader_las() COPC files, depth query (-max_depth), buffer. depth query performed . fix temporary: breaks progress bar reader_las() less serious bug. Fix: reader_las() large files. Fix: load_raster() thread-safe New: rasterize() accepts new argument default_value. rasterizing operator filter (e.g. -keep_z_above 2) pixels covered points may longer contain point pass filter criteria assigned NA. differentiate NAs non covered pixels NAs covered pixels without point pass filter, later case can assigned another value 0.","code":""},{"path":"/news/index.html","id":"lasr-055","dir":"Changelog","previous_headings":"","what":"lasR 0.5.5","title":"lasR 0.5.5","text":"Fix: #50 write_vpc() properly reprojects bounding boxes WGS84 Enhance: write_vpc() writes zmin zmax file. Fix: #55 local_maximum() longer fails ofile = \"\" Fix: progress bar reader_las() COPC files. Fix: metrics zsd isd incorrect due wrong parenthesis code.","code":""},{"path":"/news/index.html","id":"lasr-054","dir":"Changelog","previous_headings":"","what":"lasR 0.5.4","title":"lasR 0.5.4","text":"Fix: #48 segfault delete_points() 0 points left. Enhance: #47 pipelines named list. Enhance: #47 output list returned exec named duplicated names made unique make.names() Doc: added notes documentation geometry_features() address question #45 Enhance: #49 set_crs() longer forces pipeline read files. Enhance: exec() normalizes path users get error providing path ~. New: rasterize() gained metric zaboveX compute canopy cover.","code":""},{"path":"/news/index.html","id":"lasr-053","dir":"Changelog","previous_headings":"","what":"lasR 0.5.3","title":"lasR 0.5.3","text":"Fix: #45 computation time geometry_features delete_points() Fix: local_maximum() processing deleted points. Enhance: #44 write_vpc write datetime Enhance: delete_points can now physically remove deleted points number points deleted important. flagged kept memory. can also free available memory.","code":""},{"path":"/news/index.html","id":"lasr-052","dir":"Changelog","previous_headings":"","what":"lasR 0.5.2","title":"lasR 0.5.2","text":"New: #42 write_vpc() gained argument absolute_path Fix: #42 write_vpc() orders long/lat coordinates properly Linux Fix: #42 write_vpc() writes absolute path relative path exist Windows Fix: #40 triangulate() 0 point chunk. Fix: #43: geometry_feature works file already contains extrabytes attributes Enhance: 0 point point-clouds longer stopping computation. stage delete_points() removes points, pipeline stopped current chunk/file computation keep going others. case stages stages either crash stop computation.","code":""},{"path":"/news/index.html","id":"lasr-051","dir":"Changelog","previous_headings":"","what":"lasR 0.5.1","title":"lasR 0.5.1","text":"Fix: write_vpc() crash files without CRS Fix: write_vpc() write CRS set upstream set_crs()","code":""},{"path":"/news/index.html","id":"lasr-050","dir":"Changelog","previous_headings":"","what":"lasR 0.5.0","title":"lasR 0.5.0","text":"New: stage geometry_features() compute point wise geometry features based k-nearest neighbors. New: stage callback() can load 10 extrabyte attributes. Using flag E extrabytes loaded. New: stage set_crs() assign coordinate reference system point pipeline. New: raster GeoTiff format now created COMPRESS=DEFLATE, PREDICTOR=2,TILED=YES effectively reducing size rasters New: summarize() output includes CRS.","code":""},{"path":"/news/index.html","id":"lasr-048","dir":"Changelog","previous_headings":"","what":"lasR 0.4.8","title":"lasR 0.4.8","text":"Enhance: #33 local_maximum() gained record_attributes argument chose attribute points recorded vector file. Enhance: #33 local_maximum_raster() longer record zeroed LAS point attributes","code":""},{"path":"/news/index.html","id":"lasr-047","dir":"Changelog","previous_headings":"","what":"lasR 0.4.7","title":"lasR 0.4.7","text":"Fix: #32 writing vector file path containing wildcard crashed program.","code":""},{"path":"/news/index.html","id":"lasr-046","dir":"Changelog","previous_headings":"","what":"lasR 0.4.6","title":"lasR 0.4.6","text":"Fix: lax included laz file working. Fix: #30 can read files bigger 2.14 GB","code":""},{"path":"/news/index.html","id":"lasr-045","dir":"Changelog","previous_headings":"","what":"lasR 0.4.5","title":"lasR 0.4.5","text":"Fix: #29 using filter rasterize() produced corrupted output.","code":""},{"path":"/news/index.html","id":"lasr-044","dir":"Changelog","previous_headings":"","what":"lasR 0.4.4","title":"lasR 0.4.4","text":"Fix: bug set_parallel_strategy(nested(ncores = 4, ncores2 = 4)). Fix: attribute datatime datetime VPC files. Fix: #25 triangulation 0 points crashed. 0 points possible filter. Fix: #24 write_vpc() writes correct number points LAS 1.4 files. Fix: read WKT strings LAS files size inferior declared header (null-terminated record_length_after_header).","code":""},{"path":"/news/index.html","id":"lasr-043","dir":"Changelog","previous_headings":"","what":"lasR 0.4.3","title":"lasR 0.4.3","text":"Fix: #22 segfault partial processing. Fix: memory access WKT strings non-null-terminated.","code":""},{"path":"/news/index.html","id":"lasr-042","dir":"Changelog","previous_headings":"","what":"lasR 0.4.2","title":"lasR 0.4.2","text":"Fix: add_attribute() incorrectly reallocating memory causing potential crashes, especially adding several attributes. Fix: reader_las() crashing header LAS file record correct number points. Fix: naming queries. Documentation: reorganized URLs navbar website.","code":""},{"path":"/news/index.html","id":"lasr-040","dir":"Changelog","previous_headings":"","what":"lasR 0.4.0","title":"lasR 0.4.0","text":"New: parallelism multiple files. See ?multithreading New: stage local_maximum_raster compute local maximum raster New: argument exec pass processing options preferred direct naming. New: function set_exec_options() assign global processing options override arguments potentially hardcoded exec() New: stage load_raster read raster instead producing fly point cloud. New: stage add_rgb modify point data format Doc: new article website parallelism illustrated version ?multithreading Doc: improve documentation processing options ?exec ?set_exec_options","code":""},{"path":"/news/index.html","id":"lasr-036","dir":"Changelog","previous_headings":"","what":"lasR 0.3.6","title":"lasR 0.3.6","text":"Fix: #18 strongly improving arithmetic accuracy point_in_triangle.","code":""},{"path":"/news/index.html","id":"lasr-035","dir":"Changelog","previous_headings":"","what":"lasR 0.3.5","title":"lasR 0.3.5","text":"Fix: #17 transform_with can used pit_fill","code":""},{"path":"/news/index.html","id":"lasr-034","dir":"Changelog","previous_headings":"","what":"lasR 0.3.4","title":"lasR 0.3.4","text":"Fix: #15 pit_fill producing corrupted output Fix: pit_fill respecting parameters given user Fix: pit_fill combination rasterize(\"max\") working properly","code":""},{"path":"/news/index.html","id":"lasr-033","dir":"Changelog","previous_headings":"","what":"lasR 0.3.3","title":"lasR 0.3.3","text":"Fix: #12 write lax buffered chunk Fix: #13 processing chunk buffered","code":""},{"path":"/news/index.html","id":"lasr-032","dir":"Changelog","previous_headings":"","what":"lasR 0.3.2","title":"lasR 0.3.2","text":"Fix: CRS working Windows Fix: library(lasR) transparently checks latest version Windows.","code":""},{"path":"/news/index.html","id":"lasr-031","dir":"Changelog","previous_headings":"","what":"lasR 0.3.1","title":"lasR 0.3.1","text":"Fix: bugs making spatial query multiple files multiple spatial indexing systems (e.g. lax+nothing, lax+copc)","code":""},{"path":"/news/index.html","id":"lasr-030","dir":"Changelog","previous_headings":"","what":"lasR 0.3.0","title":"lasR 0.3.0","text":"Change: processor() reader() deprecated replaced exec() reader_las(). intends provide consistent natural way separate pipeline. .e stages global processing options .e. buffer, chunking, progress bar. example following now respects LAScatalog processing options possible previous syntax. New: processor now able process chunk like lidR New: stage delete_points() remove points pipeline. New: now possible write following: New: possible omit reader stage. automatically adds default reader New: triangulation 4x faster uses half memory. Fix: summarize(), rasterize() write_las() longer process withheld points streaming mode.","code":"ctg = lidR::readLAScatalog() pipeline = reader_las() + rasterize(...) exec(pipeline, on = ctg) pipeline = reader_las() + rasterize(...) exec(pipeline, on = file, chunk = 500) dtm = dtm() pipeline <- read + dtm + transform_with(dtm[[2]]) pipeline = rasterize(...) exec(pipeline, on = ctg)"},{"path":"/news/index.html","id":"lasr-021-2024-03-05","dir":"Changelog","previous_headings":"","what":"lasR 0.2.1 (2024-03-05)","title":"lasR 0.2.1 (2024-03-05)","text":"Fix: callback() properly handles errors injected function New: handy functions tempxyz() generate temp files extension .xyz. New: rasterize() now parallelized internal metrics including buffered area based approach New: rasterize() gained progress bar internal metrics.","code":""},{"path":"/news/index.html","id":"lasr-020-2024-03-01","dir":"Changelog","previous_headings":"","what":"lasR 0.2.0 (2024-03-01)","title":"lasR 0.2.0 (2024-03-01)","text":"New: rasterize() gains ability perform multi-resolution buffered rasterization. See documentation. New: rasterize() gains numerous native metrics zmax, zmean, zmedian, imax, imean . New: internal engine gains ability skip processing files collection use files load buffer. feature works LAScatalog lidR respecting processed attribute used lidR Fix: loading package offline created bug R longer handles errors.","code":""},{"path":"/news/index.html","id":"lasr-012-2024-02-10","dir":"Changelog","previous_headings":"","what":"lasR 0.1.2 (2024-02-10)","title":"lasR 0.1.2 (2024-02-10)","text":"New: progress bar reading header files (LAScatalog) can enabled progress = TRUE Fix: progress bar starts appear earlier .e. 0%. pipeline affects feeling progress.","code":""},{"path":"/news/index.html","id":"lasr-011-2024-02-08","dir":"Changelog","previous_headings":"","what":"lasR 0.1.1 (2024-02-08)","title":"lasR 0.1.1 (2024-02-08)","text":"Doc: Corrected documentation argument ncores processor(), incorrectly mentioned supported. New: Added new functions ncores() half_cores(). Fix: Corrected reader progress bar display reading las file filter buffer. Fix: Fixed overall progress bar, delayed one file showing incorrect progress.","code":""},{"path":"/news/index.html","id":"lasr-010-2024-02-01","dir":"Changelog","previous_headings":"","what":"lasR 0.1.0 (2024-02-01)","title":"lasR 0.1.0 (2024-02-01)","text":"Open public Fix: Fix overall progress bar, delayed one file showing incorrect progress.","code":""}]
