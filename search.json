[{"path":"https://r-lidar.github.io/lasR/articles/baba.html","id":"concept","dir":"Articles","previous_headings":"","what":"Concept","title":"Buffered Area Based Approach","text":"area-based approach partitions study area cells computes derived metrics points lie within cell. method offers straightforward means map value interest across territory. However, one drawback mapping resolution typically coarse, cells typically measuring 20 x 20 meters, corresponding 400 square meters inventory plots used build predictive model. Achieving finer resolution possible. lasR, introduced concept Buffered Area Based Approach (BABA) Moving Windows Area Based Approach (MWABA). BABA, metrics computed using points within cell size s (typically 20 meters), akin classical ABA. However, resolution raster effectively r due moving window progresses steps size r. instance, can compute average Z elevation 400 square meter area resolution 5 meters, instead typical 20 meters.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/baba.html","id":"exemple-1","dir":"Articles","previous_headings":"","what":"Exemple 1","title":"Buffered Area Based Approach","text":"’s important emphasize BABA, although resolution set 5 meters, values pixel computed based 20-meter cell. metric remains valid concerning reference plot inventory, typically 400 square meters. Consequently, becomes feasible predict map values interest fine-grained resolution using regular plot inventory data.","code":"f <- system.file(\"extdata\", \"Megaplot.las\", package=\"lasR\") aba  = rasterize(20, \"zmean\")      # ABA baba = rasterize(c(5,20), \"zmean\") # BABA pipeline = aba + baba ans = exec(pipeline, on = f)  terra::plot(ans[[1]], col = col, main = \"ABA\") terra::plot(ans[[2]], col = col, main = \"BABA\")"},{"path":"https://r-lidar.github.io/lasR/articles/baba.html","id":"exemple-2","dir":"Articles","previous_headings":"","what":"Exemple 2","title":"Buffered Area Based Approach","text":"approach also enables mapping point density finer resolution, among possibilities.","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") c1 <- rasterize(1, \"count\") c2  <- rasterize(c(1,4), \"count\") pipeline = c1 + c2 res <- exec(pipeline, on = f) terra::plot(res[[1]]/4, col = gray.colors(15,0,1), main = \"Regular\")   # divide by 4 to get the density terra::plot(res[[2]]/25, col = gray.colors(15,0,1), main = \"Moving windows\")  # divide by 25 to get the density"},{"path":"https://r-lidar.github.io/lasR/articles/baba.html","id":"naming-convention","dir":"Articles","previous_headings":"","what":"Naming convention","title":"Buffered Area Based Approach","text":"Buffered Area Based Approach (BABA), Moving Windows Area Based Approach (MWABA), Multi-Resolution Area Based Approach (MRABA) – feel free refer however prefer.","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/articles/benchmarks.html","id":"code","dir":"Articles","previous_headings":"Canopy Height Model","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) chm = rasterize_canopy(ctg, 1, p2r())   # lasR set_parallel_strategy(...) pipeline = rasterize(1, \"max\") exec(pipeline, on = ctg)"},{"path":[]},{"path":[]},{"path":"https://r-lidar.github.io/lasR/articles/benchmarks.html","id":"code-1","dir":"Articles","previous_headings":"Digital Terrain Model","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) dtm = rasterize_terrain(ctg, 1, tin())  # lasR set_parallel_strategy(...) tri = triangulate() pipeline = reader_las(filter = keep_ground()) + tri + rasterize(1, tri) exec(pipeline, on = ctg)"},{"path":[]},{"path":"https://r-lidar.github.io/lasR/articles/benchmarks.html","id":"multiple-raster","dir":"Articles","previous_headings":"","what":"Multiple raster","title":"Benchmarks of lasR vs. lidR","text":"gain terms computation time much significant running multiple stages single pipeline files read lasR multiple times lidR. , operations executed single pass C++ level, resulting efficient memory management.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/benchmarks.html","id":"code-2","dir":"Articles","previous_headings":"Multiple raster","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) custom_function = function(z,i) { list(avgz = mean(z), avgi = mean(i)) } ctg = readLAScatalog(f) chm = rasterize_canopy(ctg, 1, p2r()) met = pixel_metrics(ctg, ~custom_function(Z, Intensity), 20) den = rasterize_density(ctg, 5)  # lasR set_parallel_strategy(...) custom_function = function(z,i) { list(avgz = mean(z), avgi = mean(i)) } chm = rasterize(1, \"max\") met = rasterize(20, custom_function(Z, Intensity)) den = rasterize(5, \"count\") pipeline = chm + met + den exec(pipeline, on = folder)"},{"path":[]},{"path":[]},{"path":"https://r-lidar.github.io/lasR/articles/benchmarks.html","id":"code-3","dir":"Articles","previous_headings":"Normalization","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) opt_output_files(ctg) <- paste0(tempdir(), \"/*_norm\") norm = normalize_height(ctg, tin())  # lasR set_parallel_strategy(...) pipeline = reader(f) + normalize() + write_las() processor(pipeline)"},{"path":[]},{"path":[]},{"path":"https://r-lidar.github.io/lasR/articles/benchmarks.html","id":"code-4","dir":"Articles","previous_headings":"Local maximum","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"# lidR future::plan(future::multicore(...)) tree = locate_trees(ctg, lmf(5))  # lasR set_parallel_strategy(...) pipeline = reader(f) + local_maximum(5) processor(pipeline)"},{"path":[]},{"path":"https://r-lidar.github.io/lasR/articles/benchmarks.html","id":"complex-pipeline","dir":"Articles","previous_headings":"","what":"Complex Pipeline","title":"Benchmarks of lasR vs. lidR","text":"complex pipeline, point cloud normalized written new files. Digital Terrain Model (DTM) produced, Canopy Height Model (CHM) built, individual trees detected. detected trees used seeds region-growing algorithm segments trees. lasR pipeline can handle hundreds laser tiles, lidR may struggle apply pipeline, especially tree segmentation.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/benchmarks.html","id":"code-5","dir":"Articles","previous_headings":"Complex Pipeline","what":"Code","title":"Benchmarks of lasR vs. lidR","text":"","code":"del = triangulate(filter = keep_ground()) norm = transform_with(del) dtm = rasterize(1, del) chm = rasterize(1, \"max\") seed = local_maximum(3) tree = region_growing(chm, seed) write = write_las() pipeline = read + del + norm + write + dtm + chm +  seed + tree ans = exec(pipeline, on = ctg, progress = TRUE)"},{"path":[]},{"path":"https://r-lidar.github.io/lasR/articles/multithreading.html","id":"sequential-strategy","dir":"Articles","previous_headings":"","what":"Sequential strategy","title":"Parallel processing","text":"sequential strategy default strategy. However, easier start option explain specificities lasR. sequential processing, name indicates, files processed sequentially, nothing parallelized. point cloud one file passes pipeline files waiting processed. represented figure .","code":"set_parallel_strategy(sequential()) # or exec(pipeline, on = f, ncores = sequential())"},{"path":"https://r-lidar.github.io/lasR/articles/multithreading.html","id":"concurrent-points-strategy","dir":"Articles","previous_headings":"","what":"Concurrent points strategy","title":"Parallel processing","text":"Concurrent points half_cores() default strategy. files processed sequentially. point cloud one file passes pipeline files waiting. Inside pipeline, stages parallelized processing points different threads. core processes subset point cloud. stages parallelized consequently faster, practice, lot stages can easily parallelized way.","code":"set_parallel_strategy(concurrent_points(4)) # or exec(pipeline, on = f, ncores = concurrent_points(4))"},{"path":"https://r-lidar.github.io/lasR/articles/multithreading.html","id":"concurrent-files-strategy","dir":"Articles","previous_headings":"","what":"Concurrent files strategy","title":"Parallel processing","text":"files processed parallel. point cloud several files passes several cloned pipelines files waiting. Inside pipeline, stages parallelized. puts lot pressure disk many files read simultaneously, also stage can write raster/vector/LAS files simultaneously. Additionally, uses lot memory since many LAS files loaded memory simultaneously. modern fast SSD disks significant amount RAM, fastest option. course, users use cores; otherwise, may run memory. See also benchmarks vignette.","code":"set_parallel_strategy(concurrent_files(4)) # or exec(pipeline, on = f, ncores = concurrent_files(4)) # or exec(pipeline, on = f, ncores = 4) # more convenient"},{"path":"https://r-lidar.github.io/lasR/articles/multithreading.html","id":"nested-strategy","dir":"Articles","previous_headings":"","what":"Nested strategy","title":"Parallel processing","text":"files processed parallel. point cloud several files passes several cloned pipelines files waiting. Inside pipeline, stages also parallelized processing points different threads. Nested reserved experts .","code":"set_parallel_strategy(nested(4, 2)) # or exec(pipeline, on = f, ncores = nested(4, 2))"},{"path":"https://r-lidar.github.io/lasR/articles/multithreading.html","id":"special-cases","dir":"Articles","previous_headings":"","what":"Special cases","title":"Parallel processing","text":"lasR, everything written pure C++ except two stages inject user-defined R code use R C API (see R stages) R multi-threaded, thus calling stages parallel thread-safe crash R session best case deeply corrupt R memory worst case. Consequently, stages protected pipelines involving stages ran parallel concurrent-files strategy.","code":"rasterize(20, user_function(Z)) callback(user_function(data))"},{"path":"https://r-lidar.github.io/lasR/articles/multithreading.html","id":"real-timeline","dir":"Articles","previous_headings":"","what":"Real timeline","title":"Parallel processing","text":"figures , pipelines represented idealized simplified manner. example, stages depicted taking amount time, cores shown running parallel without overhead. simplification aids understanding, capture full complexity actual process. actual timeline real pipeline processing 9 files shown figure .","code":""},{"path":"https://r-lidar.github.io/lasR/articles/r-stages.html","id":"rasterize","dir":"Articles","previous_headings":"","what":"Rasterize","title":"R stages","text":"tutorial, mentioned rasterize() supports injection user-defined R expression. equivalent pixel_metrics() package lidR. user-defined function can mapped, making extremely versatile slower. Let’s compute map median intensity injecting user-defined expression. Like lidR, attributes point cloud named: X, Y, Z, Intensity, gpstime, ReturnNumber, NumberOfreturns, Classification, UserData, PointSourceID, R, G, B, NIR. users familiar lidR package, note ScanAngleRank/ScanAngle; instead scanner angle always named ScanAngle numeric. Also flags named Withheld, Synthetic Keypoint.  Notice , specific case, using rasterize(10, \"i_median\") efficient.","code":"pipeline = rasterize(10, median(Intensity)) ans = exec(pipeline, on = f)  terra::plot(ans, mar = c(1, 1, 1, 3), col = heat.colors(15))"},{"path":"https://r-lidar.github.io/lasR/articles/r-stages.html","id":"callback","dir":"Articles","previous_headings":"","what":"Callback","title":"R stages","text":"callback stage holds significant importance second last entry point inject R code pipeline, following rasterize(). familiar lidR package, initial step often involves reading data lidR::readLAS() expose point cloud data.frame object R. contrast, lasR loads point cloud optimally C++ without exposing directly R. However, callback, becomes possible expose point cloud data.frame executing specific R functions. Similar lidR, attributes point cloud lasR named: X, Y, Z, Intensity, gpstime, ReturnNumber, NumberOfreturns, Classification, UserData, PointSourceID, R, G, B, NIR. Notably, users accustomed lidR package, scanner angle consistently named ScanAngle numeric, opposed ScanAngleRank/ScanAngle. Additionally, flags named Withheld, Synthetic, Keypoint. Let’s delve simple example. LAS file, callback loads point cloud data.frame invokes meanz() function data.frame. output list two elements processed two files (f displayed document). average Z elevation respectively 809.08 13.27 file. mindful , given LAS/LAZ file, point cloud may contain points original file file loaded buffer. clarification matter provided later. callback function versatile can also employed edit point cloud. user-defined function returns data.frame number rows original one, function edits underlying C++ dataset. enables users perform tasks assigning class specific point. physically removing points possible, users can flag points Withheld. cases, points processed subsequent stages, discarded. observed, , time callback explicitly return anything; however, edited point cloud internally. generate output, users must use another stage write_las(). ’s important note write_las() write point number 12 flagged withheld. Neither subsequent stage process . point still memory discarded. memory efficiency reasons, possible physically remove point underlying memory lasR. Instead, points flagged withheld never processed. One consequence , points flagged withheld LAS/LAZ file processed lasR. aligns intended purpose flag according LAS specification may differ default behavior many software market including lidR. Now, let’s explore capabilities callback . First, let’s create lidR-like read_las() function expose point cloud R. following example, user-defined function employed return data.frame . user’s function returns data.frame number points original dataset, updates points C++ level. , use no_las_update = TRUE explicitly return result. Ground points can also classified using R function, one provided RCSF package: callback() exposes point cloud data.frame. way expose point clouds users manageable way. One reasons lasR memory-efficient faster lidR expose point cloud data.frame. Thus, pipelines using callback() significantly different lidR. advantage using lasR ability pipe different stages.","code":"meanz = function(data){ return(mean(data$Z)) } call = callback(meanz, expose = \"xyz\") ans = exec(call, on = f) print(ans) #>  - 809.0835  #>  - 13.27202 edit_points = function(data) {   data$Classification[5:7] = c(2L,2L,2L)   data$Withheld = FALSE   data$Withheld[12] = TRUE   return(data) }  call = callback(edit_points, expose = \"xyzc\") ans = exec(call, on = f) ans #> NULL read_las = function(f, select = \"xyzi\", filter = \"\") {   load = function(data) { return(data) }   read = reader(filter = filter)   call = callback(load, expose = select, no_las_update = TRUE)   return (exec(read+call, on = f)) }  f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") las = read_las(f) head(las) #>          X       Y        Z Intensity #> 1 273357.1 5274360 806.5340      1340 #> 2 273357.2 5274359 806.5635       728 #> 3 273357.2 5274358 806.0248      1369 #> 4 273357.2 5274510 809.6303       589 #> 5 273357.2 5274509 809.3880      1302 #> 6 273357.2 5274508 809.4847       123 csf = function(data) {   id = RCSF::CSF(data)   class = integer(nrow(data))   class[id] = 2L   data$Classification <- class   return(data) }  read = reader() classify = callback(csf, expose = \"xyz\") write = write_las() pipeline = read + classify + write exec(pipeline, on = f)"},{"path":"https://r-lidar.github.io/lasR/articles/r-stages.html","id":"buffer","dir":"Articles","previous_headings":"","what":"Buffer","title":"R stages","text":"Point clouds typically stored multiple contiguous files. avoid edge artifacts, file must loaded extra points coming neighboring files. Everything handled automatically, except callback() stage. callback(), point cloud exposed data.frame buffer, providing user-defined function spatial context. callback used edit points, everything handled internally. However, R object returned, responsibility user handle buffer. example, following pipeline, processing two files, callback() used count number points. presence triangulate() implies file loaded buffer make valid triangulation. Consequently, counting points callback() returns points summarise() summarise() internal function knows deal buffer. can compare pipeline without triangulate(). case, reason use buffer, files buffered. counts equal. handle buffer, user can read attribute bbox data.frame. contains bounding box point cloud without buffer use column Buffer contains TRUE FALSE point. TRUE, point buffer. buffer exposed user includes letter 'b'. conclusion, hypothesis user-defined function returns something complex, two ways handle buffer: either using bounding box using Buffer flag. third option use drop_buffer. case users ensure receive data.frame include points buffer.","code":"count = function(data) { length(data$X) } del = triangulate(filter = keep_ground()) npts = callback(count, expose = \"x\") sum = summarise() ans = exec(del + npts + sum, on = f) print(ans$callback) #>  - 585020  #>  - 868951 ans$callback[[1]]+ ans$callback[[2]] #> [1] 1453971 ans$summary$npoints #> [1] 1355607 ans = exec(npts + sum, on = f) ans$callback[[1]]+ ans$callback[[2]] #> [1] 1355607 ans$summary$npoints #> [1] 1355607 count_buffer_aware = function(data) {   bbox = attr(data, \"bbox\")   npoints = sum(!data$Buffer)   return(list(bbox = bbox, npoints = npoints)) }  del = triangulate(filter = keep_ground()) npts = callback(count_buffer_aware, expose = \"b\") # b for buffer sum = summarise() ans = exec(del + npts + sum, on = f) print(ans$callback) #>  - List: #>    - bbox : 885022.4 629157.2 885210.2 629400  #>    - npoints : 531662  #>  - List: #>    - bbox : 885024.1 629400 885217.1 629700  #>    - npoints : 823945 ans$callback[[1]]$npoints+ ans$callback[[2]]$npoints #> [1] 1355607 ans$summary$npoints #> [1] 1355607"},{"path":"https://r-lidar.github.io/lasR/articles/r-stages.html","id":"parallelisation","dir":"Articles","previous_headings":"","what":"Parallelisation","title":"R stages","text":"Read multithreading page entering section. R multi-threaded, thus calling stages parallel thread-safe crash R session best case deeply corrupt R memory worst case. Consequently, stages protected run concurrently concurrent-file strategy. stages meant build complex convenient pipelines intend production tools. lasR::rasterize(10, mymetrics(Z, Intensity)) produces output lidR::pixel_metrics(las, mymetrics(Z, Intensity), 10), lidR version faster can parallelized multiple R sessions. lasR, hand, parallelizes computation single R session. approach pros cons won’t discussed tutorial. One con pipelines using injected R code parallelizable default.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"overall-functionality","dir":"Articles","previous_headings":"","what":"Overall functionality","title":"Tutorial","text":"lasR, R functions provided user designed process data directly; instead, used create pipeline. pipeline consists atomic stages applied point cloud order. stage can either transform point cloud within pipeline without generating output process point cloud produce output. figure , 4 LAS/LAZ files pipeline (1) reads file, (2) builds writes DTM disk, (3) transforms point cloud normalizing elevation, (4) builds canopy height model using transformed point cloud, (5) transforms point cloud removing points 5 m. resulting version point cloud (points 5m) discarded lost additional stage pipeline. However, stages can added, application predictive model points 5 m stage writes point cloud disk. first file completes entire pipeline, second file used, pipeline applied fill missing parts geospatial rasters vectors produced pipeline. file loaded buffer neighboring files needed. pipeline created R interface nothing initially. building pipeline, users must call exec() function initiate computation.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"reader","dir":"Articles","previous_headings":"","what":"Reader","title":"Tutorial","text":"reader() stage MUST first stage pipeline (blue figure ). stage reads point cloud. creating pipeline stage, header files read, computation actually applied. result returned. practice using reader() without argument can omitted, function exec adds --fly.","code":"pipeline = reader() exec(pipeline, on = f) #> NULL"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"triangulate","dir":"Articles","previous_headings":"","what":"Triangulate","title":"Tutorial","text":"first stage can try triangulate(). algorithm performs Delaunay triangulation points interest. Triangulating points useful task employed numerous processing tasks. Triangulating points interesting, usually want use filter argument triangulate specific points interest. following example, triangulate points classified 2 (.e., ground). produces meshed Digital Terrain Model. files read sequentially, points loaded one one stored build Delaunay triangulation. program stores point cloud Delaunay triangulation current processing file. data discarded load new file. users provide path output file store result, result lost. following pipeline, building triangulation ground points, get output everything lost. following pipeline triangulation stored geopackage file providing argument ofile:  Notice use keep_ground() shortcut \"Classification == 2\". can also triangulate first returns. produce meshed Digital Surface Model. can also perform triangulations pipeline. idea lasR execute tasks one pass using pipeline: Using triangulate() without stage pipeline usually useful. Typically, triangulate() employed without ofile argument intermediate step. instance, can used rasterize().","code":"pipeline = reader() + triangulate(filter = \"Classification == 2\") ans = exec(pipeline, on = f) ans #> NULL pipeline = reader() + triangulate(filter = keep_ground(), ofile = tempgpkg()) ans = exec(pipeline, on = f) ans #> Simple feature collection with 1 feature and 0 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XYZ #> Bounding box:  xmin: 273357.2 ymin: 5274357 xmax: 273642.9 ymax: 5274643 #> z_range:       zmin: 788.9932 zmax: 814.8322 #> Projected CRS: NAD83(CSRS) / MTM zone 7 #>                             geom #> 1 MULTIPOLYGON Z (((273500.4 ...  par(mar = c(2, 2, 1, 1)) plot(ans, axes = T, lwd = 0.5,  cex.axis = 0.5) read = reader() del = triangulate(filter = keep_first(), ofile = tempgpkg()) ans = exec(read+del, on = f) read = reader() del1 = triangulate(filter = keep_ground(), ofile = tempgpkg()) del2 = triangulate(filter = keep_first(), ofile = tempgpkg()) pipeline = read + del1 + del2 ans = exec(pipeline, on = f)"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"rasterize","dir":"Articles","previous_headings":"","what":"Rasterize","title":"Tutorial","text":"rasterize() exactly users may expect even . three variations: Rasterize Delaunay triangulation. Rasterize predefined operators. operators optimized internally, making operations fast possible. Rasterize injecting user-defined R expression. equivalent pixel_metrics() package lidR. user-defined function can mapped, making extremely versatile slower. variations, users can build CHM, DTM, predictive model, anything else.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"rasterize---triangulation","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - triangulation","title":"Tutorial","text":"Let’s build DTM using triangulation ground points rasterize() stage. following pipeline, LAS files read, points loaded LAS file buffer, Delaunay triangulation ground points built, triangulation interpolated rasterized. default, rasterize() writes raster temporary file, result discarded. , exec() returns one SpatRaster triangulate() returns nothing (NULL). Therefore, pipeline contains two stages, one returns something.  Notice , contrary lidR package, usually high-level function names like rasterize_terrain(). Instead, lasR made low-level atomic stages versatile also challenging use.","code":"# omitting reader() for the example del = triangulate(filter = keep_ground()) dtm = rasterize(1, del) pipeline = del + dtm ans = exec(pipeline, on = f) ans #> class       : SpatRaster  #> size        : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file2a1fb1928c2.tif  #> name        : file2a1fb1928c2 terra::plot(ans, col = gray.colors(25,0,1), mar = c(1, 1, 1, 3))"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"rasterize---internal-metrics","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - internal metrics","title":"Tutorial","text":"Internal metrics strings format attribute_function. attribute attribute point cloud z, classification, intensity. function available metrics function mean, max, sd. following examples valid metric strings: z_max, i_mean, intensity_mean, classification_mode, z_sd. Readers can refer official documentation discover possible combinations. Let’s build two CHMs: one based highest point per pixel resolution 2 meters, second based triangulation first returns resolution 50 cm. following pipeline, using two variations rasterize(): one capable rasterizing triangulation capable rasterizing point cloud predefined operator (max interpreted z_max absence explicit attribute). output named list two SpatRaster.  simplicity package pre-installed pipelines named dsm() dtm() explained .","code":"del <- triangulate(filter = keep_first()) chm1 <- rasterize(2, \"max\") chm2 <- rasterize(0.5, del) pipeline <- del + chm1 + chm2 ans <- exec(pipeline, on = f)  terra::plot(ans[[1]], mar = c(1, 1, 1, 3), col = col) terra::plot(ans[[2]], mar = c(1, 1, 1, 3), col = col)"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"rasterize---r-expression","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - R expression","title":"Tutorial","text":"special case covered special tutorial R-based stages","code":""},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"rasterize---buffered","dir":"Articles","previous_headings":"Rasterize","what":"Rasterize - buffered","title":"Tutorial","text":"lasR package introduced concept buffered area-based approach enhance resolution prediction maps. However, concept covered detail tutorial. information, readers can refer dedicated article","code":""},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"transform-with","dir":"Articles","previous_headings":"","what":"Transform with","title":"Tutorial","text":"Another way use Delaunay triangulation transform point cloud. Users can add subtract triangulation point cloud, effectively normalizing . Unlike lidR package, high-level function names like normalize_points(). Instead, lasR composed low-level atomic stages offer versatility. Let’s normalize point cloud using triangulation ground points (meshed DTM). following example, triangulation used transform_with() modifies point cloud pipeline. triangulate() transform_with() return nothing. output NULL. convenience pipeline pre-recorded package name normalize(). transform_with() can also transform raster rotation matrix. presented tutorial. obtain meaningful output, necessary chain another stage. point cloud modified , discarded nothing . instance, can compute Canopy Height Model (CHM) normalized point cloud. following pipeline, first rasterization (chm1) applied normalization, second rasterization occurs transform_with(), thus applied transformed point cloud.  performing normalization, users may want write normalized point cloud disk later use. case, can append write_las() stage pipeline.","code":"del = triangulate(filter = keep_ground()) norm = transform_with(del, \"-\") pipeline = del + norm ans = exec(pipeline, on = f) ans #> NULL del = triangulate(filter = keep_ground()) norm = transform_with(del, \"-\") chm1 = rasterize(2, \"max\") chm2 = rasterize(2, \"max\") pipeline = chm1 + del + norm + chm2 ans = exec(pipeline, on = f)  col = grDevices::colorRampPalette(c(\"blue\", \"cyan2\", \"yellow\", \"red\"))(15) terra::plot(c(ans[[1]], ans[[2]]), col = col)"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"write-las","dir":"Articles","previous_headings":"","what":"Write LAS","title":"Tutorial","text":"write_las() can called point pipeline. writes one file per input file, using name input files added prefixes suffixes. following pipeline, read files, write ground points files named original files suffix _ground, perform triangulation entire point cloud, followed normalization. Finally, write normalized point cloud suffix _normalized. crucial include wildcard * file path; otherwise, single large file created. behavior may intentional. Let’s consider creating file merge pipeline. following example, wildcard * used names LAS/LAZ files. input files read, points sequentially written single file dataset_merged.laz, naturally forming merge pipeline.","code":"write1 = write_las(paste0(tempdir(), \"/*_ground.laz\"), filter = keep_ground()) write2 = write_las(paste0(tempdir(), \"/*_normalized.laz\"), ) del = triangulate(filter = keep_ground()) norm = transform_with(del, \"-\") pipeline =  write1 + del + norm + write2 ans = exec(pipeline, on = f) ans #>  - write_las : /tmp/RtmpcpemnH/bcts_1_ground.laz /tmp/RtmpcpemnH/bcts_2_ground.laz  #>  - write_las.1 : /tmp/RtmpcpemnH/bcts_1_normalized.laz /tmp/RtmpcpemnH/bcts_2_normalized.laz ofile = paste0(tempdir(), \"/dataset_merged.laz\") merge = reader() + write_las(ofile) ans = exec(merge, on = f) ans #> [1] \"/tmp/RtmpcpemnH/dataset_merged.laz\""},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"local-maximum","dir":"Articles","previous_headings":"","what":"Local maximum","title":"Tutorial","text":"stage works either point cloud raster. following pipeline first stage builds CHM, second stage finds local maxima point cloud second stages finds local maxima chm. lm1 lm2 expected produce relatively close results strictly identical.","code":"chm = rasterize(1, \"max\") lm1 = local_maximum(3) lm2 = local_maximum_raster(chm, 3) pipeline = chm + lm1 + lm2"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"tree-segmentation","dir":"Articles","previous_headings":"","what":"Tree Segmentation","title":"Tutorial","text":"section presents complex pipeline tree segmentation using local_maximum_raster() identify tree tops CHM. uses region_growing() segment trees using seeds produced local_maximum_raster(). Canopy Height Model (CHM) triangulation-based using triangulate() rasterize() first returns. CHM post-processed pit_fill(), algorithm designed enhance CHM filling pits NAs. reader may noticed seeds produced raster one used region_growing(). checked internally ensure seeds matching raster used segmenting trees. tutorial, pipeline tested one file render page faster. However, pipeline can applied number files produce continuous output, managing buffer files. Every intermediate output can exported, tutorial, export everything display outputs.","code":"del = triangulate(filter = keep_first()) chm = rasterize(0.5, del) chm2 = pit_fill(chm) seed = local_maximum_raster(chm2, 3) tree = region_growing(chm2, seed) pipeline = del + chm + chm2 +  seed + tree ans = exec(pipeline, on = f) col = grDevices::colorRampPalette(c(\"blue\", \"cyan2\", \"yellow\", \"red\"))(25) col2 = grDevices::colorRampPalette(c(\"purple\", \"blue\", \"cyan2\", \"yellow\", \"red\", \"green\"))(50) terra::plot(ans$rasterize, col = col, mar = c(1, 1, 1, 3)) terra::plot(ans$pit_fill, col = col, mar = c(1, 1, 1, 3)) terra::plot(ans$region_growing, col = col2[sample.int(50, 277, TRUE)], mar = c(1, 1, 1, 3)) plot(ans$local_maximum$geom, add = T, pch = 19, cex = 0.5)"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"buffer","dir":"Articles","previous_headings":"","what":"Buffer","title":"Tutorial","text":"Point clouds typically stored multiple contiguous files. avoid edge artifacts, file must loaded extra points coming neighboring files. Everything handled automatically.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"hulls","dir":"Articles","previous_headings":"","what":"Hulls","title":"Tutorial","text":"Delaunay triangulation defines convex polygon, represents convex hull points. However, dense point clouds, removing triangles large edges due absence points results complex structure.  hulls() algorithm computes contour mesh, producing concave hull holes:  However hulls() likely used without triangulation. case returns bounding box point cloud file. used triangulate(0) returns convex hull inefficient way get convex hull.","code":"del = triangulate(15, filter = keep_ground(), ofile = tempgpkg()) ans = exec(del, on = f)  par(mar = c(2, 2, 1, 1)) plot(ans, axes = T, lwd = 0.5, cex.axis = 0.5) del = triangulate(15, filter = keep_ground()) bound = hulls(del) ans = exec(del+bound, on = f)  par(mar = c(2, 2, 1, 1)) plot(ans, axes = T, lwd = 0.5, col = \"gray\", cex.axis = 0.5)"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"readers","dir":"Articles","previous_headings":"","what":"Readers","title":"Tutorial","text":"reader() MUST first stage pipeline even can conveniently omitted simplest form. However several readers hidden behind reader(): reader_coverage(): read files process entire point cloud. default behavior reader(). reader_rectangles(): read rectangular regions interest coverage process sequentially. reader_circles(): read circular regions interest coverage process sequentially. following pipeline triangulates ground points, normalizes point cloud, computes metric interest file entire coverage. file loaded buffer triangulation performed without edge artifacts. Notice use drop_buffer = TRUE expose data.frame without buffer used perform triangulation normalization. following pipeline, contrary, works exactly operates circular plots. readers allow building ground inventory pipeline, plot extraction examples","code":"my_metric_fun = function(data) { mean(data$Z) } tri <- triangulate(filter = keep_ground()) trans <- transform_with(tri) norm <- tri + trans metric <- callback(my_metric_fun, expose = \"z\", drop_buffer = TRUE) pipeline = norm + metric pipeline = reader_circles(xcenter, ycenter, 11.28) + pipeline"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"summarise","dir":"Articles","previous_headings":"","what":"Summarise","title":"Tutorial","text":"summarise() stage computes metrics interest entire point cloud, .e., points read. following example, processing four files. stage reports number points, number first returns, histograms, metrics. Like stages, output produced summarise() depends positioning pipeline. Let’s insert sampling stage (described tutorial). can see summarizes point cloud current state pipeline. summarise() can also compute metrics. case, metrics computed entire point cloud (.e., points read) chunk read (.e., file query). feature, example, allows computing metrics plot inventory.","code":"read = reader() summary = summarise() pipeline = read + summary ans = exec(pipeline, on = f) head(ans) #>  - npoints : 2834350  #>  - nsingle : 1233936  #>  - nwithheld : 0  #>  - nsynthetic : 0  #>  - npoints_per_return : 1981696 746460 101739 4455  #>  - npoints_per_class : 2684009 150341 pipeline = summarise() + sampling_voxel(4) + summarise() ans = exec(pipeline, on = f) print(head(ans[[1]])) #>  - npoints : 73403  #>  - nsingle : 31294  #>  - nwithheld : 0  #>  - nsynthetic : 0  #>  - npoints_per_return : 53538 15828 3569 451 16 1  #>  - npoints_per_class : 61347 8159 3897 print(head(ans[[2]])) #>  - npoints : 12745  #>  - nsingle : 5042  #>  - nwithheld : 0  #>  - nsynthetic : 0  #>  - npoints_per_return : 9415 2589 655 79 6 1  #>  - npoints_per_class : 10862 1510 373"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"plot-inventory","dir":"Articles","previous_headings":"","what":"Plot inventory","title":"Tutorial","text":"pipeline extracts plot inventory using shapefile non-normalized point cloud, normalizes plot transform_with(), computes metrics plot using summarise(). also writes normalized non-normalized plot separate files. means , single pass, performs extraction, normalization, saving, computation. circular plot loaded buffer perform correct triangulation, stages natively know handle buffer. means summarise() computes metrics without including buffer points write_las() write buffer points.","code":"ofiles_plot <- paste0(tempdir(), \"/plot_*.las\") ofiles_plot_norm <- paste0(tempdir(), \"/plot_*_norm.las\")  library(sf) inventory <- st_read(\"shapefile.shp\") coordinates <- st_coordinates(inventory) xcenter <- coordinates[,1] ycenter <- coordinates[,2]  read <- reader(xc = xcenter, yc = ycenter, r = 11.28)  tri <- triangulate(filter = keep_ground()) trans <- transform_with(tri) norm <- tri + trans metrics <- summarise(metrics = c(\"z_mean\", \"z_p95\", \"i_median\", \"count\")) write1 <- write_las(ofiles_plot) write2 <- write_las(ofiles_plot_norm)  pipeline = read + write1 + norm + write2"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"wildcard-usage","dir":"Articles","previous_headings":"","what":"Wildcard Usage","title":"Tutorial","text":"Usually, write_las() used wildcard ofile argument (see ) write one file per processed file. Otherwise, everything written single massive LAS file (might desired behavior). contrary, rasterize() used without wildcard write everything single raster file, also accepts wildcard write results multiple files, useful reader_circles() avoid one massive raster mostly empty. Compare pipeline without wildcard. Without wildcard, output single raster covers entire point cloud two patches populated pixels.  wildcard, output contains two rasters cover regions interest.","code":"ofile = paste0(tempdir(), \"/chm.tif\")   # no wildcard  x = c(885100, 885100) y = c(629200, 629600)  pipeline = reader(xc = x, yc = y, r = 20) + rasterize(2, \"max\", ofile = ofile) r0 = exec(pipeline, on = f)  terra::plot(r0, col = col) # covers the entire collection of files ofile = paste0(tempdir(), \"/chm_*.tif\") # wildcard  x = c(885100, 885100) y = c(629200, 629600)  pipeline = reader(xc = x, yc = y, r = 20) + rasterize(2, \"max\", ofile = ofile) ans = exec(pipeline, on = f)  r1 = terra::rast(ans[1]) r2 = terra::rast(ans[2]) terra::plot(r1, col = col) terra::plot(r2, col = col)"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"compatibility-with-lidr","dir":"Articles","previous_headings":"","what":"Compatibility with lidR","title":"Tutorial","text":"lasR depends lidR compatibility . Instead providing paths files folder possible pass LAScatalog LAS object readers. case LAScatalog, exec() respects processing options LAScatalog including chunk size, chunk buffer, progress bar display partial processing. general case, options can supplied arguments exec() functions.","code":"library(lasR) library(lidR)  pipeline = normalize() + write_las()  ctg = readLAScatalog(folder) ans = exec(pipeline, on = ctg)  las = readLAS(file) ans = exec(pipeline, on = las)"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"stop-pipeline-if","dir":"Articles","previous_headings":"","what":"Stop pipeline if","title":"Tutorial","text":"pipeline can long succession stages, may happen want apply entire pipeline every file. case, stop_if stage allows us conditionally stop pipeline anywhere. Let’s assume dataset 100 files pipeline reads, computes hulls, computes DTM. possible compute hulls 100 files DTM reduced region interest defined user stop_if_outside(). stop_if (currently) stage can put reader(). case, reading stage skipped, effectively applying pipeline subset files encompass bounding boxes defined user. Notice pipeline produces output pipeline takes longer compute files processed read anyway. thus preferable put stop_if() reader() specific case. Currently, one stop_if stage conditionally stops pipeline based bounding box condition, easy add options later demand.","code":"read = reader() hll = hulls() tri = triangulate(filter = keep_ground()) dtm = rasterize(1, tri) pipeline = read + hll + tri + dtm stopif <- stop_if_outside(880000, 620000, 885000, 630000) pipeline <- read + hll + stopif + tri + dtm pipeline <- stopif + read + hll + tri + dtm pipeline <- read + stopif + hll + tri + dtm"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"parallel-processing","dir":"Articles","previous_headings":"","what":"Parallel processing","title":"Tutorial","text":"topic covered dedicated article","code":""},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"pre-read-a-point-cloud-in-memory","dir":"Articles","previous_headings":"","what":"Pre-read a point cloud in memory","title":"Tutorial","text":"tutorial seen batch processing mode. also possible load point cloud memory read_cloud() point cloud loaded memory possible apply pipeline . following computing DTM sampling point cloud. output thus raster point cloud modified. See point cloud 73,400 point. applying pipeline object 23,780 points","code":"f <- c(system.file(\"extdata\", \"Topography.las\", package=\"lasR\")) cloud = read_cloud(f) cloud #> Source       : LASF (v1.2) #> Size         : 2.28 MB #> Extent       : 273357.14 273642.86 5274357.14 5274642.85 (xmin, xmax, ymin, ymax) #> Points       : 73.40 thousands #> Area         : 81629.0 m² #> Density      : 0.9 pts/m² #> Coord. ref.  : (null) #> Schema       : #> 17 attributes | 31 bytes per points #>  Name: flags             | uchar  | Desc: Internal 8-bit mask reserved for lasR core engine #>  Name: X                 | int    | Desc: X coordinate #>  Name: Y                 | int    | Desc: Y coordinate #>  Name: Z                 | int    | Desc: Z coordinate #>  Name: Intensity         | ushort | Desc: Pulse return magnitude #>  Name: ReturnNumber      | uchar  | Desc: Pulse return number for a given output pulse #>  Name: NumberOfReturns   | uchar  | Desc: Total number of returns for a given pulse #>  Name: Classification    | uchar  | Desc: The 'class' attributes of a point #>  Name: UserData          | uchar  | Desc: Used at the user’s discretion #>  Name: PointSourceID     | short  | Desc: Source from which this point originated #>  Name: ScanAngle         | char   | Desc: Rounded angle at which the laser point was output #>  Name: gpstime           | double | Desc: Time tag value at which the point was observed #>  Name: EdgeOfFlightline  | bit    | Desc: Set when the point is at the end of a scan #>  Name: ScanDirectionFlag | bit    | Desc: Direction in which the scanner mirror was traveling  #>  Name: Synthetic         | bit    | Desc: Point created by a technique other than direct observation #>  Name: Keypoint          | bit    | Desc: Point is considered to be a model key-point #>  Name: Withheld          | bit    | Desc: Point is supposed to be deleted) pipeline = dtm() + sampling_poisson(2) ans = exec(pipeline, on = cloud) ans #> class       : SpatRaster  #> size        : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. :   #> source      : file2a1f1f18b723.tif  #> name        : file2a1f1f18b723 cloud #> Source       : LASF (v1.2) #> Size         : 737.18 kB #> Extent       : 273357.14 273642.84 5274357.15 5274642.85 (xmin, xmax, ymin, ymax) #> Points       : 23.78 thousands #> Area         : 81623.7 m² #> Density      : 0.3 pts/m² #> Coord. ref.  : (null) #> Schema       : #> 17 attributes | 31 bytes per points #>  Name: flags             | uchar  | Desc: Internal 8-bit mask reserved for lasR core engine #>  Name: X                 | int    | Desc: X coordinate #>  Name: Y                 | int    | Desc: Y coordinate #>  Name: Z                 | int    | Desc: Z coordinate #>  Name: Intensity         | ushort | Desc: Pulse return magnitude #>  Name: ReturnNumber      | uchar  | Desc: Pulse return number for a given output pulse #>  Name: NumberOfReturns   | uchar  | Desc: Total number of returns for a given pulse #>  Name: Classification    | uchar  | Desc: The 'class' attributes of a point #>  Name: UserData          | uchar  | Desc: Used at the user’s discretion #>  Name: PointSourceID     | short  | Desc: Source from which this point originated #>  Name: ScanAngle         | char   | Desc: Rounded angle at which the laser point was output #>  Name: gpstime           | double | Desc: Time tag value at which the point was observed #>  Name: EdgeOfFlightline  | bit    | Desc: Set when the point is at the end of a scan #>  Name: ScanDirectionFlag | bit    | Desc: Direction in which the scanner mirror was traveling  #>  Name: Synthetic         | bit    | Desc: Point created by a technique other than direct observation #>  Name: Keypoint          | bit    | Desc: Point is considered to be a model key-point #>  Name: Withheld          | bit    | Desc: Point is supposed to be deleted)"},{"path":"https://r-lidar.github.io/lasR/articles/tutorial.html","id":"other-stages","dir":"Articles","previous_headings":"","what":"Other stages","title":"Tutorial","text":"lasR several stages mentioned tutorial. Among others: add_extrabytes() add_rgb() callback() classify_with_ivf() classify_with_csf() delete_points() geometry_features() load_raster() pit_fill() write_vpc()","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"rationnale-for-lasr-vs--lidr","dir":"Articles","previous_headings":"","what":"Rationnale for lasR vs. lidR","title":"Why lasR?","text":"need new package addition lidR? Short answer: yes!","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"speed","dir":"Articles","previous_headings":"Rationnale for lasR vs. lidR","what":"Speed","title":"Why lasR?","text":"short answer lies following graph. x-axis represents time perform three different rasterizations (CHM, DTM, density map), y-axis represents amount RAM memory used lidR lasR (details benchmark vignette). lasR intended much efficient lidR terms memory usage computation times.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"pipeline","dir":"Articles","previous_headings":"Rationnale for lasR vs. lidR","what":"Pipeline","title":"Why lasR?","text":"second issue absence powerful pipeline engine lidR. Performing task simple extracting deriving metrics multiple inventory plots non-normalized collection files easy lidR. straightforward point cloud normalized, , users must write complex custom script. introduction real pipelines, lasR enables users complex tasks easier way (see tutorial vignette well pipeline vignette).","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"r-binding","dir":"Articles","previous_headings":"Rationnale for lasR vs. lidR","what":"R binding","title":"Why lasR?","text":"Last least, lidR closely tied R can exist R package. lasR, hand, standalone software. R component lasR merely API, APIs may exist. plan develop python package, QGIS plugin, standalone GUI software future. current state, lasR available R package.","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"pipeline-1","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Pipeline","title":"Why lasR?","text":"lasR introduces versatile pipeline engine, enabling creation complex processing pipelines. Users can simultaneously create ABA compute DTM one read pass, leading significant speed-.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"data-loading","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Data loading","title":"Why lasR?","text":"Unlike lidR, lasR load lidar data data.frame. designed efficient data processing, memory management C++ level. Consequently, read_las() function. Everything internally efficiently stored C++ structure keeps data compact memory. However, entry points available inject user-defined R code C++ pipeline.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"dependencies","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Dependencies","title":"Why lasR?","text":"lasR 0 dependency. doesn’t even depend Rcpp. lasR use terra sf R level reading writing spatial data; instead, links GDAL. terra sf installed, output files read packages. Due absence dependency R package non-loading data R objects, also dependency rgl, resulting interactive 3D viewer like lidR.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"code","dir":"Articles","previous_headings":"Main differences between lasR and lidR","what":"Code","title":"Why lasR?","text":"lasR written 100% C++ contains R code. utilizes source code lidR significant improvements. major improvements observed benchmark much source code rather organization code, .e., longer using data.frame, memory management C++ rather R, processing R level, pipelines, .","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"should-i-use-lidr-or-lasr","dir":"Articles","previous_headings":"","what":"Should I use lidR or lasR?","title":"Why lasR?","text":"question actually pretty simple answer. want explore, manipulate, test, try, retry, implement new ideas mind, use lidR. know want, want relatively common (raster metrics, DTM, CHM, tree location), especially want large coverage, use lasR.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"example-1","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 1","title":"Why lasR?","text":"received 500 km² data, want CHM DTM. → Use lasR compute fast possible.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"example-2","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 2","title":"Why lasR?","text":"want segment trees, explore different methods, test different parameters small plots. Maybe integrate custom step, ’s exploratory process. → Use lidR.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"example-3","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 3","title":"Why lasR?","text":"want extract circular ground inventories compute metrics plot. → dataset already normalized, can use either lasR lidR; pretty much equivalent. lidR easier use; lasR little bit efficient difficult use (yet pipeline vignette contains copy-pastable code ). dataset normalized, lasR much simpler case, thanks pipeline processor allows adding normalization stage computing metrics.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"example-4","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 4","title":"Why lasR?","text":"want create complex pipeline computes local shape points classify roofs wires point cloud. using shapefile, want classify water point cloud. finish, want write new classified LAS files. → Use lidR. lasR many tools. lasR lidR; much efficient less versatile fewer tools.","code":""},{"path":"https://r-lidar.github.io/lasR/articles/why.html","id":"example-5","dir":"Articles","previous_headings":"Should I use lidR or lasR?","what":"Example 5","title":"Why lasR?","text":"want find segment trees common algorithm. Nothing fancy. want 100 km² . → Use lasR. lidR probably fail .","code":""},{"path":"https://r-lidar.github.io/lasR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jean-Romain Roussel. Author, maintainer, copyright holder. Martin Isenburg. Copyright holder.           author included LASlib LASzip libraries Benoît St-Onge. Copyright holder.           author included 'chm_prep' function Niels Lohmann. Copyright holder.           author included json parser Volodymyr Bilonenko. Copyright holder.           author included delaunator triangulation State Key Laboratory Remote Sensing Science, Institute Remote Sensing Science Engineering, Beijing Normal University. Copyright holder.           copyright holder included CSF Authors Eigen. Copyright holder.           Authorship copyright included Eigen library detailed inst/COPYRIGHTS Marius Muja. Copyright holder.           author included nanoflann library David G. Lowe. Copyright holder.           author included nanoflann library Jose L. Blanco. Copyright holder.           author included nanoflann library","code":""},{"path":"https://r-lidar.github.io/lasR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Roussel J (2025). lasR: Fast Pipeable Airborne LiDAR Data Tools. R package version 0.17.2, https://github.com/r-lidar/lasR.","code":"@Manual{,   title = {lasR: Fast and Pipeable Airborne LiDAR Data Tools},   author = {Jean-Romain Roussel},   year = {2025},   note = {R package version 0.17.2},   url = {https://github.com/r-lidar/lasR}, }"},{"path":"https://r-lidar.github.io/lasR/index.html","id":"lasr-","dir":"","previous_headings":"","what":"Fast and Pipeable Airborne LiDAR Data Tools","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"Fast Airborne LiDAR Data Processing lasr library (pronounced “laser”) C++ library large scale airborne point cloud processing C++, R Python APIs. enables creation execution complex processing pipelines massive lidar data. can read write .las, .laz .pcd files, compute metrics using area-based approach, generate digital canopy models, segment individual trees, decimate point data, process collections files using multicore processing strategies. lasr offers range tools process massive volumes lidar data efficiently production environment using either C++ API, R API (lasR package) Python API (pylasr package). 💵 Sponsor lasr. free open source, requires time effort develop maintain.","code":""},{"path":"https://r-lidar.github.io/lasR/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"📖 Start tutorial learn use lasR R. 🐍 Python users, see Python documentation examples. comprehensive source documentation R package lasR documentation, lasr primarily R package. Even Python users start R tutorial, examples written R, tutorial general concepts coding.","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/index.html","id":"r-api","dir":"","previous_headings":"APIs","what":"R API","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"current plan release lasR CRAN. Instead, hosted r-universe: Since lasR available CRAN, users rely CRAN versioning system RStudio update button get latest version. Instead, lasR loaded library(lasR), internal routine checks latest version notifies user update available. approach allows frequent updates, ensuring users access newest features bug fixes without waiting formal release cycle.","code":"install.packages('lasR', repos = 'https://r-lidar.r-universe.dev') library(lasR) #> lasR 0.1.3 is now available. You are using 0.1.1 #> install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')"},{"path":"https://r-lidar.github.io/lasR/index.html","id":"python-api","dir":"","previous_headings":"APIs","what":"Python API","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"pylasr Python API lasr, providing clean, Pythonic interface high-performance C++ library processing large-scale LiDAR point clouds. Prerequisites Python 3.9+ C++17 compatible compiler GDAL (>= 2.2.3), GEOS (>= 3.4.0), PROJ (>= 4.9.3) Build source Pre-built packages available PyPI future. now, please build source.","code":"git clone https://github.com/r-lidar/lasR.git cd lasR/python pip install -e ."},{"path":"https://r-lidar.github.io/lasR/index.html","id":"c-api","dir":"","previous_headings":"APIs","what":"C++ API","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"use lasr C++ program, must linked gdal proj. dependencies provided vendor directory. Tools available public given api.h.","code":""},{"path":"https://r-lidar.github.io/lasR/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"simple example pipeline classifies removed outliers produce Digital Surface Model Digital Terrain Model folder containing airborne LiDAR point clouds. examples see tutorial.","code":""},{"path":"https://r-lidar.github.io/lasR/index.html","id":"r","dir":"","previous_headings":"Examples","what":"R","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"","code":"library(lasR) folder = \"/folder/of/laz/tiles/\" pipeline = classify_with_sor() + delete_noise() + chm(1) + dtm(1) exec(pipeline, on = folder, ncores = 16, progress = TRUE)"},{"path":"https://r-lidar.github.io/lasR/index.html","id":"python","dir":"","previous_headings":"Examples","what":"Python","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"","code":"import pylasr folder = \"/folder/of/laz/tiles/\" pipeline = (pylasr.classify_with_sor() +              pylasr.delete_points([\"Classification == 18\"]) +              pylasr.dsm(1, \"dsm.tif\") +              pylasr.dtm(1, \"dtm.tif\"))  pipeline.set_progress(True) pipeline.set_concurrent_files_strategy(16) result = pipeline.execute(folder)"},{"path":"https://r-lidar.github.io/lasR/index.html","id":"c","dir":"","previous_headings":"Examples","what":"C++","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"C++ API significantly complex use. R Python APIs aim provide high-level interfaces high-level languages, making usages simpler user-friendly. low-level C++ API never intended standalone use; instead, serves bridge building high-level APIs.","code":"#include \"api.h\"  using namespace api;  std::string on = \"/folder/of/laz/tiles/\"  // platform independent tmp files std::filesystem::path temp_dir = std::filesystem::temp_directory_path(); std::filesystem::path temp_dsm = temp_dir / \"dsm.tif\"; std::filesystem::path temp_dtm = temp_dir / \"dtm.tif\";  Pipeline tri = triangulate(0, {\"Classification %in% 2 9\"}); Pipeline dtm = rasterize_triangulation(tri.get_stages().front().get_uid(), 1, temp_dtm.string());  Pipeline p; p += classify_with_sor(); p += delete_points({\"Classification == 18\"}); p += rasterize(1, 1, {\"max\"}, {\"\"}, temp_dsm.string()); p += tri; p += dtm;  p.set_files(on); p.set_concurrent_files_strategy(8); p.set_progress(false);  std::string file = p.write_json();  return execute(file);"},{"path":"https://r-lidar.github.io/lasR/index.html","id":"main-differences-with-lidr","dir":"","previous_headings":"","what":"Main Differences with lidR","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"following benchmark compares time RAM usage lasR (R API) lidR producing Digital Terrain Model (DTM), Canopy Height Model (CHM), raster containing two metrics derived elevation (Z) intensity. test conducted 120 million points stored 4 LAZ files. details, check benchmark vignette.  Pipelines: lasR introduces pipelines optimally chain multiple operations point cloud, feature available lidR. Algorithm Efficiency: lasR uses powerful algorithms designed speed efficiency. Language Performance: Entirely written C/C++, lasR R code except API interface. makes highly optimized performance. Memory Usage: Unlike lidR, loads point cloud R data.frame, lasR stores point clouds C++ structure exposed user, minimizing memory usage. Dependencies: lasR single strong dependency gdal. sf terra installed, user experience enhanced, mandatory. details, see relevant vignette.","code":""},{"path":"https://r-lidar.github.io/lasR/index.html","id":"copyright-information","dir":"","previous_headings":"","what":"Copyright Information","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"lasr free open source relies free open source tools. © 2023-2025 Jean-Romain Roussel Licence: GPL-3 © 2023-2025 Jean-Romain Roussel Licence: GPL-3 © 2025 Alexey Grigoryev Licence: GPL-3 © 2007-2021 Martin Isenburg - http://rapidlasso.com Licence: LGPL (modified R-compliant Jean-Romain Roussel) See dedicated readme details modifications made alternative linking. © 2008-2023 Benoît St-Onge - Geophoton-inc/chm_prep Licence: GPL-3 Lohmann, N. (2023). JSON Modern C++ (Version 3.11.3) [Computer software]. https://github.com/nlohmann Licence: MIT © 2018 Volodymyr Bilonenko. delfrrr/delaunator-cpp Licence: MIT Guennebaud, Gaël Jacob, Benoît others Eigen: C++ linear algebra library http://eigen.tuxfamily.org Licence: MPL2 © 2017 State Key Laboratory Remote Sensing Science, Institute Remote Sensing Science Engineering, Beijing Normal University Licence: Apache W. Zhang, J. Qi, P. Wan, H. Wang, D. Xie, X. Wang, G. Yan, “Easy--Use Airborne LiDAR Data Filtering Method Based Cloth Simulation,” Remote Sens., vol. 8, . 6, p. 501, 2016.","code":""},{"path":"https://r-lidar.github.io/lasR/index.html","id":"about","dir":"","previous_headings":"","what":"About","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"lasr developed openly r-lidar. initial development lasr made possible financial support Laval University. continue development free software, now offer consulting, programming, training services. information, please visit website.","code":""},{"path":"https://r-lidar.github.io/lasR/index.html","id":"install-dependencies-on-gnulinux","dir":"","previous_headings":"","what":"Install dependencies on GNU/Linux","title":"Fast and Pipeable Airborne LiDAR Data Tools","text":"","code":"sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable sudo apt-get update sudo apt-get install libgdal-dev libgeos-dev libproj-dev"},{"path":"https://r-lidar.github.io/lasR/reference/add_attribute.html","id":null,"dir":"Reference","previous_headings":"","what":"Add attributes to a point cloud — add_extrabytes","title":"Add attributes to a point cloud — add_extrabytes","text":"Modify memory layout point cloud add attributes point cloud. Values zeroed: underlying point cloud edited support new extrabyte attribute. new attribute can populated later another stage","code":""},{"path":"https://r-lidar.github.io/lasR/reference/add_attribute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add attributes to a point cloud — add_extrabytes","text":"","code":"add_extrabytes(data_type, name, description, scale = 1, offset = 0)  remove_attribute(name)"},{"path":"https://r-lidar.github.io/lasR/reference/add_attribute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add attributes to a point cloud — add_extrabytes","text":"data_type character. data type extra bytes attribute. Can \"uchar\", \"char\", \"ushort\", \"short\", \"uint\", \"int\", \"uint64\", \"int64\", \"float\", \"double\". name character. name extra bytes attribute add remove file. description character. short description extra bytes attribute add file (32 characters). scale, offset numeric. scale offset data. See LAS specification. Leave unchanged working LAS files.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/add_attribute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add attributes to a point cloud — add_extrabytes","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/add_attribute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add attributes to a point cloud — add_extrabytes","text":"","code":"f <- system.file(\"extdata\", \"Example.las\", package = \"lasR\") fun <- function(data) { data$RAND <- runif(nrow(data), 0, 100); return(data) } pipeline <- reader() +   add_extrabytes(\"float\", \"RAND\", \"Random numbers\") +   callback(fun, expose = \"xyz\") exec(pipeline, on = f) #> NULL"},{"path":"https://r-lidar.github.io/lasR/reference/add_rgb.html","id":null,"dir":"Reference","previous_headings":"","what":"Add RGB attributes to a LAS file — add_rgb","title":"Add RGB attributes to a LAS file — add_rgb","text":"Modifies LAS format convert format RGB attributes. Values zeroed: underlying point cloud edited transformed format supports RGB. RGB can populated later another stage. point cloud already RGB, nothing happens, RGB values preserved.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/add_rgb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add RGB attributes to a LAS file — add_rgb","text":"","code":"add_rgb()"},{"path":"https://r-lidar.github.io/lasR/reference/add_rgb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add RGB attributes to a LAS file — add_rgb","text":"stage transforms point cloud pipeline returns nothing. Otherwise returns R object returned function 'fun'","code":""},{"path":"https://r-lidar.github.io/lasR/reference/add_rgb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add RGB attributes to a LAS file — add_rgb","text":"","code":"f <- system.file(\"extdata\", \"Example.las\", package=\"lasR\")  pipeline <- add_rgb() + write_las() exec(pipeline, on = f) #> [1] \"/tmp/Rtmp5kcE0j/Example.las\""},{"path":"https://r-lidar.github.io/lasR/reference/callback.html","id":null,"dir":"Reference","previous_headings":"","what":"Call a user-defined function on the point cloud — callback","title":"Call a user-defined function on the point cloud — callback","text":"Call user-defined function point cloud. function receives data.frame point cloud. first input must point cloud. function returns anything data.frame number points, output stored returned end. However, output data.frame number points, updates point cloud. function can, therefore, used modify point cloud using user-defined function. function versatile complex. comprehensive set examples can found online tutorial.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/callback.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call a user-defined function on the point cloud — callback","text":"","code":"callback(fun, expose = \"xyz\", ..., drop_buffer = FALSE, no_las_update = FALSE)"},{"path":"https://r-lidar.github.io/lasR/reference/callback.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call a user-defined function on the point cloud — callback","text":"fun function. user-defined function takes first argument data.frame exposed point cloud attributes (see examples). expose character. Expose attributes interest save memory (see details). ... parameters function fun drop_buffer bool. false, expose point buffer. no_las_update bool. user-defined function returns data.frame, supposed update point cloud. Can disabled.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/callback.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Call a user-defined function on the point cloud — callback","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/callback.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Call a user-defined function on the point cloud — callback","text":"lasR, point cloud exposed R data.frame like lidR. stored internally C++ structure seen modified directly users using R code. callback function stage allows direct interaction point cloud copying temporarily data.frame apply user-defined function.expose: 'expose' argument specifies data actually exposed R. example, 'xyzia' means x, y, z coordinates, intensity, scan angle exposed. supported entries t - gpstime, - scan angle, - intensity, n - number returns, r - return number, c - classification, u - user data, p - point source ID, e - edge flight line flag, R - red channel RGB color, G - green channel RGB color, B - blue channel RGB color, N - near-infrared channel, C - scanner channel (format 6+) Also numbers 1 9 extra attributes data numbers 1 9. 'E' enables extra attribute loaded. '*' wildcard enables everything exposed point cloud","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/reference/callback.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Call a user-defined function on the point cloud — callback","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package = \"lasR\")  # There is no function in lasR to read the data in R. Let's create one read_las <- function(f) {   load <- function(data) { return(data) }   read <- reader()   call <- callback(load, expose = \"xyzi\", no_las_update = TRUE)   return (exec(read + call, on = f)) } las <- read_las(f) head(las) #>          X       Y        Z Intensity #> 1 273357.1 5274360 806.5340      1340 #> 2 273357.2 5274359 806.5635       728 #> 3 273357.2 5274358 806.0248      1369 #> 4 273357.2 5274510 809.6303       589 #> 5 273357.2 5274509 809.3880      1302 #> 6 273357.2 5274508 809.4847       123  convert_intensity_in_range <- function(data, min, max) {   i <- data$Intensity   i <- ((i - min(i)) / (max(i) - min(i))) * (max - min) + min   i[i < min] <- min   i[i > max] <- max   data$Intensity <- as.integer(i)   return(data) }  read <- reader() call <- callback(convert_intensity_in_range, expose = \"i\", min = 0, max = 255) write <- write_las() pipeline <- read + call + write ans <- exec(pipeline, on = f)  las <- read_las(ans) head(las) #>          X       Y        Z Intensity #> 1 273357.1 5274360 806.5340       137 #> 2 273357.2 5274359 806.5635        72 #> 3 273357.2 5274358 806.0248       140 #> 4 273357.2 5274510 809.6303        57 #> 5 273357.2 5274509 809.3880       133 #> 6 273357.2 5274508 809.4847         7"},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_csf.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify ground points — classify_with_csf","title":"Classify ground points — classify_with_csf","text":"Classify points using Cloth Simulation Filter Zhang et al. (2016) (see references) relies authors' original source code. point cloud already ground points, classification original ground point set zero. stage modifies point cloud pipeline produce output.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_csf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify ground points — classify_with_csf","text":"","code":"classify_with_csf(   slope_smooth = FALSE,   class_threshold = 0.5,   cloth_resolution = 0.5,   rigidness = 1L,   iterations = 500L,   time_step = 0.65,   ...,   class = 2L,   filter = \"\" )"},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_csf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify ground points — classify_with_csf","text":"slope_smooth logical. steep slopes exist, set parameter TRUE reduce errors post-processing. class_threshold scalar. distance simulated cloth classify point cloud ground non-ground. default 0.5. cloth_resolution scalar. distance particles cloth. usually set average distance points point cloud. default value 0.5. rigidness integer. rigidness cloth. 1 stands soft (fit rugged terrain), 2 stands medium, 3 stands hard cloth (flat terrain). default 1. iterations integer. Maximum iterations simulating cloth. default value 500. Usually, need change value. time_step scalar. Time step simulating cloth gravity. default value 0.65. Usually, need change value. suitable cases. ... Unused class integer. classification attribute points. Usually 2 ground points. filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_csf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classify ground points — classify_with_csf","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_csf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Classify ground points — classify_with_csf","text":"W. Zhang, J. Qi*, P. Wan, H. Wang, D. Xie, X. Wang, G. Yan, “Easy--Use Airborne LiDAR Data Filtering Method Based Cloth Simulation,” Remote Sens., vol. 8, . 6, p. 501, 2016. (http://www.mdpi.com/2072-4292/8/6/501/htm)","code":""},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_csf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classify ground points — classify_with_csf","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline = classify_with_csf(TRUE, 1 ,1, time_step = 1) + write_las() ans = exec(pipeline, on = f, progress = TRUE) #> Read files headers: [==========] 100% (1 threads)                     Overall: [          ] 0% (1 threads) | : no progress                      Overall: [          ] 0% (1 threads) | read_las: [          ] 0% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 1% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 2% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 3% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 4% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 5% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 6% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 7% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 8% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 9% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 10% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 11% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 12% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 13% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 14% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 15% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 16% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 17% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 18% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 19% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 20% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 21% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 22% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 23% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 24% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 25% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 26% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 27% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 28% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 29% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 30% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 31% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 32% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 33% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 34% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 35% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 36% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 37% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 38% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 39% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 40% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 41% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 42% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 43% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 44% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 45% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 46% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 47% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 48% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 49% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 50% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 51% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 52% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 53% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 54% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 55% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 56% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 57% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 58% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 59% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 60% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 61% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 62% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 63% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 64% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 65% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 66% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 67% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 68% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 69% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 70% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 71% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 72% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 73% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 74% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 75% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 76% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 77% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 78% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 79% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 80% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 81% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 82% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 83% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 84% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 85% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 86% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 87% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 88% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 89% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 90% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 91% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 92% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 93% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 94% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 95% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 96% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 97% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 98% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 99% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==========] 100% (1 threads)                     Overall: [          ] 0% (1 threads) | CSF: no progress                      Overall: [          ] 0% (1 threads) | Write LAS: [          ] 0% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 1% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 2% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 3% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 4% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 5% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 6% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 7% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 8% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [          ] 9% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 10% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 11% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 12% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 13% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 14% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 15% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 16% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 17% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 18% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=         ] 19% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 20% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 21% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 22% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 23% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 24% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 25% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 26% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 27% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 28% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==        ] 29% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 30% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 31% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 32% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 33% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 34% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 35% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 36% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 37% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 38% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [===       ] 39% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 40% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 41% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 42% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 43% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 44% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 45% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 46% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 47% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 48% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [====      ] 49% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 50% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 51% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 52% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 53% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 54% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 55% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 56% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 57% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 58% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=====     ] 59% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 60% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 61% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 62% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 63% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 64% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 65% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 66% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 67% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 68% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [======    ] 69% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 70% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 71% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 72% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 73% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 74% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 75% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 76% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 77% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 78% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [=======   ] 79% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 80% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 81% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 82% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 83% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 84% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 85% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 86% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 87% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 88% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========  ] 89% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 90% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 91% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 92% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 93% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 94% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 95% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 96% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 97% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 98% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [========= ] 99% (1 threads)                     Overall: [          ] 0% (1 threads) | Write LAS: [==========] 100% (1 threads)                     Overall: [==========] 100% (1 threads) |                      Overall: [==========] 100% (1 threads)"},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_ivf.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify noise points — classify_with_ivf","title":"Classify noise points — classify_with_ivf","text":"Classify points using Isolated Voxel Filter (IVF). stage identifies points points surrounding 3 x 3 x 3 = 27 voxels edits points assign target classification. Used class 18, classifies points noise. stage modifies point cloud pipeline produce output.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_ivf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify noise points — classify_with_ivf","text":"","code":"classify_with_ivf(res = 5, n = 6L, class = 18L)"},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_ivf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify noise points — classify_with_ivf","text":"res numeric. Resolution voxels. n integer. maximal number 'points' 27 voxels. class integer. class assign points match condition.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_ivf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classify noise points — classify_with_ivf","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_sor.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify noise points — classify_with_sor","title":"Classify noise points — classify_with_sor","text":"Classify points using Statistical Outliers Removal (SOR) methods first described PCL library also implemented CloudCompare (see references). point, computes mean distance k-nearest neighbors. points farther average distance plus number times (multiplier) standard deviation considered noise.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_sor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify noise points — classify_with_sor","text":"","code":"classify_with_sor(k = 8, m = 6, class = 18L)"},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_sor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify noise points — classify_with_sor","text":"k numeric. number neighbours m numeric. Multiplier. maximum distance : ⁠avg distance + m * std deviation⁠ class integer. class assign points match condition.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/classify_with_sor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classify noise points — classify_with_sor","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/delete_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter and delete points — delete_points","title":"Filter and delete points — delete_points","text":"stage modifies point cloud pipeline produce output. Points matching `filter` criteria **processed**. case, means deleted. **Note:** versions < 0.17, behavior opposite.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/delete_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter and delete points — delete_points","text":"","code":"delete_points(filter = \"\")  delete_noise()  delete_ground()"},{"path":"https://r-lidar.github.io/lasR/reference/delete_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter and delete points — delete_points","text":"filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/delete_points.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter and delete points — delete_points","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/delete_points.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter and delete points — delete_points","text":"","code":"f <- system.file(\"extdata\", \"Megaplot.las\", package=\"lasR\") read <- reader() filter <- delete_points(\"Z < 4\") # Remove points below 4  pipeline <- read + summarise() + filter + summarise() exec(pipeline, on = f) #> $summary #> $summary$npoints #> [1] 81590 #>  #> $summary$nsingle #> [1] 34337 #>  #> $summary$nwithheld #> [1] 0 #>  #> $summary$nsynthetic #> [1] 0 #>  #> $summary$npoints_per_return #>     1     2     3     4  #> 55756 21493  3999   342  #>  #> $summary$npoints_per_class #>     1     2  #> 74201  7389  #>  #> $summary$z_histogram #>     0     2     4     6     8    10    12    14    16    18    20    22    24  #> 11031  1256  2476  3994  4295  4898  5943  7115  8557  9934 10353  7520  3156  #>    26    28    30  #>   955   103     4  #>  #> $summary$i_histogram #>     0    50   100   150   200   250   300   350   400   450   500   550   600  #> 43359 37956   204    42    16     6     2     0     1     1     2     0     1  #>  #> $summary$crs #> [1] \"PROJCRS[\\\"NAD83 / UTM zone 17N\\\",BASEGEOGCRS[\\\"NAD83\\\",DATUM[\\\"North American Datum 1983\\\",ELLIPSOID[\\\"GRS 1980\\\",6378137,298.257222101,LENGTHUNIT[\\\"metre\\\",1]]],PRIMEM[\\\"Greenwich\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],ID[\\\"EPSG\\\",4269]],CONVERSION[\\\"UTM zone 17N\\\",METHOD[\\\"Transverse Mercator\\\",ID[\\\"EPSG\\\",9807]],PARAMETER[\\\"Latitude of natural origin\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8801]],PARAMETER[\\\"Longitude of natural origin\\\",-81,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8802]],PARAMETER[\\\"Scale factor at natural origin\\\",0.9996,SCALEUNIT[\\\"unity\\\",1],ID[\\\"EPSG\\\",8805]],PARAMETER[\\\"False easting\\\",500000,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8806]],PARAMETER[\\\"False northing\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8807]]],CS[Cartesian,2],AXIS[\\\"(E)\\\",east,ORDER[1],LENGTHUNIT[\\\"metre\\\",1]],AXIS[\\\"(N)\\\",north,ORDER[2],LENGTHUNIT[\\\"metre\\\",1]],USAGE[SCOPE[\\\"Engineering survey, topographic mapping.\\\"],AREA[\\\"North America - between 84°W and 78°W - onshore and offshore. Canada - Nunavut; Ontario; Quebec. United States (USA) - Florida; Georgia; Kentucky; Maryland; Michigan; New York; North Carolina; Ohio; Pennsylvania; South Carolina; Tennessee; Virginia; West Virginia.\\\"],BBOX[23.81,-84,84,-78]],ID[\\\"EPSG\\\",26917]]\" #>  #> $summary$epsg #> [1] 26917 #>  #>  #> $summary.1 #> $summary.1$npoints #> [1] 68328 #>  #> $summary.1$nsingle #> [1] 26693 #>  #> $summary.1$nwithheld #> [1] 0 #>  #> $summary.1$nsynthetic #> [1] 0 #>  #> $summary.1$npoints_per_return #>     1     2     3     4  #> 47919 18297  2058    54  #>  #> $summary.1$npoints_per_class #>     1  #> 68328  #>  #> $summary.1$z_histogram #>     4     6     8    10    12    14    16    18    20    22    24    26    28  #>  1501  3994  4295  4898  5943  7115  8557  9934 10353  7520  3156   955   103  #>    30  #>     4  #>  #> $summary.1$i_histogram #>     0    50  #> 34738 33590  #>  #> $summary.1$crs #> [1] \"PROJCRS[\\\"NAD83 / UTM zone 17N\\\",BASEGEOGCRS[\\\"NAD83\\\",DATUM[\\\"North American Datum 1983\\\",ELLIPSOID[\\\"GRS 1980\\\",6378137,298.257222101,LENGTHUNIT[\\\"metre\\\",1]]],PRIMEM[\\\"Greenwich\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],ID[\\\"EPSG\\\",4269]],CONVERSION[\\\"UTM zone 17N\\\",METHOD[\\\"Transverse Mercator\\\",ID[\\\"EPSG\\\",9807]],PARAMETER[\\\"Latitude of natural origin\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8801]],PARAMETER[\\\"Longitude of natural origin\\\",-81,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8802]],PARAMETER[\\\"Scale factor at natural origin\\\",0.9996,SCALEUNIT[\\\"unity\\\",1],ID[\\\"EPSG\\\",8805]],PARAMETER[\\\"False easting\\\",500000,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8806]],PARAMETER[\\\"False northing\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8807]]],CS[Cartesian,2],AXIS[\\\"(E)\\\",east,ORDER[1],LENGTHUNIT[\\\"metre\\\",1]],AXIS[\\\"(N)\\\",north,ORDER[2],LENGTHUNIT[\\\"metre\\\",1]],USAGE[SCOPE[\\\"Engineering survey, topographic mapping.\\\"],AREA[\\\"North America - between 84°W and 78°W - onshore and offshore. Canada - Nunavut; Ontario; Quebec. United States (USA) - Florida; Georgia; Kentucky; Maryland; Michigan; New York; North Carolina; Ohio; Pennsylvania; South Carolina; Tennessee; Virginia; West Virginia.\\\"],BBOX[23.81,-84,84,-78]],ID[\\\"EPSG\\\",26917]]\" #>  #> $summary.1$epsg #> [1] 26917 #>  #>"},{"path":"https://r-lidar.github.io/lasR/reference/deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated — deprecated","title":"Deprecated — deprecated","text":"Use reader instead.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated — deprecated","text":"","code":"reader_las(filter = \"\", select = \"*\", copc_depth = NULL, ...)  reader_las_coverage(filter = \"\", select = \"*\", copc_depth = NULL, ...)  reader_las_circles(   xc,   yc,   r,   filter = \"\",   select = \"*\",   copc_depth = NULL,   ... )  reader_las_rectangles(   xmin,   ymin,   xmax,   ymax,   filter = \"\",   select = \"*\",   copc_depth = NULL,   ... )"},{"path":"https://r-lidar.github.io/lasR/reference/deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated — deprecated","text":"filter see reader select, copc_depth see reader ... see reader xc, yc, r see reader xmin, xmax, ymin, ymax see reader","code":""},{"path":"https://r-lidar.github.io/lasR/reference/dsm.html","id":null,"dir":"Reference","previous_headings":"","what":"Digital Surface Model — dsm","title":"Digital Surface Model — dsm","text":"Digital Surface Model using triangulate rasterize. chm() alias dsm() misleading actually computes DSM include normalization step. chm() deprecated. Technically dsm(tin = TRUE) simply association stage triangulate() rasterize() dsm(tin = FALSE) simply alias rasterize(\"max\").","code":""},{"path":"https://r-lidar.github.io/lasR/reference/dsm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Digital Surface Model — dsm","text":"","code":"dsm(res = 1, tin = FALSE, ofile = tempfile(fileext = \".tif\"))  chm(res = 1, tin = FALSE, ofile = tempfile(fileext = \".tif\"))"},{"path":"https://r-lidar.github.io/lasR/reference/dsm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Digital Surface Model — dsm","text":"res numeric. resolution raster. tin bool. default DSM point--raster based methods .e. pixel assigned elevation highest point. tin = TRUE CHM triangulation-based model. first returns triangulated interpolated. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/reference/dsm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Digital Surface Model — dsm","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline <- reader() + dsm() exec(pipeline, on = f) #> class       : SpatRaster  #> size        : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file25df63a8ba7.tif  #> name        : max"},{"path":"https://r-lidar.github.io/lasR/reference/dtm.html","id":null,"dir":"Reference","previous_headings":"","what":"Digital Terrain Model — dtm","title":"Digital Terrain Model — dtm","text":"Create Digital Terrain Model using triangulate rasterize.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/dtm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Digital Terrain Model — dtm","text":"","code":"dtm(res = 1, add_class = NULL, ofile = temptif())"},{"path":"https://r-lidar.github.io/lasR/reference/dtm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Digital Terrain Model — dtm","text":"res numeric. resolution raster. add_class integer. default triangulates using ground water points (classes 2 9). possible provide additional classes. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/reference/dtm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Digital Terrain Model — dtm","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline <- reader() + dtm() exec(pipeline, on = f) #> class       : SpatRaster  #> size        : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file25df77f0faac.tif  #> name        : file25df77f0faac"},{"path":"https://r-lidar.github.io/lasR/reference/edit_attribute.html","id":null,"dir":"Reference","previous_headings":"","what":"Edit an attribute of the points — edit_attribute","title":"Edit an attribute of the points — edit_attribute","text":"Edit attribute points filtering point based criteria.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/edit_attribute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Edit an attribute of the points — edit_attribute","text":"","code":"edit_attribute(filter = \"\", attribute = \"\", value = 0)"},{"path":"https://r-lidar.github.io/lasR/reference/edit_attribute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Edit an attribute of the points — edit_attribute","text":"filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters. attribute string. name attribute edit value numeric. value assign. careful, user try assign value range representable value given data type clamped.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/edit_attribute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Edit an attribute of the points — edit_attribute","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/edit_attribute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Edit an attribute of the points — edit_attribute","text":"","code":"f <- system.file(\"extdata\", \"Example.las\", package=\"lasR\")  edit = edit_attribute(filter = c(\"Z < 975\", \"Z > 974\"), attribute = \"UserData\", value = 2) io = write_las(templas()) pipeline = edit + io ans = exec(pipeline, on = f)"},{"path":"https://r-lidar.github.io/lasR/reference/exec.html","id":null,"dir":"Reference","previous_headings":"","what":"Process the pipeline — exec","title":"Process the pipeline — exec","text":"Process pipeline. Every functions package nothing. function must called pipeline order actually process point-cloud. process parallel using multiple cores, refer multithreading page.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/exec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process the pipeline — exec","text":"","code":"exec(pipeline, on, with = NULL, ...)"},{"path":"https://r-lidar.github.io/lasR/reference/exec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process the pipeline — exec","text":"pipeline pipeline. serie stages called order Can paths files use, path folder files stored, path virtual point cloud file data.frame containing point cloud. supports also LAScatalog LAS objects lidR. supports PCD, LAS, LAZ file formats. list. list options control pipeline executed. includes options control parallel processing, progress bar display, tile buffering . See set_exec_options details available options. ... processing options can explicitly named passed outside argument. See set_exec_options","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/reference/exec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process the pipeline — exec","text":"","code":"if (FALSE) { # \\dontrun{ f <- paste0(system.file(package=\"lasR\"), \"/extdata/bcts/\") f <- list.files(f, pattern = \"(?i)\\\\.la(s|z)$\", full.names = TRUE)  read <- reader_las() tri <- triangulate(15) dtm <- rasterize(5, tri) lmf <- local_maximum(5) met <- rasterize(2, \"imean\") pipeline <- read + tri + dtm + lmf + met ans <- exec(pipeline, on = f, with = list(progress = TRUE)) } # }"},{"path":"https://r-lidar.github.io/lasR/reference/filter_with_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Select highest or lowest points — filter_with_grid","title":"Select highest or lowest points — filter_with_grid","text":"Select retained highest lowest points per grid cell","code":""},{"path":"https://r-lidar.github.io/lasR/reference/filter_with_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select highest or lowest points — filter_with_grid","text":"","code":"filter_with_grid(res, operator = \"min\", filter = \"\")"},{"path":"https://r-lidar.github.io/lasR/reference/filter_with_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select highest or lowest points — filter_with_grid","text":"res numeric. resolution grid operator string. Can min max retain lowest highest points filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/filters.html","id":null,"dir":"Reference","previous_headings":"","what":"Point Filters — filters","title":"Point Filters — filters","text":"Filters strings used filter argument lasR stages process points interest. Filters follow format 'Attribute condition value(s)', e.g.: Z > 2, Intensity < 155, Classification == 2, ReturnNumber == 1.  available conditions include >, <, >=, <=, ==, !=, %%, %%, %%. supported attributes names attributes point cloud X, Y, Z, Intensity, gpstime, UserData, ReturnNumber, ScanAngle, Amplitude . Valid filter strings e.g. Z > 2.5, UserData == 2, Classification %% 1 2 3, Z %1 4. Multiple conditions can combined c(\"Z >= 1\", \"Z <= 4). Note filters never fail. filter references attribute present point cloud (e.g., Intensity < 50 point cloud without intensity data), attribute treated value 0. behavior can impact conditions like Intensity < 50 points pass test. convenience, commonly used filters corresponding helper functions return appropriate filter string. Points satisfy specified condition retained processing, others ignored current stage.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/filters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Point Filters — filters","text":"","code":"keep_class(x)  drop_class(x)  keep_first()  drop_first()  keep_ground()  keep_ground_and_water()  drop_ground()  keep_noise()  drop_noise()  keep_z_above(x)  drop_z_above(x)  keep_z_below(x)  drop_z_below(x)  keep_z_between(x, y)  drop_z_between(x, y)  drop_duplicates()  # S3 method for class 'laslibfilter' print(x, ...)  # S3 method for class 'laslibfilter' e1 + e2"},{"path":"https://r-lidar.github.io/lasR/reference/filters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Point Filters — filters","text":"x, y numeric integer function filter used. ... Unused. e1, e2 lasR objects.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/filters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Point Filters — filters","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") gnd = keep_class(c(2,9)) reader(gnd) #> ----------- #> reader (uid:f2a78234fdc4) #>   filter : [Classification %in% 2 9]  #>   output :   #> ----------- #>  triangulate(filter = keep_ground()) #> ----------- #> triangulate (uid:d14044aa5b78) #>   use_attribute : Z  #>   max_edge : 0.00  #>   filter : [Classification == 2]  #>   output :   #> ----------- #>  rasterize(1, \"max\", filter = \"Z > 5\") #> ----------- #> rasterize (uid:a498ef3763f9) #>   method : [max]  #>   window : 1.00  #>   res : 1.00  #>   filter : [Z > 5]  #>   output : /tmp/Rtmp5kcE0j/file25df64bd1455.tif  #> ----------- #>"},{"path":"https://r-lidar.github.io/lasR/reference/focal.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate focal (","title":"Calculate focal (","text":"Calculate focal (\"moving window\") values cell raster using various functions. NAs always omitted; thus, stage effectively acts NA filler. window always circular. edges handled adjusting window.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/focal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate focal (","text":"","code":"focal(raster, size, fun = \"mean\", ofile = temptif())"},{"path":"https://r-lidar.github.io/lasR/reference/focal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate focal (","text":"raster LASRalgorithm. stage produces raster. size numeric. window size **units point cloud**, pixels. example, 2 means 2 meters 2 feet, 2 pixels. fun string. Function apply. Supported functions 'mean', 'median', 'min', 'max', 'sum'. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/focal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate focal (","text":"stage produces raster. path provided `ofile` expected `.tif` format supported GDAL.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/focal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate focal (","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package = \"lasR\")  chm = rasterize(2, \"zmax\") chm2 = lasR:::focal(chm, 8, fun = \"mean\") chm3 = lasR:::focal(chm, 8, fun = \"max\") pipeline <- reader() + chm + chm2 + chm2 ans = exec(pipeline, on = f) #> Warning: GDAL Error 1: TIFFResetField:/tmp/Rtmp5kcE0j/file25df2a6a566.tif: Can not read TIFF directory entry.  terra::plot(ans[[1]])  terra::plot(ans[[2]])  terra::plot(ans[[3]])"},{"path":"https://r-lidar.github.io/lasR/reference/geometry_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute pointwise geometry features — geometry_features","title":"Compute pointwise geometry features — geometry_features","text":"Compute pointwise geometry features based local neighborhood. feature added new point attribute. names new attributes (recorded) coeff00, coeff01, coeff02 , lambda1, lambda2, lambda3, anisotropy, planarity, sphericity, linearity, omnivariance, curvature, eigensum, angle, normalX, normalY, normalZ (recorded order). total 23 attributes can added. strongly discouraged use . features recorded single precision floating points yet computing triple size point cloud. stage modifies point cloud pipeline produce output. pipeline two stages stage, attribute name overwritten.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/geometry_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute pointwise geometry features — geometry_features","text":"","code":"geometry_features(k, r, features = \"\")"},{"path":"https://r-lidar.github.io/lasR/reference/geometry_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute pointwise geometry features — geometry_features","text":"k, r integer numeric respectively k-nearest neighbours radius neighborhood sphere. k given r missing, computes knn, r given k missing computes sphere neighborhood, k r given computes knn limit search distance. features String. Geometric feature export. feature added new attribute. Use 'C' 9 principal component coefficients, 'E' 3 eigenvalues covariance matrix, '' anisotropy, 'p' planarity, 's' sphericity, 'l' linearity, 'o' omnivariance, 'c' curvature, 'e' sum eigenvalues, '' angle (inclination degrees relative vertical), 'n' 3 components normal vector. Notice uppercase labeled components allow computing lowercase labeled components. Default \"\". case, singular value decomposition computed serves purpose. order flags matter features recorded order mentioned .","code":""},{"path":"https://r-lidar.github.io/lasR/reference/geometry_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute pointwise geometry features — geometry_features","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/geometry_features.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute pointwise geometry features — geometry_features","text":"Hackel, T., Wegner, J. D., & Schindler, K. (2016). Contour detection unstructured 3D point clouds. Proceedings IEEE conference computer vision pattern recognition (pp. 1610-1618).","code":""},{"path":"https://r-lidar.github.io/lasR/reference/geometry_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute pointwise geometry features — geometry_features","text":"","code":"f <- system.file(\"extdata\", \"Example.las\", package = \"lasR\") pipeline <- geometry_features(8, features = \"pi\") + write_las() ans <- exec(pipeline, on = f)"},{"path":"https://r-lidar.github.io/lasR/reference/hag.html","id":null,"dir":"Reference","previous_headings":"","what":"Height Above Ground (HAG) — normalize","title":"Height Above Ground (HAG) — normalize","text":"Normalize point cloud using triangulate transform_with. process involves triangulating ground points using transform_with linearly interpolate elevation point within corresponding triangles. normalize() function modifies Z elevation values, effectively flattening topography normalizing point cloud based Height Ground (HAG). contrast, hag() function records HAG extrabyte attribute named 'HAG', preserving original Z coordinates (Height Sea Level).","code":""},{"path":"https://r-lidar.github.io/lasR/reference/hag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Height Above Ground (HAG) — normalize","text":"","code":"normalize()  hag()"},{"path":[]},{"path":"https://r-lidar.github.io/lasR/reference/hag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Height Above Ground (HAG) — normalize","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pipeline <- reader() + normalize() + write_las() exec(pipeline, on = f) #> [1] \"/tmp/Rtmp5kcE0j/Topography.las\""},{"path":"https://r-lidar.github.io/lasR/reference/hulls.html","id":null,"dir":"Reference","previous_headings":"","what":"Contour of a point cloud — hulls","title":"Contour of a point cloud — hulls","text":"stage uses Delaunay triangulation computes contour. contour strict Delaunay triangulation convex hull, lasR, triangulation max_edge argument. Thus, contour might convex hull holes. Used without triangulation returns bouding box points.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/hulls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Contour of a point cloud — hulls","text":"","code":"hulls(mesh = NULL, ofile = tempgpkg())"},{"path":"https://r-lidar.github.io/lasR/reference/hulls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Contour of a point cloud — hulls","text":"mesh NULL LASRalgorithm. triangulate stage. NULL take bounding box header file. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/hulls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Contour of a point cloud — hulls","text":"stage produces vector. path provided `ofile` expected `.gpkg` format supported GDAL. Vector stages may produce geometries Z coordinates. Thus, discouraged store formats 3D support, shapefiles.","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/reference/hulls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Contour of a point cloud — hulls","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package = \"lasR\") read <- reader() tri <- triangulate(20, filter = keep_ground()) contour <- hulls(tri) pipeline <- read + tri + contour ans <- exec(pipeline, on = f) plot(ans)"},{"path":"https://r-lidar.github.io/lasR/reference/info.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Information about the Point Cloud — info","title":"Print Information about the Point Cloud — info","text":"function prints useful information point cloud files, including file version, size, bounding box, CRS, . called without parameters, returns pipeline stage. convenience, can also called path file immediate execution, likely common use case (see examples).","code":""},{"path":"https://r-lidar.github.io/lasR/reference/info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Information about the Point Cloud — info","text":"","code":"info(f)"},{"path":"https://r-lidar.github.io/lasR/reference/info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Information about the Point Cloud — info","text":"f string (optional) Path LAS/LAZ file.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Information about the Point Cloud — info","text":"nothing. stage used side effect printing","code":""},{"path":"https://r-lidar.github.io/lasR/reference/info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Information about the Point Cloud — info","text":"","code":"f <- system.file(\"extdata\", \"MixedConifer.las\", package = \"lasR\") g <- system.file(\"extdata\", \"Example.pcd\", package = \"lasR\")  # Return a pipeline stage exec(info(), on = f) #> Source       : LASF (v1.2) #> Size         : 1.47 MB #> Extent       : 481260.00 481349.99 3812921.09 3813010.99 (xmin, xmax, ymin, ymax) #> Points       : 37.66 thousands #> Area         : 8090.1 m² #> Density      : 4.7 pts/m² #> Coord. ref.  : NAD83 / UTM zone 12N #> Schema       : #> 18 attributes | 39 bytes per points #>  Name: flags             | uchar  | Desc: Internal 8-bit mask reserved for lasR core engine #>  Name: X                 | int    | Desc: X coordinate #>  Name: Y                 | int    | Desc: Y coordinate #>  Name: Z                 | int    | Desc: Z coordinate #>  Name: Intensity         | ushort | Desc: Pulse return magnitude #>  Name: ReturnNumber      | uchar  | Desc: Pulse return number for a given output pulse #>  Name: NumberOfReturns   | uchar  | Desc: Total number of returns for a given pulse #>  Name: Classification    | uchar  | Desc: The 'class' attributes of a point #>  Name: UserData          | uchar  | Desc: Used at the user’s discretion #>  Name: PointSourceID     | short  | Desc: Source from which this point originated #>  Name: ScanAngle         | char   | Desc: Rounded angle at which the laser point was output #>  Name: gpstime           | double | Desc: Time tag value at which the point was observed #>  Name: treeID            | double | Desc: An ID for each segmented tree #>  Name: EdgeOfFlightline  | bit    | Desc: Set when the point is at the end of a scan #>  Name: ScanDirectionFlag | bit    | Desc: Direction in which the scanner mirror was traveling  #>  Name: Synthetic         | bit    | Desc: Point created by a technique other than direct observation #>  Name: Keypoint          | bit    | Desc: Point is considered to be a model key-point #>  Name: Withheld          | bit    | Desc: Point is supposed to be deleted) #> NULL  # Convenient user-friendly usage info(f) #> Source       : LASF (v1.2) #> Size         : 1.47 MB #> Extent       : 481260.00 481349.99 3812921.09 3813010.99 (xmin, xmax, ymin, ymax) #> Points       : 37.66 thousands #> Area         : 8090.1 m² #> Density      : 4.7 pts/m² #> Coord. ref.  : NAD83 / UTM zone 12N #> Schema       : #> 18 attributes | 39 bytes per points #>  Name: flags             | uchar  | Desc: Internal 8-bit mask reserved for lasR core engine #>  Name: X                 | int    | Desc: X coordinate #>  Name: Y                 | int    | Desc: Y coordinate #>  Name: Z                 | int    | Desc: Z coordinate #>  Name: Intensity         | ushort | Desc: Pulse return magnitude #>  Name: ReturnNumber      | uchar  | Desc: Pulse return number for a given output pulse #>  Name: NumberOfReturns   | uchar  | Desc: Total number of returns for a given pulse #>  Name: Classification    | uchar  | Desc: The 'class' attributes of a point #>  Name: UserData          | uchar  | Desc: Used at the user’s discretion #>  Name: PointSourceID     | short  | Desc: Source from which this point originated #>  Name: ScanAngle         | char   | Desc: Rounded angle at which the laser point was output #>  Name: gpstime           | double | Desc: Time tag value at which the point was observed #>  Name: treeID            | double | Desc: An ID for each segmented tree #>  Name: EdgeOfFlightline  | bit    | Desc: Set when the point is at the end of a scan #>  Name: ScanDirectionFlag | bit    | Desc: Direction in which the scanner mirror was traveling  #>  Name: Synthetic         | bit    | Desc: Point created by a technique other than direct observation #>  Name: Keypoint          | bit    | Desc: Point is considered to be a model key-point #>  Name: Withheld          | bit    | Desc: Point is supposed to be deleted)  info(g) #> Source       : PCDF (v0.7) #> Size         : 3.75 kB #> Extent       : 339002.88 339015.12 5248000.00 5248001.00 (xmin, xmax, ymin, ymax) #> Points       : 30.00  #> Area         : 12.2 m² #> Density      : 2.4 pts/m² #> Coord. ref.  : (null) #> Schema       : #> 18 attributes | 125 bytes per points #>  Name: flags             | char   | Desc: Internal 8-bit mask reserved lasR core engine #>  Name: X                 | float  | Desc:  #>  Name: Y                 | float  | Desc:  #>  Name: Z                 | float  | Desc:  #>  Name: Intensity         | double | Desc:  #>  Name: returnnumber      | double | Desc:  #>  Name: NumberOfReturns   | double | Desc:  #>  Name: ScanDirectionFlag | double | Desc:  #>  Name: EdgeOfFlightline  | double | Desc:  #>  Name: Classification    | double | Desc:  #>  Name: Synthetic         | double | Desc:  #>  Name: Keypoint          | double | Desc:  #>  Name: withheld          | double | Desc:  #>  Name: Overlap           | double | Desc:  #>  Name: ScanAngle         | double | Desc:  #>  Name: UserData          | double | Desc:  #>  Name: PointSourceID     | double | Desc:  #>  Name: gpstime           | double | Desc:"},{"path":"https://r-lidar.github.io/lasR/reference/install_cmd_tools.html","id":null,"dir":"Reference","previous_headings":"","what":"Use some lasR features from a terminal — install_cmd_tools","title":"Use some lasR features from a terminal — install_cmd_tools","text":"Install required files able run simple lasR commands terminal. Working terminal easier simple tasks possible build complex pipelines way. Examples possible commands:","code":"lasr help lasr index -i /path/to/folder lasr vpc -i /path/to/folder lasr info -i /path/to/file.las lasr chm -i /path/to/folder -o /path/to/chm.tif -res 1 -ncores 8 lasr dtm -i /path/to/folder -o /path/to/dtm.tif -res 0.5 -ncores 8"},{"path":"https://r-lidar.github.io/lasR/reference/install_cmd_tools.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use some lasR features from a terminal — install_cmd_tools","text":"","code":"install_cmd_tools()"},{"path":"https://r-lidar.github.io/lasR/reference/lasR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"lasR: airborne LiDAR for forestry applications — lasR-package","title":"lasR: airborne LiDAR for forestry applications — lasR-package","text":"lasR provides set tools process efficiently airborne LiDAR data forestry contexts. package works .las .laz files. toolbox includes algorithms DSM, CHM, DTM, ABA, normalisation, tree detection, tree segmentation, tree delineation, colourization, validation tools, well processing engine process broad LiDAR coverage split many files efficiently.","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/reference/lasR-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"lasR: airborne LiDAR for forestry applications — lasR-package","text":"Maintainer: Jean-Romain Roussel info@r-lidar.com [copyright holder] contributors: Martin Isenburg (author included LASlib LASzip libraries) [copyright holder] Benoît St-Onge (author included 'chm_prep' function) [copyright holder] Niels Lohmann (author included json parser) [copyright holder] Volodymyr Bilonenko (author included delaunator triangulation) [copyright holder] State Key Laboratory Remote Sensing Science, Institute Remote Sensing Science Engineering, Beijing Normal University (copyright holder included CSF) [copyright holder] Authors Eigen (Authorship copyright included Eigen library detailed inst/COPYRIGHTS) [copyright holder] Marius Muja mariusm@cs.ubc.ca (author included nanoflann library) [copyright holder] David G. Lowe lowe@cs.ubc.ca (author included nanoflann library) [copyright holder] Jose L. Blanco joseluisblancoc@gmail.com (author included nanoflann library) [copyright holder]","code":""},{"path":"https://r-lidar.github.io/lasR/reference/load_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a matrix for later use — load_matrix","title":"Load a matrix for later use — load_matrix","text":"Load matrix later use. example, load matrix feed transform_with stage","code":""},{"path":"https://r-lidar.github.io/lasR/reference/load_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a matrix for later use — load_matrix","text":"","code":"load_matrix(matrix, check = TRUE)"},{"path":"https://r-lidar.github.io/lasR/reference/load_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a matrix for later use — load_matrix","text":"matrix 4x4 matrix typically Rotation-Translation Matrix (RTM) check Boolean. Check matrix orthogonality.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/load_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a matrix for later use — load_matrix","text":"","code":"a = 20 * pi / 180 m <- matrix(c(   cos(a), -sin(a), 0, 1000,   sin(a), cos(a), 0, 0,   0, 0, 1, 0,   0, 0, 0, 1), nrow = 4, byrow = TRUE)  mat = load_matrix(m) trans = transform_with(mat) write = write_las(tempfile(fileext = \".las\")) pipeline = mat + trans + write  f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\")  exec(pipeline, on = f) #> $load_matrix #>           [,1]       [,2] [,3] [,4] #> [1,] 0.9396926 -0.3420201    0 1000 #> [2,] 0.3420201  0.9396926    0    0 #> [3,] 0.0000000  0.0000000    1    0 #> [4,] 0.0000000  0.0000000    0    1 #>  #> $write_las #> [1] \"/tmp/Rtmp5kcE0j/file25df188957e2.las\" #>"},{"path":"https://r-lidar.github.io/lasR/reference/load_raster.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a raster for later use — load_raster","title":"Load a raster for later use — load_raster","text":"Load raster disk file later use. example, load DTM feed transform_with stage load CHM feed pit_fill stage. raster never loaded entirely. Internally, chunks corresponding currently processed point cloud loaded. careful: internally, raster read float matter original datatype.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/load_raster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a raster for later use — load_raster","text":"","code":"load_raster(file, band = 1L)"},{"path":"https://r-lidar.github.io/lasR/reference/load_raster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a raster for later use — load_raster","text":"file character. Path raster file. band integer. band load. reads loads single band.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/load_raster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a raster for later use — load_raster","text":"","code":"r <- system.file(\"extdata/bcts\", \"bcts_dsm_5m.tif\", package = \"lasR\") f <- paste0(system.file(package = \"lasR\"), \"/extdata/bcts/\") f <- list.files(f, pattern = \"(?i)\\\\.la(s|z)$\", full.names = TRUE)  # In the following pipeline, neither load_raster nor pit_fill process any points. # The internal engine is capable of knowing that, and the LAS files won't actually be # read. Yet the raster r will be processed by chunk following the LAS file pattern. rr <- load_raster(r) pipeline <- rr + pit_fill(rr) ans <- exec(pipeline, on = f, verbose = FALSE)"},{"path":"https://r-lidar.github.io/lasR/reference/local_maximum.html","id":null,"dir":"Reference","previous_headings":"","what":"Local Maximum — local_maximum","title":"Local Maximum — local_maximum","text":"Local Maximum stage identifies points locally maximum. window size fixed circular. stage modify point cloud. produces derived product vector format. function local_maximum_raster applies raster instead point cloud","code":""},{"path":"https://r-lidar.github.io/lasR/reference/local_maximum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local Maximum — local_maximum","text":"","code":"local_maximum(   ws,   min_height = 2,   filter = \"\",   ofile = tempgpkg(),   use_attribute = \"Z\",   record_attributes = FALSE,   store_in_attribute = \"\" )  local_maximum_raster(   raster,   ws,   min_height = 2,   filter = \"\",   ofile = tempgpkg() )"},{"path":"https://r-lidar.github.io/lasR/reference/local_maximum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local Maximum — local_maximum","text":"ws numeric. Diameter moving window used detect local maxima units input data (usually meters). min_height numeric. Minimum height local maximum. Threshold point local maximum. Default 2. filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage. use_attribute character. Specifies attribute use operation, \"Z\" (coordinate) default. Alternatively, can name attribute, \"Intensity\", \"gpstime\", \"ReturnNumber\", \"HAG\", exists. Note: function fail specified attribute exist point cloud. example, \"Intensity\" requested present, \"HAG\" specified unavailable, internal engine return 0 missing attribute. record_attributes coordinates XYZ points corresponding local maxima recorded. also possible record attributes theses points intensity, return number, scan angle . store_in_attribute addition producing geospatial file local maxima, points can also flagged: 0 point local maximum, 1 point local maximum. attribute exist, must first created add_extrabytes (see examples). raster LASRalgorithm. stage produces raster.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/local_maximum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local Maximum — local_maximum","text":"stage produces vector. path provided `ofile` expected `.gpkg` format supported GDAL. Vector stages may produce geometries Z coordinates. Thus, discouraged store formats 3D support, shapefiles.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/local_maximum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local Maximum — local_maximum","text":"","code":"f <- system.file(\"extdata\", \"MixedConifer.las\", package = \"lasR\") read <- reader() lmf <- local_maximum(5) ans <- exec(read + lmf, on = f) ans #> Simple feature collection with 177 features and 0 fields #> Geometry type: POINT #> Dimension:     XYZ #> Bounding box:  xmin: 481260 ymin: 3812921 xmax: 481349.8 ymax: 3813011 #> z_range:       zmin: 2.42 zmax: 32.07 #> Projected CRS: NAD83 / UTM zone 12N #> First 10 features: #>                              geom #> 1  POINT Z (481309.9 3812944 2... #> 2   POINT Z (481294.7 3813011 16) #> 3  POINT Z (481281.9 3813003 2... #> 4  POINT Z (481278.4 3813002 2... #> 5  POINT Z (481307.2 3813000 2... #> 6  POINT Z (481265.3 3812996 1... #> 7  POINT Z (481261.8 3812999 1... #> 8  POINT Z (481302.9 3812929 2... #> 9  POINT Z (481260.7 3812939 2... #> 10 POINT Z (481262.9 3812935 1...  chm <- rasterize(1, \"max\") lmf <- local_maximum_raster(chm, 5) ans <- exec(read + chm + lmf, on = f) # terra::plot(ans$rasterize) # plot(ans$local_maximum, add = T, pch = 19)  # Storing LM in UserData. lmf <- local_maximum(5, store_in_attribute = \"UserData\") ans <- exec(read + lmf + write_las(), on = f) ans #> $local_maximum #> Simple feature collection with 177 features and 0 fields #> Geometry type: POINT #> Dimension:     XYZ #> Bounding box:  xmin: 481260 ymin: 3812921 xmax: 481349.8 ymax: 3813011 #> z_range:       zmin: 2.42 zmax: 32.07 #> Projected CRS: NAD83 / UTM zone 12N #> First 10 features: #>                              geom #> 1  POINT Z (481309.9 3812944 2... #> 2   POINT Z (481294.7 3813011 16) #> 3  POINT Z (481281.9 3813003 2... #> 4  POINT Z (481278.4 3813002 2... #> 5  POINT Z (481307.2 3813000 2... #> 6  POINT Z (481265.3 3812996 1... #> 7  POINT Z (481302.9 3812929 2... #> 8  POINT Z (481261.8 3812999 1... #> 9  POINT Z (481260.7 3812939 2... #> 10 POINT Z (481302.9 3812969 2... #>  #> $write_las #> [1] \"/tmp/Rtmp5kcE0j/MixedConifer.las\" #>   # Storing in an new attribute without geospatial output attr <- add_extrabytes(\"uchar\", \"lm\", \"local maximum flag\") lmf <- local_maximum(5, ofile = \"\", store_in_attribute = \"lm\") ans <- exec(attr + lmf + write_las(), on = f) ans #> [1] \"/tmp/Rtmp5kcE0j/MixedConifer.las\""},{"path":"https://r-lidar.github.io/lasR/reference/metric_engine.html","id":null,"dir":"Reference","previous_headings":"","what":"Metric engine — metric_engine","title":"Metric engine — metric_engine","text":"metric engine internal tool allow derive metric set points parsing string. used rasterize, summarise well functions. string composed two parts separated underscore. first part attribute metric must computed (e.g., z, intensity, classification). second part name metric (e.g., mean, sd, cv). string thus typically looks like \"z_max\", \"intensity_min\", \"z_mean\", \"classification_mode\". details see sections 'Attribute' 'Metrics' respectively.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/metric_engine.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Metric engine — metric_engine","text":"careful: engine supports combination attribute_metric strings. computable, meaningful. example, c_mode makes sense z_mode. Also, metrics computed 32-bit floating point accuracy, x_mean y_sum might slightly inaccurate, anyway, metrics supposed useful.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/metric_engine.html","id":"attribute","dir":"Reference","previous_headings":"","what":"Attribute","title":"Metric engine — metric_engine","text":"available attributes accessible via name. standard attribute shortcut using single letter: t - gpstime, - angle, - intensity, n - numberofreturns, r - returnnumber, c - classification, u - userdata, p - pointsourceid, e - edgeofflightline, d - scandirectionflag, R - red, G - green, B - blue, N - nir.careful typos: attributes non failing features. attribute exist NaN returned. Thus intesity_mean return NaN rather failing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/metric_engine.html","id":"metrics","dir":"Reference","previous_headings":"","what":"Metrics","title":"Metric engine — metric_engine","text":"available metric names : count, max, min, mean, median, sum, sd, cv, pX (percentile), aboveX, mode, kurt (kurtosis), skew (skewness). metrics attribute + name + parameter X, pX X can substituted number. , z_pX represents Xth percentile; instance, z_p95 signifies 95th percentile z. z_aboveX corresponds percentage points X (sometimes called canopy cover). possible call metric without name attribute. case, z default. e.g. mean equals z_mean","code":""},{"path":"https://r-lidar.github.io/lasR/reference/metric_engine.html","id":"extra-attribute","dir":"Reference","previous_headings":"","what":"Extra attribute","title":"Metric engine — metric_engine","text":"core attributes natively supported x, y, z, classification, intensity, . point clouds may attributes. case, metrics can derived way using names attributes. careful typos. attributes existance checked internally . example, user requests: ntensity_mean, typo name extra attribute. extra attribute never failing, ntensity_mean return NaN rather error.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/metric_engine.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Metric engine — metric_engine","text":"","code":"metrics = c(\"z_max\", \"i_min\", \"r_mean\", \"n_median\", \"z_sd\", \"c_sd\", \"t_cv\", \"u_sum\", \"z_p95\") f <- system.file(\"extdata\", \"Example.las\", package=\"lasR\") p <- summarise(metrics = metrics) r <- rasterize(5, operators = metrics) ans <- exec(p+r, on = f) ans$summary$metrics #>        c_sd i_min n_median   r_mean         t_cv u_sum   z_max    z_p95 #> 1 0.3051286    27        1 1.133333 4.466148e-07   960 978.345 978.2653 #>       z_sd #> 1 1.459199 ans$rasterize #> class       : SpatRaster  #> size        : 1, 4, 9  (nrow, ncol, nlyr) #> resolution  : 5, 5  (x, y) #> extent      : 339000, 339020, 5248000, 5248005  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83 / UTM zone 17N (EPSG:26917)  #> source      : file25df568eb33d.tif  #> names       : z_max, i_min, r_mean, n_median, z_sd, c_sd, ..."},{"path":"https://r-lidar.github.io/lasR/reference/multithreading.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel processing tools — multithreading","title":"Parallel processing tools — multithreading","text":"lasR uses OpenMP paralellize internal C++ code. set_parallel_strategy() globally changes strategy used process point clouds. sequential(), concurrent_files(), concurrent_points(), nested() functions assign parallelization strategy (see Details). has_omp_support() tells lasR package compiled support OpenMP unlikely case MacOS.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/multithreading.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel processing tools — multithreading","text":"","code":"set_parallel_strategy(strategy)  unset_parallel_strategy()  get_parallel_strategy()  ncores()  half_cores()  sequential()  concurrent_files(ncores = half_cores())  concurrent_points(ncores = half_cores())  nested(ncores = ncores()/4L, ncores2 = 2L)  has_omp_support()"},{"path":"https://r-lidar.github.io/lasR/reference/multithreading.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel processing tools — multithreading","text":"strategy object returned one sequential(), concurrent_points(), concurrent_files() nested(). ncores integer. Number cores. ncores2 integer.  Number cores. nested strategy ncores number concurrent files ncores2 number concurrent points.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/multithreading.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parallel processing tools — multithreading","text":"4 strategies parallel processing: sequential parallelization : sequential() concurrent-points Point cloud files processed sequentially one one. Inside pipeline, stages parallelized able process multiple points simultaneously. stages natively parallelized. E.g. concurrent_points(4) concurrent-files Files processed parallel. Several files loaded memory processed simultaneously. entire pipeline parallelized, inside stage, points processed sequentially. E.g. concurrent_files(4) nested Files processed parallel. Several files loaded memory processed simultaneously, inside stages, points processed parallel. E.g. nested(4,2) concurrent-files likely desirable fastest option. However, uses memory loads multiple files. default concurrent_points(half_cores()) can changed globally using e.g. set_parallel_strategy(concurrent_files(4))","code":""},{"path":"https://r-lidar.github.io/lasR/reference/multithreading.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel processing tools — multithreading","text":"","code":"if (FALSE) { # \\dontrun{ f <- paste0(system.file(package=\"lasR\"), \"/extdata/bcts/\") f <- list.files(f, pattern = \"(?i)\\\\.la(s|z)$\", full.names = TRUE)  pipeline <- reader_las() + rasterize(2, \"imean\")  ans <- exec(pipeline, on = f, progress = TRUE, ncores = concurrent_files(4))  set_parallel_strategy(concurrent_files(4)) ans <- exec(pipeline, on = f, progress = TRUE) } # }"},{"path":"https://r-lidar.github.io/lasR/reference/pit_fill.html","id":null,"dir":"Reference","previous_headings":"","what":"Pits and spikes filling — pit_fill","title":"Pits and spikes filling — pit_fill","text":"Pits spikes filling raster. Typically used post-processing CHM. algorithm St-Onge 2008 (see reference).","code":""},{"path":"https://r-lidar.github.io/lasR/reference/pit_fill.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pits and spikes filling — pit_fill","text":"","code":"pit_fill(   raster,   lap_size = 3L,   thr_lap = 0.1,   thr_spk = -0.1,   med_size = 3L,   dil_radius = 0L,   ofile = temptif() )"},{"path":"https://r-lidar.github.io/lasR/reference/pit_fill.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pits and spikes filling — pit_fill","text":"raster LASRalgorithm. stage produces raster. lap_size integer. Size Laplacian filter kernel (integer value, pixels). thr_lap numeric. Threshold Laplacian value detecting cavity (values value considered cavity). positive value. thr_spk numeric. Threshold Laplacian value detecting spike (values value considered spike). negative value. med_size integer. Size median filter kernel (integer value, pixels). dil_radius integer. Dilation radius (integer value, pixels). ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/pit_fill.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pits and spikes filling — pit_fill","text":"stage produces raster. path provided `ofile` expected `.tif` format supported GDAL.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/pit_fill.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pits and spikes filling — pit_fill","text":"St-Onge, B., 2008. Methods improving quality true orthomosaic Vexcel UltraCam images created using alidar digital surface model, Proceedings Silvilaser 2008, Edinburgh, 555-562. https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=81365288221f3ac34b51a82e2cfed8d58defb10e","code":""},{"path":"https://r-lidar.github.io/lasR/reference/pit_fill.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pits and spikes filling — pit_fill","text":"","code":"f <- system.file(\"extdata\", \"MixedConifer.las\", package=\"lasR\")  reader <- reader(filter = keep_first()) tri <- triangulate() chm <- rasterize(0.25, tri) pit <- pit_fill(chm) u <- exec(reader + tri + chm + pit, on = f)  chm <- u[[1]] sto <- u[[2]]  #terra::plot(c(chm, sto), col = lidR::height.colors(25))"},{"path":"https://r-lidar.github.io/lasR/reference/print.lasrcloud.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for 'lasrcloud' Objects — print.lasrcloud","title":"Print Method for 'lasrcloud' Objects — print.lasrcloud","text":"function defines custom print method objects class 'lasrcloud'.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/print.lasrcloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for 'lasrcloud' Objects — print.lasrcloud","text":"","code":"# S3 method for class 'lasrcloud' print(x, ...)"},{"path":"https://r-lidar.github.io/lasR/reference/print.lasrcloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for 'lasrcloud' Objects — print.lasrcloud","text":"x object class 'lasrcloud'. ... Additional arguments (used).","code":""},{"path":"https://r-lidar.github.io/lasR/reference/rasterize.html","id":null,"dir":"Reference","previous_headings":"","what":"Rasterize a point cloud — rasterize","title":"Rasterize a point cloud — rasterize","text":"Rasterize point cloud using different approaches. stage modify point cloud. produces derived product raster format.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/rasterize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rasterize a point cloud — rasterize","text":"","code":"rasterize(res, operators = \"max\", filter = \"\", ofile = temptif(), ...)"},{"path":"https://r-lidar.github.io/lasR/reference/rasterize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rasterize a point cloud — rasterize","text":"res numeric. resolution raster. Can vector two resolutions. case correspond x y resolution buffered rasterization. (see section 'Buffered' examples) operators Can character vector. \"min\", \"max\" \"count\" accepted well many others (see section 'Operators'). Can also rasterize triangulation input LASRalgorithm triangulation (see examples). Can also user-defined expression (see example section 'Operators'). filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage. ... default_value numeric. rasterizing operator filter (e.g. -keep_z_above 2) pixels covered points may longer contain point pass filter criteria assigned NA. differentiate NAs non covered pixels NAs covered pixels without point pass filter, later case can assigned another value 0.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/rasterize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rasterize a point cloud — rasterize","text":"stage produces raster. path provided `ofile` expected `.tif` format supported GDAL.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/rasterize.html","id":"operators","dir":"Reference","previous_headings":"","what":"Operators","title":"Rasterize a point cloud — rasterize","text":"operators string vector strings: read metric_engine see possible strings examples valid calls:   operators R user-defined expression, function return either vector numbers list containing atomic numbers. assign band name raster, vector list must named accordingly. following valid operators:","code":"rasterize(10, c(\"max\", \"count\", \"i_mean\", \"z_p95\")) rasterize(10, c(\"z_max\", \"c_count\", \"intensity_mean\", \"p95\")) f = function(x) { return(mean(x)) } g = function(x,y) { return(c(avg = mean(x), med = median(y))) } h = function(x) { return(list(a = mean(x), b = median(x))) } rasterize(10, f(Intensity)) rasterize(10, g(Z, Intensity)) rasterize(10, h(Z))"},{"path":"https://r-lidar.github.io/lasR/reference/rasterize.html","id":"buffered","dir":"Reference","previous_headings":"","what":"Buffered","title":"Rasterize a point cloud — rasterize","text":"argument res vector two numbers, first number represents resolution output raster, second number represents size windows used compute metrics. approach called Buffered Area Based Approach (BABA). classical rasterization, metrics computed independently pixel. example, predicting resource typically involves computing metrics 400 square meter pixel, resulting raster resolution 20 meters. possible achieve finer granularity method. However, buffered rasterization, possible compute raster resolution 10 meters (.e., computing metrics every 10 meters) using 20 x 20 windows metric computation. case, windows overlap, essentially creating moving window effect. option apply rasterizing triangulation, second value considered case.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/rasterize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rasterize a point cloud — rasterize","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader() tri  <- triangulate(filter = keep_ground()) dtm  <- rasterize(1, tri) # input is a triangulation stage avgi <- rasterize(10, mean(Intensity)) # input is a user expression chm  <- rasterize(2, \"max\") # input is a character vector pipeline <- read + tri + dtm + avgi + chm ans <- exec(pipeline, on = f) ans[[1]] #> class       : SpatRaster  #> size        : 286, 286, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 273357, 273643, 5274357, 5274643  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file25df1bc32bae.tif  #> name        : file25df1bc32bae  ans[[2]] #> class       : SpatRaster  #> size        : 30, 30, 1  (nrow, ncol, nlyr) #> resolution  : 10, 10  (x, y) #> extent      : 273350, 273650, 5274350, 5274650  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file25df23c0ff9.tif  #> name        : file25df23c0ff9  ans[[3]] #> class       : SpatRaster  #> size        : 144, 144, 1  (nrow, ncol, nlyr) #> resolution  : 2, 2  (x, y) #> extent      : 273356, 273644, 5274356, 5274644  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83(CSRS) / MTM zone 7 (EPSG:2949)  #> source      : file25df3628f2c7.tif  #> name        : max   # Demonstration of buffered rasterization  # A good resolution for computing point density is 5 meters. c0 <- rasterize(5, \"count\")  # Computing point density at too fine a resolution doesn't make sense since there is # either zero or one point per pixel. Therefore, producing a point density raster with # a 2 m resolution is not feasible with classical rasterization. c1 <- rasterize(2, \"count\")  # Using a buffered approach, we can produce a raster with a 2-meter resolution where # the metrics for each pixel are computed using a 5-meter window. c2  <- rasterize(c(2,5), \"count\")  pipeline = read + c0 + c1 + c2 res <- exec(pipeline, on = f) terra::plot(res[[1]]/25)  # divide by 25 to get the density  terra::plot(res[[2]]/4)   # divide by 4 to get the density  terra::plot(res[[3]]/25)  # divide by 25 to get the density"},{"path":"https://r-lidar.github.io/lasR/reference/read_cloud.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a point cloud in memory — read_cloud","title":"Read a point cloud in memory — read_cloud","text":"Read point cloud memory. point cloud stored C++ data structure exposed users","code":""},{"path":"https://r-lidar.github.io/lasR/reference/read_cloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a point cloud in memory — read_cloud","text":"","code":"read_cloud(file, progress = TRUE)"},{"path":"https://r-lidar.github.io/lasR/reference/read_cloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a point cloud in memory — read_cloud","text":"file file containing point cloud. Currently LAS LAZ files supported progress boolean progress bar","code":""},{"path":"https://r-lidar.github.io/lasR/reference/read_cloud.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a point cloud in memory — read_cloud","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") las <- read_cloud(f) #> Read files headers: [==========] 100% (1 threads)                     Overall: [          ] 0% (1 threads) | : no progress                      Overall: [          ] 0% (1 threads) | read_las: [          ] 0% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 1% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 2% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 3% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 4% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 5% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 6% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 7% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 8% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [          ] 9% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 10% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 11% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 12% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 13% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 14% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 15% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 16% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 17% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 18% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=         ] 19% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 20% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 21% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 22% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 23% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 24% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 25% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 26% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 27% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 28% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==        ] 29% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 30% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 31% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 32% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 33% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 34% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 35% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 36% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 37% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 38% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [===       ] 39% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 40% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 41% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 42% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 43% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 44% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 45% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 46% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 47% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 48% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [====      ] 49% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 50% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 51% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 52% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 53% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 54% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 55% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 56% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 57% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 58% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=====     ] 59% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 60% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 61% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 62% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 63% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 64% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 65% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 66% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 67% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 68% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [======    ] 69% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 70% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 71% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 72% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 73% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 74% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 75% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 76% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 77% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 78% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [=======   ] 79% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 80% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 81% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 82% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 83% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 84% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 85% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 86% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 87% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 88% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========  ] 89% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 90% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 91% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 92% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 93% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 94% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 95% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 96% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 97% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 98% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [========= ] 99% (1 threads)                     Overall: [          ] 0% (1 threads) | read_las: [==========] 100% (1 threads)                     Overall: [==========] 100% (1 threads) |                      Overall: [==========] 100% (1 threads)                     las #> Source       : LASF (v1.2) #> Size         : 2.28 MB #> Extent       : 273357.14 273642.86 5274357.14 5274642.85 (xmin, xmax, ymin, ymax) #> Points       : 73.40 thousands #> Area         : 81629.0 m² #> Density      : 0.9 pts/m² #> Coord. ref.  : (null) #> Schema       : #> 17 attributes | 31 bytes per points #>  Name: flags             | uchar  | Desc: Internal 8-bit mask reserved for lasR core engine #>  Name: X                 | int    | Desc: X coordinate #>  Name: Y                 | int    | Desc: Y coordinate #>  Name: Z                 | int    | Desc: Z coordinate #>  Name: Intensity         | ushort | Desc: Pulse return magnitude #>  Name: ReturnNumber      | uchar  | Desc: Pulse return number for a given output pulse #>  Name: NumberOfReturns   | uchar  | Desc: Total number of returns for a given pulse #>  Name: Classification    | uchar  | Desc: The 'class' attributes of a point #>  Name: UserData          | uchar  | Desc: Used at the user’s discretion #>  Name: PointSourceID     | short  | Desc: Source from which this point originated #>  Name: ScanAngle         | char   | Desc: Rounded angle at which the laser point was output #>  Name: gpstime           | double | Desc: Time tag value at which the point was observed #>  Name: EdgeOfFlightline  | bit    | Desc: Set when the point is at the end of a scan #>  Name: ScanDirectionFlag | bit    | Desc: Direction in which the scanner mirror was traveling  #>  Name: Synthetic         | bit    | Desc: Point created by a technique other than direct observation #>  Name: Keypoint          | bit    | Desc: Point is considered to be a model key-point #>  Name: Withheld          | bit    | Desc: Point is supposed to be deleted) u = exec(chm(5), on = las) u #> class       : SpatRaster  #> size        : 58, 58, 1  (nrow, ncol, nlyr) #> resolution  : 5, 5  (x, y) #> extent      : 273355, 273645, 5274355, 5274645  (xmin, xmax, ymin, ymax) #> coord. ref. :   #> source      : file25df2af9ede1.tif  #> name        : max"},{"path":"https://r-lidar.github.io/lasR/reference/reader.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the pipeline — reader","title":"Initialize the pipeline — reader","text":"first stage must called pipeline. stage nothing returns nothing associated another processing stage. initializes pipeline. reader() main function dispatches functions. reader_coverage() processes entire point cloud. reader_circles() reader_rectangles() read process selected regions interest. chosen reader options .e. using reader() can omitted.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/reader.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the pipeline — reader","text":"","code":"reader(filter = \"\", select = \"*\", copc_depth = NULL, ...)  reader_coverage(filter = \"\", select = \"*\", copc_depth = NULL, ...)  reader_circles(xc, yc, r, filter = \"\", select = \"*\", copc_depth = NULL, ...)  reader_rectangles(   xmin,   ymin,   xmax,   ymax,   filter = \"\",   select = \"*\",   copc_depth = NULL,   ... )"},{"path":"https://r-lidar.github.io/lasR/reference/reader.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the pipeline — reader","text":"filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters. select character. Unused. Reserved future versions. copc_depth integer. files COPC file possible read point hierarchy given level. COPC hierarchy 0-index. first level 0 1. ... passed readers xc, yc, r numeric. Circle centres radius radii. xmin, ymin, xmax, ymax numeric. Coordinates rectangles","code":""},{"path":"https://r-lidar.github.io/lasR/reference/reader.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize the pipeline — reader","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package = \"lasR\")  pipeline <- reader() + rasterize(10, \"zmax\") ans <- exec(pipeline, on = f) # terra::plot(ans)  pipeline <- reader(filter = keep_z_above(1.3)) + rasterize(10, \"zmean\") ans <- exec(pipeline, on = f) # terra::plot(ans)  # read_las() with no option can be omitted ans <- exec(rasterize(10, \"zmax\"), on = f) # terra::plot(ans)  # Perform a query and apply the pipeline on a subset pipeline = reader_circles(273500, 5274500, 20) + rasterize(2, \"zmax\") ans <- exec(pipeline, on = f) # terra::plot(ans)  # Perform a query and apply the pipeline on a subset with 1 output files per query ofile = paste0(tempdir(), \"/*_chm.tif\") pipeline = reader_circles(273500, 5274500, 20) + rasterize(2, \"zmax\", ofile = ofile) ans <- exec(pipeline, on = f) # terra::plot(ans)"},{"path":"https://r-lidar.github.io/lasR/reference/region_growing.html","id":null,"dir":"Reference","previous_headings":"","what":"Region growing — region_growing","title":"Region growing — region_growing","text":"Region growing individual tree segmentation based Dalponte Coomes (2016) algorithm (see reference). Note stage strictly performs segmentation, original method described manuscript also performs pre- post-processing tasks. , tasks expected done user separate functions.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/region_growing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Region growing — region_growing","text":"","code":"region_growing(   raster,   seeds,   th_tree = 2,   th_seed = 0.45,   th_cr = 0.55,   max_cr = 20,   ofile = temptif() )"},{"path":"https://r-lidar.github.io/lasR/reference/region_growing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Region growing — region_growing","text":"raster LASRalgoritm. stage producing raster. seeds LASRalgoritm. stage producing points used seeds. th_tree numeric. Threshold pixel tree. Default 2. th_seed numeric. Growing threshold 1. See reference Dalponte et al. 2016. pixel added region height greater tree height multiplied value. 0 1. Default 0.45. th_cr numeric. Growing threshold 2. See reference Dalponte et al. 2016. pixel added region height greater current mean height region multiplied value. 0 1. Default 0.55. max_cr numeric. Maximum value crown diameter detected tree (data units). Default 20. CAREFUL algorithm exists lidR package parameter pixels lidR. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/region_growing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Region growing — region_growing","text":"stage produces raster. path provided `ofile` expected `.tif` format supported GDAL.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/region_growing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Region growing — region_growing","text":"Dalponte, M. Coomes, D. . (2016), Tree-centric mapping forest carbon density airborne laser scanning hyperspectral data. Methods Ecol Evol, 7: 1236–1245. doi:10.1111/2041-210X.12575.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/region_growing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Region growing — region_growing","text":"","code":"f <- system.file(\"extdata\", \"MixedConifer.las\", package=\"lasR\")  reader <- reader(filter = keep_first()) chm <- rasterize(1, \"max\") lmx <- local_maximum_raster(chm, 5) tree <- region_growing(chm, lmx, max_cr = 10) u <- exec(reader + chm + lmx + tree, on = f)  # terra::plot(u$rasterize) # plot(u$local_maximum, add = T, pch = 19, cex = 0.5) # terra::plot(u$region_growing, col = rainbow(150)) # plot(u$local_maximum, add = T, pch = 19, cex = 0.5)"},{"path":"https://r-lidar.github.io/lasR/reference/sampling.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the point cloud — sampling_voxel","title":"Sample the point cloud — sampling_voxel","text":"Sample point cloud, keeping one random point per pixel per voxel perform poisson sampling. stages modify point cloud pipeline produce output. used 'filter' argument, points match criteria subsampled. point kept point cloud.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/sampling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the point cloud — sampling_voxel","text":"","code":"sampling_voxel(res = 2, filter = \"\", ...)  sampling_pixel(   res = 2,   filter = \"\",   method = \"random\",   use_attribute = \"Z\",   ... )  sampling_poisson(distance = 2, filter = \"\", ...)"},{"path":"https://r-lidar.github.io/lasR/reference/sampling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the point cloud — sampling_voxel","text":"res numeric. pixel/voxel resolution filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters. ... unused method string can \"random\" retain one random point \"min\" \"max\" retain highest lowest points respectively. min max users can use argument `use_attribute` select highest intensity highest Z, highest gpstime attributes. use_attribute character. Specifies attribute use operation, \"Z\" (coordinate) default. Alternatively, can name attribute, \"Intensity\", \"gpstime\", \"ReturnNumber\", \"HAG\", exists. Note: function fail specified attribute exist point cloud. example, \"Intensity\" requested present, \"HAG\" specified unavailable, internal engine return 0 missing attribute. distance numeric. Minimum distance points poisson sampling.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/sampling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the point cloud — sampling_voxel","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/sampling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the point cloud — sampling_voxel","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\")  read <- reader() vox <- sampling_voxel(5) # sample 1 random points per voxel write <- write_las() pipeline <- read + vox + write ans = exec(pipeline, on = f)  # Only ground points are poisson sampled. Other point are kept vox <- sampling_poisson(10, filter = \"Classification == 2\") write <- write_las() pipeline <- read + vox + write ans = exec(pipeline, on = f)"},{"path":"https://r-lidar.github.io/lasR/reference/set_crs.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the CRS of the pipeline — set_crs","title":"Set the CRS of the pipeline — set_crs","text":"Assign CRS pipeline. stage reproject data. assigns CRS. stage affects subsequent stages pipeline thus appear close reader assign correct CRS stages.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/set_crs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the CRS of the pipeline — set_crs","text":"","code":"set_crs(x)"},{"path":"https://r-lidar.github.io/lasR/reference/set_crs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the CRS of the pipeline — set_crs","text":"x integer string. EPSG code WKT string understood GDAL","code":""},{"path":"https://r-lidar.github.io/lasR/reference/set_crs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set the CRS of the pipeline — set_crs","text":"","code":"# expected usage hmax = rasterize(10, \"max\") pipeline = reader() + set_crs(2949) + hmax  # fancy usages are working as expected. The .tif file is written with a CRS, the .gpkg file with # another CRS and the .las file with yet another CRS. pipeline = set_crs(2044) + hmax + set_crs(2004) + local_maximum(5) + set_crs(2949) + write_las()"},{"path":"https://r-lidar.github.io/lasR/reference/set_exec_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set global processing options — set_exec_options","title":"Set global processing options — set_exec_options","text":"Set global processing options exec function. default, pipelines executed without progress bar, processing one file time sequentially. following options can passed exec() function four ways. See details.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/set_exec_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set global processing options — set_exec_options","text":"","code":"set_exec_options(   ncores = NULL,   progress = NULL,   buffer = NULL,   chunk = NULL,   ... )  unset_exec_option()"},{"path":"https://r-lidar.github.io/lasR/reference/set_exec_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set global processing options — set_exec_options","text":"ncores object returned one sequential(), concurrent_points(), concurrent_files(), nested(). See multithreading. NULL default concurrent_points(half_cores()). simple integer provided corresponds concurrent_files(ncores). progress boolean. Displays progress bar. buffer numeric. file read buffer. default NULL, mean file buffered. means internal routine knows buffer needed pick greatest value internal suggestion value. chunk numeric. default, collection files processed file (chunk = NULL chunk = 0). possible process arbitrary-sized chunks. useful e.g., processing collections large files processing massive copc file. ... internal options exposed users.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/set_exec_options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set global processing options — set_exec_options","text":"4 ways pass processing options, important understand precedence rules: first option explicitly naming option. option deprecated used convenience backward compatibility. second option passing list argument. option explicit preferred. argument takes precedence explicit arguments. third option using LAScatalog lidR package. LAScatalog already carries processing options respected lasR package. options LAScatalog take precedence. last option setting global processing options. global precedence mainly intended provide way users override options access exec() function. may happen developer creates function executes pipeline internally, users provide options.","code":"exec(pipeline, on = f, progress = TRUE, ncores = 8) exec(pipeline, on = f, with = list(progress = TRUE, chunk = 500)) exec(pipeline, on = ctg, ncores = 4) set_exec_options(progress = TRUE, ncores = concurrent_files(2)) exec(pipeline, on = f)"},{"path":[]},{"path":"https://r-lidar.github.io/lasR/reference/sort_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort points in the point cloud — sort_points","title":"Sort points in the point cloud — sort_points","text":"stage sorts points spatially. grid 50 meters applied, points sorted within cell grid. increases data locality, speeds spatial queries, may slightly increases final size files compressed LAZ format compared optimal compression.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/sort_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort points in the point cloud — sort_points","text":"","code":"sort_points()"},{"path":"https://r-lidar.github.io/lasR/reference/sort_points.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort points in the point cloud — sort_points","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/sort_points.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sort points in the point cloud — sort_points","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") exec(sort_points(), on = f) #> NULL"},{"path":"https://r-lidar.github.io/lasR/reference/stop_if_outside.html","id":null,"dir":"Reference","previous_headings":"","what":"Stop the pipeline conditionally — stop_if_outside","title":"Stop the pipeline conditionally — stop_if_outside","text":"Stop pipeline conditionally. stages `stop_if` stage skipped condition met. allows process subset dataset skip stages conditionally. stop computation. breaks pipeline current file/chunk currently processed. (see exemple)","code":""},{"path":"https://r-lidar.github.io/lasR/reference/stop_if_outside.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stop the pipeline conditionally — stop_if_outside","text":"","code":"stop_if_outside(xmin, ymin, xmax, ymax)"},{"path":"https://r-lidar.github.io/lasR/reference/stop_if_outside.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stop the pipeline conditionally — stop_if_outside","text":"xmin, ymin, xmax, ymax numeric. bounding box","code":""},{"path":"https://r-lidar.github.io/lasR/reference/stop_if_outside.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stop the pipeline conditionally — stop_if_outside","text":"","code":"# Collection of 4 files f <- system.file(\"extdata\", \"bcts/\", package=\"lasR\")  # This bounding box encompasses only one of the four files stopif = stop_if_outside(884800, 620000, 885400, 629200)  read = reader() hll = hulls() tri = triangulate(filter = keep_ground()) dtm = rasterize(1, tri)  # reads the 4 files but 'tri' and 'dtm' are computed only for one file because stopif # allows to escape the pipeline outside the bounding box pipeline = read + hll + stopif + tri + dtm ans1 <- exec(pipeline, on = f) plot(ans1$hulls$geom, axes = TRUE) terra::plot(ans1$rasterize, add = TRUE)   # stopif can be applied before read. Only one file will actually be read and processed pipeline = stopif + read + hll + tri + dtm ans2 <- exec(pipeline, on = f) plot(ans2$hulls$geom, axes = TRUE) terra::plot(ans1$rasterize, add = TRUE, legend = FALSE)"},{"path":"https://r-lidar.github.io/lasR/reference/summarise.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary — summarise","title":"Summary — summarise","text":"Summarize dataset counting number points, first returns metrics entire point cloud. also produces histogram Z Intensity attributes entiere point cloud. can also compute metrics file chunk metric engine rasterize. stage modify point cloud. produces summary list.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/summarise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary — summarise","text":"","code":"summarise(zwbin = 2, iwbin = 50, metrics = NULL, filter = \"\")"},{"path":"https://r-lidar.github.io/lasR/reference/summarise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary — summarise","text":"zwbin, iwbin numeric. Width bins histograms Z Intensity. metrics Character vector. \"min\", \"max\" \"count\" accepted well many others (see metric_engine). NULL nothing computed. something provided metrics computed chunk loaded. chunk might file may also plot (see examples). filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/summarise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary — summarise","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader() pipeline <- read + summarise() ans <- exec(pipeline, on = f) ans #> $npoints #> [1] 73403 #>  #> $nsingle #> [1] 31294 #>  #> $nwithheld #> [1] 0 #>  #> $nsynthetic #> [1] 0 #>  #> $npoints_per_return #>     1     2     3     4     5     6  #> 53538 15828  3569   451    16     1  #>  #> $npoints_per_class #>     1     2     9  #> 61347  8159  3897  #>  #> $z_histogram #>   788   790   792   794   796   798   800   802   804   806   808   810   812  #>     1   163   265   470   596   694  1610  4955  5510 13833  9974  9865  8076  #>   814   816   818   820   822   824   826   828   830  #>  6643  4682  2958  1715   830   390   146    26     1  #>  #> $i_histogram #>   50  100  150  200  250  300  350  400  450  500  550  600  650  700  750  800  #>   25  397 1041 1576 2842 2585 2249 2051 2341 2575 2301 2529 2483 2623 2505 2697  #>  850  900  950 1000 1050 1100 1150 1200 1250 1300 1350 1400 1450 1500 1550 1600  #> 2759 2865 2865 3242 3272 3556 3464 3231 2589 2472 3478 3747 1969  532  183  104  #> 1650 1700 1750 1800 1850 1900 1950 2000 2050 2100 2150 2200 2250 2300 2350 2400  #>   97   65   35   18    9   13    7    6    0    1    0    2    1    0    0    0  #> 2450  #>    1  #>  #> $crs #> [1] \"PROJCRS[\\\"NAD83(CSRS) / MTM zone 7\\\",BASEGEOGCRS[\\\"NAD83(CSRS)\\\",DATUM[\\\"NAD83 Canadian Spatial Reference System\\\",ELLIPSOID[\\\"GRS 1980\\\",6378137,298.257222101,LENGTHUNIT[\\\"metre\\\",1]]],PRIMEM[\\\"Greenwich\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],ID[\\\"EPSG\\\",4617]],CONVERSION[\\\"MTM zone 7\\\",METHOD[\\\"Transverse Mercator\\\",ID[\\\"EPSG\\\",9807]],PARAMETER[\\\"Latitude of natural origin\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8801]],PARAMETER[\\\"Longitude of natural origin\\\",-70.5,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8802]],PARAMETER[\\\"Scale factor at natural origin\\\",0.9999,SCALEUNIT[\\\"unity\\\",1],ID[\\\"EPSG\\\",8805]],PARAMETER[\\\"False easting\\\",304800,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8806]],PARAMETER[\\\"False northing\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8807]]],CS[Cartesian,2],AXIS[\\\"easting (E(X))\\\",east,ORDER[1],LENGTHUNIT[\\\"metre\\\",1]],AXIS[\\\"northing (N(Y))\\\",north,ORDER[2],LENGTHUNIT[\\\"metre\\\",1]],USAGE[SCOPE[\\\"Engineering survey, topographic mapping.\\\"],AREA[\\\"Canada - Quebec - between 72°W and 69°W.\\\"],BBOX[45.01,-72,61.8,-69]],ID[\\\"EPSG\\\",2949]]\" #>  #> $epsg #> [1] 2949 #>   # Compute metrics for each plot read = reader_circles(c(273400, 273500), c(5274450, 5274550), 11.28) metrics = summarise(metrics = c(\"z_mean\", \"z_p95\", \"i_median\", \"count\")) pipeline = read + metrics ans = exec(pipeline, on = f) ans$metrics #>   count i_median   z_mean    z_p95 #> 1   291     1311 806.0330 807.2401 #> 2   185      731 804.0168 811.2172"},{"path":"https://r-lidar.github.io/lasR/reference/temporary_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporary files — temporary_files","title":"Temporary files — temporary_files","text":"Convenient functions create temporary file given extension.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/temporary_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporary files — temporary_files","text":"","code":"temptif()  tempgpkg()  tempshp()  templas()  templaz()"},{"path":"https://r-lidar.github.io/lasR/reference/temporary_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporary files — temporary_files","text":"string. Path temporary file.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/temporary_files.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporary files — temporary_files","text":"","code":"tempshp() #> [1] \"/tmp/Rtmp5kcE0j/file25df2872fed1.shp\" templaz() #> [1] \"/tmp/Rtmp5kcE0j/file25df13de7820.laz\""},{"path":"https://r-lidar.github.io/lasR/reference/tools.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools inherited from base R — tools","title":"Tools inherited from base R — tools","text":"Tools inherited base R","code":""},{"path":"https://r-lidar.github.io/lasR/reference/tools.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tools inherited from base R — tools","text":"","code":"# S3 method for class 'PipelinePtr' print(x, ...)  # S3 method for class 'PipelinePtr' e1 + e2  # S3 method for class 'PipelinePtr' x[[i, ...]]"},{"path":"https://r-lidar.github.io/lasR/reference/tools.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools inherited from base R — tools","text":"x, e1, e2 lasR objects ... lasR objects. equivalent + index","code":""},{"path":"https://r-lidar.github.io/lasR/reference/tools.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tools inherited from base R — tools","text":"","code":"algo1 <- rasterize(1, \"max\") algo2 <- rasterize(4, \"min\") print(algo1) #> ----------- #> rasterize (uid:99cf75ddf3c1) #>   method : [max]  #>   window : 1.00  #>   res : 1.00  #>   filter : []  #>   output : /tmp/Rtmp5kcE0j/file25df1e5462bb.tif  #> ----------- #>  #> NULL pipeline <- algo1 + algo2 print(pipeline) #> ----------- #> rasterize (uid:99cf75ddf3c1) #>   method : [max]  #>   window : 1.00  #>   res : 1.00  #>   filter : []  #>   output : /tmp/Rtmp5kcE0j/file25df1e5462bb.tif  #> ----------- #> rasterize (uid:fdb7938909f3) #>   method : [min]  #>   window : 4.00  #>   res : 4.00  #>   filter : []  #>   output : /tmp/Rtmp5kcE0j/file25df609b3c43.tif  #> ----------- #>  #> NULL"},{"path":"https://r-lidar.github.io/lasR/reference/transform_with.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform a Point Cloud Using Another Stage — transform_with","title":"Transform a Point Cloud Using Another Stage — transform_with","text":"stage uses another stage modify point cloud pipeline. used Delaunay triangulation raster, performs operation modify Z coordinate point cloud. interpolation method linear triangle mesh bilinear raster. can typically used build normalization stage. used 4x4 Rotation-Translation Matrix, multiplies coordinates points apply rigid transformation described matrix. stage modifies point cloud pipeline produce output.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/transform_with.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform a Point Cloud Using Another Stage — transform_with","text":"","code":"transform_with(stage, operator = \"-\", store_in_attribute = \"\", bilinear = TRUE)"},{"path":"https://r-lidar.github.io/lasR/reference/transform_with.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform a Point Cloud Using Another Stage — transform_with","text":"stage stage produces triangulation, raster, Rotation-Translation Matrix (RTM), sometimes also referred \"Affine Transformation Matrix\". Can also 4x4 RTM matrix. operator string. '-' '+' supported (triangulation raster). store_in_attribute string. Use extra byte attribute store result (triangulation raster). bilinear bool. stage raster stage, Z values interpolated bilinear interpolation. FALSE desactivate .","code":""},{"path":"https://r-lidar.github.io/lasR/reference/transform_with.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform a Point Cloud Using Another Stage — transform_with","text":"stage transforms point cloud pipeline. consequently returns nothing.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/transform_with.html","id":"rtm-matriz","dir":"Reference","previous_headings":"","what":"RTM Matriz","title":"Transform a Point Cloud Using Another Stage — transform_with","text":"Warning: lasR uses bounding boxes oriented along XY axes processed chunk manage data location buffer properly. Transforming point cloud rotation matrix affects bounding box lasR handles buffer. used matrix rotational component, safe add stages transformation unless user certain buffer involved.","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/reference/transform_with.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform a Point Cloud Using Another Stage — transform_with","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\")  # with a triangulation mesh  <- triangulate(filter = keep_ground()) trans <- transform_with(mesh) pipeline <- mesh + trans + write_las() ans <- exec(pipeline, on = f)  # with a matrix a = 20 * pi / 180 m <- matrix(c(   cos(a), -sin(a), 0, 1000,   sin(a), cos(a), 0, 0,   0, 0, 1, 0,   0, 0, 0, 1), nrow = 4, byrow = TRUE)  pipeline = transform_with(m) + write_las() exec(pipeline, on = f) #> $load_matrix #>           [,1]       [,2] [,3] [,4] #> [1,] 0.9396926 -0.3420201    0 1000 #> [2,] 0.3420201  0.9396926    0    0 #> [3,] 0.0000000  0.0000000    1    0 #> [4,] 0.0000000  0.0000000    0    1 #>  #> $write_las #> [1] \"/tmp/Rtmp5kcE0j/Topography.las\" #>"},{"path":"https://r-lidar.github.io/lasR/reference/triangulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Delaunay triangulation — triangulate","title":"Delaunay triangulation — triangulate","text":"2.5D Delaunay triangulation. Can used build DTM, CHM, normalize point cloud, application. stage typically used intermediate process without output file. stage modify point cloud.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/triangulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delaunay triangulation — triangulate","text":"","code":"triangulate(max_edge = 0, filter = \"\", ofile = \"\", use_attribute = \"Z\")"},{"path":"https://r-lidar.github.io/lasR/reference/triangulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delaunay triangulation — triangulate","text":"max_edge numeric. Maximum edge length triangle Delaunay triangulation. triangle edge length greater value, removed. max_edge = 0, trimming done (see examples). filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters. ofile character. Full outputs always stored disk. ofile = \"\" stage store result disk return nothing. however hold partial output results temporarily memory. useful stage intermediate stage. use_attribute character. Specifies attribute use operation, \"Z\" (coordinate) default. Alternatively, can name attribute, \"Intensity\", \"gpstime\", \"ReturnNumber\", \"HAG\", exists. Note: function fail specified attribute exist point cloud. example, \"Intensity\" requested present, \"HAG\" specified unavailable, internal engine return 0 missing attribute.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/triangulate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delaunay triangulation — triangulate","text":"stage produces vector. path provided `ofile` expected `.gpkg` format supported GDAL. Vector stages may produce geometries Z coordinates. Thus, discouraged store formats 3D support, shapefiles.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/triangulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delaunay triangulation — triangulate","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader() tri1 <- triangulate(25, filter = keep_ground(), ofile = tempgpkg()) tri2 <- triangulate(ofile = tempgpkg()) pipeline <- read + tri1 + tri2 ans <- exec(pipeline, on = f) #plot(ans[[1]]) #plot(ans[[2]])"},{"path":"https://r-lidar.github.io/lasR/reference/write.html","id":null,"dir":"Reference","previous_headings":"","what":"Write point clouds — write_las","title":"Write point clouds — write_las","text":"Write point cloud LAS LAZ PCD files step pipeline (typically end). Unlike stages, output written single large file multiple tiled files corresponding original collection files.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/write.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write point clouds — write_las","text":"","code":"write_las(   ofile = paste0(tempdir(), \"/*.las\"),   filter = \"\",   keep_buffer = FALSE )  write_copc(   ofile = paste0(tempdir(), \"/*.copc.laz\"),   filter = \"\",   keep_buffer = FALSE,   max_depth = NA,   density = \"dense\" )  write_pcd(ofile = paste0(tempdir(), \"/*.pcd\"), binary = TRUE)"},{"path":"https://r-lidar.github.io/lasR/reference/write.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write point clouds — write_las","text":"ofile character. Output file names. string must contain wildcard * wildcard can replaced name original tile preserve tiling pattern. wildcard omitted, everything written single file. may desired behavior circumstances, e.g., merge files. filter 'filter' argument allows filtering point-cloud work points interest. given stage filter applied, points meet criteria processed. common strings Classification == 2\", \"Z > 2\", \"Intensity < 100\". details see filters. keep_buffer bool. buffer removed write file can preserved. max_depth integer. Maximum depth hierarchy. Default NA meaning auto computes density character. Can 'sparse', 'normal' 'dense'. controls point density per octant. 'sparce' Octree octant subdivided 64 x 64 x 64 cells mean density point light. Normal 128, dense 256. binary boolean. Write binary ascii PCD files.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/write.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write point clouds — write_las","text":"write_las can write COPC LAZ file simply naming output file \".copc.laz\" extension. However, users must cautious. Writing COPC optimized memory usage requires two copies point cloud memory ensure proper sorting writing. user afford keep two copies point cloud RAM, use specialized writer Untwine (PDAL) lascopcindex (LAStools).write_copc wrapper around write_las, extra arguments control COPC format.write_pcd merge multiple files one bigger file yet. write subset file either yet.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/write.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write point clouds — write_las","text":"","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") read <- reader() tri  <- triangulate(filter = keep_ground()) normalize <- tri + transform_with(tri) pipeline <- read + normalize + write_las(paste0(tempdir(), \"/*_norm.las\")) exec(pipeline, on = f) #> [1] \"/tmp/Rtmp5kcE0j/Topography_norm.las\""},{"path":"https://r-lidar.github.io/lasR/reference/write_lax.html","id":null,"dir":"Reference","previous_headings":"","what":"Write spatial indexing .lax files — write_lax","title":"Write spatial indexing .lax files — write_lax","text":"Creates .lax file .las .laz file processed datase. .lax file contains spatial indexing information. Spatial indexing drastically speeds tile buffering spatial queries. lasR, mandatory spatially indexed point clouds, either using .lax files .copc.laz files. processed file collection spatially indexed, write_lax() file automatically added beginning pipeline (see Details).","code":""},{"path":"https://r-lidar.github.io/lasR/reference/write_lax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write spatial indexing .lax files — write_lax","text":"","code":"write_lax(embedded = FALSE, overwrite = FALSE)"},{"path":"https://r-lidar.github.io/lasR/reference/write_lax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write spatial indexing .lax files — write_lax","text":"embedded boolean. .lax file auxiliary file accompanies corresponding las laz file. .lax file can also embedded within laz file produce single file. overwrite boolean. stage create new spatial index corresponding point cloud already spatial index. TRUE, forces creation new one. copc.laz files never reindexed lax files.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/write_lax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write spatial indexing .lax files — write_lax","text":"stage added automatically lasR, placed beginning pipeline, las/laz files indexed --fly used. advantage users need anything; works transparently delay processing. drawback , condition, stage run parallel. stage explicitly added users, can placed anywhere pipeline always executed first anything else. files indexed first parallel, actual processing start. avoid overthinking works, best simpler run exec(write_lax(), = files) non indexed point cloud anything point cloud.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/write_lax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write spatial indexing .lax files — write_lax","text":"","code":"if (FALSE) { # \\dontrun{ exec(write_lax(), on = files) } # }"},{"path":"https://r-lidar.github.io/lasR/reference/write_vpc.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a Virtual Point Cloud — write_vpc","title":"Write a Virtual Point Cloud — write_vpc","text":"Borrowing concept virtual rasters GDAL, VPC file format references point cloud files virtual point cloud (VPC)","code":""},{"path":"https://r-lidar.github.io/lasR/reference/write_vpc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a Virtual Point Cloud — write_vpc","text":"","code":"write_vpc(ofile, absolute_path = FALSE, use_gpstime = FALSE)"},{"path":"https://r-lidar.github.io/lasR/reference/write_vpc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a Virtual Point Cloud — write_vpc","text":"ofile character. file path extension .vpc write virtual point cloud file absolute_path boolean. absolute path files stored tile index file. use_gpstime logical. fill datetime attribute VPC file, uses year day year recorded header. attributes usually relevant. often zeroed official signification attributes corresponds creation LAS file. guarantee date corresponds acquisition date. use_gpstime = TRUE, use gpstime first point recorded file compute day year acquisition. works GPS time recorded Adjusted Standard GPS Time GPS Week Time.","code":""},{"path":"https://r-lidar.github.io/lasR/reference/write_vpc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Write a Virtual Point Cloud — write_vpc","text":"https://www.lutraconsulting.co.uk/blog/2023/06/08/virtual-point-clouds/https://github.com/PDAL/wrench/blob/main/vpc-spec.md","code":""},{"path":"https://r-lidar.github.io/lasR/reference/write_vpc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a Virtual Point Cloud — write_vpc","text":"","code":"if (FALSE) { # \\dontrun{ pipeline = write_vpc(\"folder/dataset.vpc\") exec(pipeline, on = \"folder\") } # }"},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0172","dir":"Changelog","previous_headings":"","what":"lasR 0.17.2","title":"lasR 0.17.2","text":"Fix: #198 LAS files 0 points discarded --fly. New: argument store_in_attribute local_maximum New: undocumented capacity logging informations files (log, progress). Accessible R API via Accessible C++ API via two members Fix: #205 absolute paths write_vpc broken since 0.17.0 Fix: #207 sor executed parallel multiple files. Fix: #206 local_maximum() normalize() delete_points()","code":"exec(..., progress_file = \"path/to/progress.ext\", log_file = \"path/to/log.ext\") Pipeline::set_progress_file(std::string); Pipeline::set_profile_file(std::string);"},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0171","dir":"Changelog","previous_headings":"","what":"lasR 0.17.1","title":"lasR 0.17.1","text":"Fix: info() prints informations processed chunk. first one. Fix: #196. ExtraBytes attributes zeroed reading two files (main file + buffer file)","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0170","dir":"Changelog","previous_headings":"","what":"lasR 0.17.0","title":"lasR 0.17.0","text":"lasR 0.17.0 bring new features. However redesigned internally provided C++ API. R API (lasR package) now uses C++ API. now python package (pylasr) leverage C++ API well. now possible integrate lasR API matlab, juliaor language supports C++ binding simple pipeline 3 stage using C++, R python API. variable list file apply pipeline. C++: R: python:","code":"#include \"api.h\"  using namespace api;  // platform independent tmp file std::filesystem::path temp_dir = std::filesystem::temp_directory_path();  std::filesystem::path temp_file = temp_dir / \"test.las\";  Pipeline p; p.set_files(on); p.set_concurrent_files_strategy(8); p.set_progress(true);  p += info() +   delete_points({\"Z < 1.37\"}) +    write_las(temp_file);  std::string file = p.write_json();  execute(file); library(lasR)  pipeline = info() +     delete_points(\"Z < 1.37\") +    write_las()  execute(pipeline, on, ncores = 8, progress = TRUE); import pylasr  # Use example file from the package example_file = \"inst/extdata/Example.las\" output_file = \"filtered_output.las\"  pipeline = (pylasr.info() +              pylasr.delete_points([\"Z < 1.37\"]) +              pylasr.write_las(output_file))  pipeline.set_progress(True) result = pipeline.execute(example_file)"},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"breaking-changes-0-17-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"lasR 0.17.0","text":"Inverted delete_points behavior: stage delete_points now works consistently stages’ filter arguments. Previously, delete_points(\"Z < 4\") kept points 4, allowed commands like delete_points(keep_z_below(4)) counter-intuitive.Now, points matching filter processed. case delete_points(), means deleted.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"fixes-0-17-0","dir":"Changelog","previous_headings":"","what":"Fixes","title":"lasR 0.17.0","text":"Fixed crash geometry_features running points deleted delete_points().","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0162","dir":"Changelog","previous_headings":"","what":"lasR 0.16.2","title":"lasR 0.16.2","text":"Fix #164: lasR now fast . unknown reason, become extremely slow stages involving spatial queries normalize(), transform_with(), sor(), geometry_feature(). lasR performance restored. Enhancement: building kdtree spatial indexing can take significant time (several seconds). Spatial indexes now built required. Thus, pipeline using rasterize() longer build spatial index. Regression: regained full speed lasR cost increased memory usage. lasR now consumes memory.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0161","dir":"Changelog","previous_headings":"","what":"lasR 0.16.1","title":"lasR 0.16.1","text":"Fix #158: triangulation fewer 3 points Fix #160: crash empty folder Fix: NIR attribute now recognized part LAS specification Fix #161: reader_circles() reader_rectangles() skipping queries outside file collection Fix #166: sort_points() works deleted points previous stages Fix #170: classify_with_sor() flagged parallelized use multiple cores Fix #170: KNN search rewritten using nanoflann; stages relying KNN search now much faster","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0160","dir":"Changelog","previous_headings":"","what":"lasR 0.16.0","title":"lasR 0.16.0","text":"New: stage edit_attribute() New: stage remove_attribute() New: filters keep_z_between() drop_z_between() Doc: enhanced documentation filter argument Doc: revised documentation add_extrabytes() Change: add_attributes() checks reserved names (#159) Change: angle computed geometry_feature() now called inclination instead angle, angle reserved name","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0151","dir":"Changelog","previous_headings":"","what":"lasR 0.15.1","title":"lasR 0.15.1","text":"Fix #146 fix memory layout adding new attributes Fix #146 add_attribute() overwrite previous attribute rather duplicating . Fix #135 write valid WKT string COPC files Fix #151 memory corruption calling callback deleted points","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0150","dir":"Changelog","previous_headings":"","what":"lasR 0.15.0","title":"lasR 0.15.0","text":"New: lasR now supports PCD format. reader() function can read PCD files, new stage, write_pcd(), available. However, due current state software limitations format , functionality restricted: lasR read multiple PCD files, thus buffer merge . Additionally, write_pcd() support streaming data. New: #140 info() now prints useful COPC metadata. Fix: #142 circular buffers now handled properly. Change: #139 chm() function replaced dsm().","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0141","dir":"Changelog","previous_headings":"","what":"lasR 0.14.1","title":"lasR 0.14.1","text":"Fix: #141 write_las() drops circular buffers properly Fix: #136 write_las() preserves dates writes generating software Enhance: #137 pipeline preserve VLR attributes LAS files","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0140","dir":"Changelog","previous_headings":"","what":"lasR 0.14.0","title":"lasR 0.14.0","text":"Doc: Documented lasR can write COPC files. New: Added write_copc() function extra arguments control hierarchy depth density. Fix: Fixed unmapped memory issue writing COPC files.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0139","dir":"Changelog","previous_headings":"","what":"lasR 0.13.9","title":"lasR 0.13.9","text":"Fix: #113 geometry_feature() overwrite attributes already existing. Fix: serious bug memory may corrupted deleting points leading unexpected results crash.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0138","dir":"Changelog","previous_headings":"","what":"lasR 0.13.8","title":"lasR 0.13.8","text":"New argument check load_matrix() disable orthogonality check Enhancement: info() reporting point density. Enhancement: incorrect extension raster vector files outputs now returns helpful error. Previously using e.g. .tif local maximum output instead .shpor gpkg returned non helpful error: Erreur : error 1 creating GDAL dataset. Attempt create 0x0 dataset illegal,sizes must larger zero. now returns Expecting vector format : file.tif","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0137","dir":"Changelog","previous_headings":"","what":"lasR 0.13.7","title":"lasR 0.13.7","text":"Fix: #123 filter argument negative numbers Fix: #124 exec() 0 file longer crashes. New: new stage load_matrix()","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0136","dir":"Changelog","previous_headings":"","what":"lasR 0.13.6","title":"lasR 0.13.6","text":"Fix: #120 fix write_las() properly writes return number number return LAS 1.4 format 6 Fix: info() longer prints every point streamable pipelines Enhancement: better support LAS format write_las(). write LAS file version format input. Enhancement: info() prints source format (LAS, PCD) version (1.4, 0.7).","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0135","dir":"Changelog","previous_headings":"","what":"lasR 0.13.5","title":"lasR 0.13.5","text":"New: transform_with used raster, bilinear interpolation can deactivated Fix: #118 one pixel shift DTM alignment","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0134","dir":"Changelog","previous_headings":"","what":"lasR 0.13.4","title":"lasR 0.13.4","text":"New: Added metrics skew kurt metric engine. New: [#110] LAS files, bit flags now read bit attributes. feature lost version 0.13.0. New: [#110] write_las() now automatically writes LAS 1.4 format required. Fix: Resolved floating-point inaccuracy region_growing() cause edge effects across two tiles chunks effectively splitting trees two parts different IDs high-resolution CHM. Fix: documentation region_growing() states max_cr parameter represents “Maximum value crown diameter detected tree”. practice, used maximum radius, resulting trees larger expected. corrected.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0133","dir":"Changelog","previous_headings":"","what":"lasR 0.13.3","title":"lasR 0.13.3","text":"Fix: #105 invalid read extrabytes Change: memory reallocated freed many points deleted stage (visible users) Change: adaptive indexation point cloud speed process low high density point clouds.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0132","dir":"Changelog","previous_headings":"","what":"lasR 0.13.2","title":"lasR 0.13.2","text":"Fix: internal function update_header() updates bounding box. Bug probably invisible users.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0131","dir":"Changelog","previous_headings":"","what":"lasR 0.13.1","title":"lasR 0.13.1","text":"Fix #103: silly typo bug caused buffering feature lost. Fix #104: crash deprecated extrabytes LAS format","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0130","dir":"Changelog","previous_headings":"","what":"lasR 0.13.0","title":"lasR 0.13.0","text":"lasR 0.13.0 massive rewrite internal engine conform third-party libraries licenses. version lasR longer tight LAS/LAZ format able support point cloud format. already partially supports PCD file format. ’m expecting users encounter bugs near future. However, unit tests passing.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"breaking-changes-0-13-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"lasR 0.13.0","text":"longer possible use LASlib filters -drop_z_above 5 stages (except reader stage). Users must use conditional commands introduced 0.12.0, \"Z > 5\". reader longer reads bit flags LAS/LAZ files, never used anyway. sort_points() longer sorts GPS time return number. performs spatial sort , parameter spatial removed. classify_with_csf() longer uses last return . write_las() longer preserves VLR EVLR. fixed later. likely changes rewrote thousands lines code.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"new-features-0-13-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"lasR 0.13.0","text":"New: Ability pre-read point cloud R using external pointer. See ?read_cloud(). See tutorial. New: Stages can now applied one one point cloud loaded memory. New: reader() replace reader_las() lasR intended limited LAS/LAZ. reader_las() deprecated. reader() supposed support format future. New: reader() new argument copc_depth","code":"f <- system.file(\"extdata\", \"Topography.las\", package=\"lasR\") pc <- read_cloud(f) u = exec(chm(5), on = pc)"},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0121","dir":"Changelog","previous_headings":"","what":"lasR 0.12.1","title":"lasR 0.12.1","text":"Fix: critical bug windows #96","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0120","dir":"Changelog","previous_headings":"","what":"lasR 0.12.0","title":"lasR 0.12.0","text":"Fix: sampling stages, filter argument previously discarded points pass test. updated behavior processes points pass test leaving others untouched. example: Previously, filtered point cloud retain Poisson-sampled ground points. Now, correctly Poisson-samples ground points preserving points. New: Added new stage, info(), print useful information file. New: Command-line utility introduced. Users can now execute simple pipelines terminal. First, use install_cmd_tools(), commands like become available: New: transform_with() now supports 4x4 Affine Transformation Matrix translate rotate point cloud. Change: Eigen library replaced Armadillo library linear algebra. change may affect sign vectors geometry_feature(). New: filter argument, available many stages, now accepts programming-style strings Z < 3, Classification == 2, UserData == 0, Intensity > 100, Classification %% 2 3 4, Classification %% 0 1 2. approach now preferred way assign filters, allowing filtering extrabyte attributes name, e.g., Amplitude > 10. Change: transform_with() raster (typically normalization) now performs bilinear interpolation. New: stages use_attribute argument now accept attribute including extrabytes attribute. New: sampling_pixel() gained argument method use_attribute retain specific points interest.","code":"sampling_poisson(1, filter = keep_ground()) lasr info -i path/to/file.las lasr vpc -i path/to/folder  lasr lax -i path/to/folder -ncores 8 lasr help lasr chm -i path/to/folder -o path/to/chm.tif -res 1 -ncore 4 lasr dtm -i path/to/folder -o path/to/chm.tif -res 0.5 -ncore 4"},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0103","dir":"Changelog","previous_headings":"","what":"lasR 0.10.3","title":"lasR 0.10.3","text":"Change: normalize() loose argument extrabytes favor new function hag() equivalent normalize(TRUE) New: add stages delete_noise(), delete_ground()","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0102","dir":"Changelog","previous_headings":"","what":"lasR 0.10.2","title":"lasR 0.10.2","text":"Fix: local_maximum function previously experienced significant delays writing points disk, taking 2 seconds Linux 30 seconds Windows. issue severely hindered parallelization capabilities. new fix dramatically reduces write time around 0.1 seconds, greatly improving overall performance.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0101","dir":"Changelog","previous_headings":"","what":"lasR 0.10.1","title":"lasR 0.10.1","text":"Fix #91: Resolved critical memory addressing issue handling large point clouds. Fix: Improved pipeline efficiency preventing reading buffer tiles pipelines using stop_if() reader_las(). Previously, buffer read even points meant skipped, leading unnecessary processing time (seconds per skipped file).","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-0100","dir":"Changelog","previous_headings":"","what":"lasR 0.10.0","title":"lasR 0.10.0","text":"New: new stage classify_with_sor() classify outliers statistical outlier removal. New: new stage focal() post-process rasters pipeline. New: new stage filter_with_grid() keep lowest highest point per cell grid. Change: #79 raster produced subset data minimal possible extent instead full extent point cloud. Fix: numerous inaccuracies numeric parameters interpreted integers. example, geometry_feature, r = 5 equal 5 r = 4.5 equal 4. Fix: parameters region_growing() individual tree segmentation inverted.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-093","dir":"Changelog","previous_headings":"","what":"lasR 0.9.3","title":"lasR 0.9.3","text":"Fix: Filters based return number, number returns, classification (e.g., -keep_last, -keep_class 128) now functional LAS 1.4. Enhancement: Prevent possibility writing file .copc.las extension; .copc automatically discarded. New: classify_with_csf() stage gained filter argument.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-092","dir":"Changelog","previous_headings":"","what":"lasR 0.9.2","title":"lasR 0.9.2","text":"Fix #81: Added warning Delaunay triangulation computed (fewer 3 points). Fix #81: Read files multiple Extra Bytes definitions. Fix #80: Circular buffers properly removed raster. Fix #83: Aborted pipeline initialization load_raster() raster extent overlaps point cloud. Fix #88: sort() now handles duplicated gpstime properly.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-091","dir":"Changelog","previous_headings":"","what":"lasR 0.9.1","title":"lasR 0.9.1","text":"Fix: Better handle datasets overlapping tiles non-duplicated points. Fix: Trigger lax indexation single file processing chunks. Fix: local_maximum() return multiple -close local maximum points two close points exact Z coordinates exact X Y coordinates (X Y; duplicated points properly handled). particularly affected local_maximum_raster(), two pixels can easily Z X Y. Fix: region_growing() th_tree argument properly respected. Fix: transform_with TIN won’t fail TIN. Instead points removed. Fix: possible edge artifacts possible filter Fix: #78 WGS84 VPC bounding box Enhance: Progress estimation display indexing single file.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-090","dir":"Changelog","previous_headings":"","what":"lasR 0.9.0","title":"lasR 0.9.0","text":"Internal: internal changes support visual programming. See lasRui project. exec() accepts path json file produced UI (non documented) New: filter keep_ground_and_water() Change: normalize uses keep_ground_and_water() Fix: #73 triangulation fails < 3 points","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-080","dir":"Changelog","previous_headings":"","what":"lasR 0.8.0","title":"lasR 0.8.0","text":"New: stage sort_points() optimize compression. New: protection overwriting processed files processing Fix: messages warnings thread safe. pipeline printed message console crash. expected safe now. Fix: #70 Fix: #71 write_lax() 2x faster used single stage Fix: progress bar write_lax() LAS 1.4. Fix: #74 write_lax() now parallelized","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-072","dir":"Changelog","previous_headings":"","what":"lasR 0.7.2","title":"lasR 0.7.2","text":"New argument use_gpstime write_vpc() Fix: division 0 raster stage initialization Fix: datetime parsing write_vpc() Fix: write_vpc() writes valid files readable QGIS","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-071","dir":"Changelog","previous_headings":"","what":"lasR 0.7.1","title":"lasR 0.7.1","text":"Fix: sampling stages robustly support 4 billions voxels Enhance: noise ivf faster. Fix: fix memory corruption point clouds 4.3 GB","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"new-features-0-7-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"lasR 0.7.0","text":"New stage classify_with_csf() classify ground points. metric engine introduced v0.6.0 can now compute metrics extrabytes attributes. e.g. Amplitude_mean New stage sampling_poisson perform Poisson Disk Sampling sampling_pixel sampling_voxel faster.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"fixes-0-7-0","dir":"Changelog","previous_headings":"","what":"FIXES","title":"lasR 0.7.0","text":"sampling_* stages respect filter argument Fix #63 crash chunk skipped either 0 points stop_if stage. Fix #64 metrics RGB actually computed RRR","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"breaking-changes-0-7-0","dir":"Changelog","previous_headings":"","what":"BREAKING CHANGES","title":"lasR 0.7.0","text":"classify_isolated_voxels() renamed classify_with_ivf() consistency.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-062","dir":"Changelog","previous_headings":"","what":"lasR 0.6.2","title":"lasR 0.6.2","text":"Fix: writing copc file copc file crashed. Fix: #62 attributes vector files recorded output file template contains wildcard * Fix: metrics cv sd computed properly.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-061","dir":"Changelog","previous_headings":"","what":"lasR 0.6.1","title":"lasR 0.6.1","text":"Fix: metrics cv sd return NAs instead Inf edges case undefined. Enhance: progress bar displays better number cores used. Fix: progress bar reader_las() stage. now displays correct percentage. Fix: write_las() without wildcard (merge mode) works files different formats scales/offsets","code":""},{"path":[]},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"lasR 0.6.0","text":"New stage stop_if conditionally escape pipeline. New section stop_if online tutorial. New stage write_lax. stage automatically added engine can now explicitly added users. New internal “metric engine”. metric engine used compute metrics , e.g., rasterize() operators like zmean, imean, . metric engine redesigned allows string format attribute_metric z_sd, i_mean, c_mode, a_mean, intensity_max, classification_mode, angle_mean, combinations. attributes mapped, new functions available sum, mode. Many added easily. Former strings zmean imax longer valid replaced z_mean i_max backward compatible. rasterize gained access new metric engine can compute many metrics natively. summarize() gained access metric engine can compute metrics file chunk. Used conjunction reader_las_circle(), can used, example, compute plot inventory metrics. online tutorial updated. section “plot inventory” longer uses callback() preceded new section “summarize”.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"breaking-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"BREAKING CHANGES","title":"lasR 0.6.0","text":"package longer assigns set_parallel_strategy(concurrent_points(half_core())) loading. Instead, nothing provided, interpreted concurrent_points(half_core()). Thus, users can now write exec(pipeline, = file, ncores = 8). engine now respect ncores = 8 global settings global precedence assigned. multi-threading vignette updated. Pipelines include R-based stages (rasterize R function, callback) longer parallelizable concurrent-file strategy. Parallelizing pipeline involves R C API terribly complex eventually leads pseudo-parallelism lot troubleshooting deal (especially abort pipeline). Consequently, removed parallelism capabilities. numerous new native metrics added metric engine compensate loss. online documentation updated accordingly.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"internal-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"INTERNAL CHANGES","title":"lasR 0.6.0","text":"large number changes separate lasR R. lasR can now compiled standalone software. Makefile added repository. R level, pipeline processing options passed C++ engine via JSON file instead passed via R’s C API, effectively separating lasR R . R side lasR now purely API standalone engine. JSON file produced lasR package can executed standalone software: lasr pipeline.json. However, syntax JSON file documented intended documented. Rather, JSON file produced API lasR package, QGIS plugin, Python package. Obviously, currently thing.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-056","dir":"Changelog","previous_headings":"","what":"lasR 0.5.6","title":"lasR 0.5.6","text":"Fix: reader_las() COPC files, depth query (-max_depth), buffer. depth query performed . fix temporary: breaks progress bar reader_las() less serious bug. Fix: reader_las() large files. Fix: load_raster() thread-safe New: rasterize() accepts new argument default_value. rasterizing operator filter (e.g. -keep_z_above 2) pixels covered points may longer contain point pass filter criteria assigned NA. differentiate NAs non covered pixels NAs covered pixels without point pass filter, later case can assigned another value 0.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-055","dir":"Changelog","previous_headings":"","what":"lasR 0.5.5","title":"lasR 0.5.5","text":"Fix: #50 write_vpc() properly reprojects bounding boxes WGS84 Enhance: write_vpc() writes zmin zmax file. Fix: #55 local_maximum() longer fails ofile = \"\" Fix: progress bar reader_las() COPC files. Fix: metrics zsd isd incorrect due wrong parenthesis code.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-054","dir":"Changelog","previous_headings":"","what":"lasR 0.5.4","title":"lasR 0.5.4","text":"Fix: #48 segfault delete_points() 0 points left. Enhance: #47 pipelines named list. Enhance: #47 output list returned exec named duplicated names made unique make.names() Doc: added notes documentation geometry_features() address question #45 Enhance: #49 set_crs() longer forces pipeline read files. Enhance: exec() normalizes path users get error providing path ~. New: rasterize() gained metric zaboveX compute canopy cover.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-053","dir":"Changelog","previous_headings":"","what":"lasR 0.5.3","title":"lasR 0.5.3","text":"Fix: #45 computation time geometry_features delete_points() Fix: local_maximum() processing deleted points. Enhance: #44 write_vpc write datetime Enhance: delete_points can now physically remove deleted points number points deleted important. flagged kept memory. can also free available memory.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-052","dir":"Changelog","previous_headings":"","what":"lasR 0.5.2","title":"lasR 0.5.2","text":"New: #42 write_vpc() gained argument absolute_path Fix: #42 write_vpc() orders long/lat coordinates properly Linux Fix: #42 write_vpc() writes absolute path relative path exist Windows Fix: #40 triangulate() 0 point chunk. Fix: #43: geometry_feature works file already contains extrabytes attributes Enhance: 0 point point-clouds longer stopping computation. stage delete_points() removes points, pipeline stopped current chunk/file computation keep going others. case stages stages either crash stop computation.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-051","dir":"Changelog","previous_headings":"","what":"lasR 0.5.1","title":"lasR 0.5.1","text":"Fix: write_vpc() crash files without CRS Fix: write_vpc() write CRS set upstream set_crs()","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-050","dir":"Changelog","previous_headings":"","what":"lasR 0.5.0","title":"lasR 0.5.0","text":"New: stage geometry_features() compute point wise geometry features based k-nearest neighbors. New: stage callback() can load 10 extrabyte attributes. Using flag E extrabytes loaded. New: stage set_crs() assign coordinate reference system point pipeline. New: raster GeoTiff format now created COMPRESS=DEFLATE, PREDICTOR=2,TILED=YES effectively reducing size rasters New: summarize() output includes CRS.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-048","dir":"Changelog","previous_headings":"","what":"lasR 0.4.8","title":"lasR 0.4.8","text":"Enhance: #33 local_maximum() gained record_attributes argument chose attribute points recorded vector file. Enhance: #33 local_maximum_raster() longer record zeroed LAS point attributes","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-047","dir":"Changelog","previous_headings":"","what":"lasR 0.4.7","title":"lasR 0.4.7","text":"Fix: #32 writing vector file path containing wildcard crashed program.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-046","dir":"Changelog","previous_headings":"","what":"lasR 0.4.6","title":"lasR 0.4.6","text":"Fix: lax included laz file working. Fix: #30 can read files bigger 2.14 GB","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-045","dir":"Changelog","previous_headings":"","what":"lasR 0.4.5","title":"lasR 0.4.5","text":"Fix: #29 using filter rasterize() produced corrupted output.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-044","dir":"Changelog","previous_headings":"","what":"lasR 0.4.4","title":"lasR 0.4.4","text":"Fix: bug set_parallel_strategy(nested(ncores = 4, ncores2 = 4)). Fix: attribute datatime datetime VPC files. Fix: #25 triangulation 0 points crashed. 0 points possible filter. Fix: #24 write_vpc() writes correct number points LAS 1.4 files. Fix: read WKT strings LAS files size inferior declared header (null-terminated record_length_after_header).","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-043","dir":"Changelog","previous_headings":"","what":"lasR 0.4.3","title":"lasR 0.4.3","text":"Fix: #22 segfault partial processing. Fix: memory access WKT strings non-null-terminated.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-042","dir":"Changelog","previous_headings":"","what":"lasR 0.4.2","title":"lasR 0.4.2","text":"Fix: add_attribute() incorrectly reallocating memory causing potential crashes, especially adding several attributes. Fix: reader_las() crashing header LAS file record correct number points. Fix: naming queries. Documentation: reorganized URLs navbar website.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-040","dir":"Changelog","previous_headings":"","what":"lasR 0.4.0","title":"lasR 0.4.0","text":"New: parallelism multiple files. See ?multithreading New: stage local_maximum_raster compute local maximum raster New: argument exec pass processing options preferred direct naming. New: function set_exec_options() assign global processing options override arguments potentially hardcoded exec() New: stage load_raster read raster instead producing fly point cloud. New: stage add_rgb modify point data format Doc: new article website parallelism illustrated version ?multithreading Doc: improve documentation processing options ?exec ?set_exec_options","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-036","dir":"Changelog","previous_headings":"","what":"lasR 0.3.6","title":"lasR 0.3.6","text":"Fix: #18 strongly improving arithmetic accuracy point_in_triangle.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-035","dir":"Changelog","previous_headings":"","what":"lasR 0.3.5","title":"lasR 0.3.5","text":"Fix: #17 transform_with can used pit_fill","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-034","dir":"Changelog","previous_headings":"","what":"lasR 0.3.4","title":"lasR 0.3.4","text":"Fix: #15 pit_fill producing corrupted output Fix: pit_fill respecting parameters given user Fix: pit_fill combination rasterize(\"max\") working properly","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-033","dir":"Changelog","previous_headings":"","what":"lasR 0.3.3","title":"lasR 0.3.3","text":"Fix: #12 write lax buffered chunk Fix: #13 processing chunk buffered","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-032","dir":"Changelog","previous_headings":"","what":"lasR 0.3.2","title":"lasR 0.3.2","text":"Fix: CRS working Windows Fix: library(lasR) transparently checks latest version Windows.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-031","dir":"Changelog","previous_headings":"","what":"lasR 0.3.1","title":"lasR 0.3.1","text":"Fix: bugs making spatial query multiple files multiple spatial indexing systems (e.g. lax+nothing, lax+copc)","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-030","dir":"Changelog","previous_headings":"","what":"lasR 0.3.0","title":"lasR 0.3.0","text":"Change: processor() reader() deprecated replaced exec() reader_las(). intends provide consistent natural way separate pipeline. .e stages global processing options .e. buffer, chunking, progress bar. example following now respects LAScatalog processing options possible previous syntax. New: processor now able process chunk like lidR New: stage delete_points() remove points pipeline. New: now possible write following: New: possible omit reader stage. automatically adds default reader New: triangulation 4x faster uses half memory. Fix: summarize(), rasterize() write_las() longer process withheld points streaming mode.","code":"ctg = lidR::readLAScatalog() pipeline = reader_las() + rasterize(...) exec(pipeline, on = ctg) pipeline = reader_las() + rasterize(...) exec(pipeline, on = file, chunk = 500) dtm = dtm() pipeline <- read + dtm + transform_with(dtm[[2]]) pipeline = rasterize(...) exec(pipeline, on = ctg)"},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-021-2024-03-05","dir":"Changelog","previous_headings":"","what":"lasR 0.2.1 (2024-03-05)","title":"lasR 0.2.1 (2024-03-05)","text":"Fix: callback() properly handles errors injected function New: handy functions tempxyz() generate temp files extension .xyz. New: rasterize() now parallelized internal metrics including buffered area based approach New: rasterize() gained progress bar internal metrics.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-020-2024-03-01","dir":"Changelog","previous_headings":"","what":"lasR 0.2.0 (2024-03-01)","title":"lasR 0.2.0 (2024-03-01)","text":"New: rasterize() gains ability perform multi-resolution buffered rasterization. See documentation. New: rasterize() gains numerous native metrics zmax, zmean, zmedian, imax, imean . New: internal engine gains ability skip processing files collection use files load buffer. feature works LAScatalog lidR respecting processed attribute used lidR Fix: loading package offline created bug R longer handles errors.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-012-2024-02-10","dir":"Changelog","previous_headings":"","what":"lasR 0.1.2 (2024-02-10)","title":"lasR 0.1.2 (2024-02-10)","text":"New: progress bar reading header files (LAScatalog) can enabled progress = TRUE Fix: progress bar starts appear earlier .e. 0%. pipeline affects feeling progress.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-011-2024-02-08","dir":"Changelog","previous_headings":"","what":"lasR 0.1.1 (2024-02-08)","title":"lasR 0.1.1 (2024-02-08)","text":"Doc: Corrected documentation argument ncores processor(), incorrectly mentioned supported. New: Added new functions ncores() half_cores(). Fix: Corrected reader progress bar display reading las file filter buffer. Fix: Fixed overall progress bar, delayed one file showing incorrect progress.","code":""},{"path":"https://r-lidar.github.io/lasR/news/index.html","id":"lasr-010-2024-02-01","dir":"Changelog","previous_headings":"","what":"lasR 0.1.0 (2024-02-01)","title":"lasR 0.1.0 (2024-02-01)","text":"Open public Fix: Fix overall progress bar, delayed one file showing incorrect progress.","code":""}]
